{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression_using_deep_learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RkXsMT7FvGWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this task, I am going to use neural network to build model to predict the charges of medical based on set of features for the patients. Also I will examine the difference between two methods for normalizing the data. These methods are Standard Scaler anf MinMax Scaler."
      ],
      "metadata": {
        "id": "K8fmkVK5l_-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "nYCE2RMEzXry"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insurance** dataset"
      ],
      "metadata": {
        "id": "foAv-glKq2ZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/krish1407/Medical-Cost-Personal-Datasets/master/insurance.csv'"
      ],
      "metadata": {
        "id": "D0s4OQmTzIR-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the dataset into pandas\n",
        "\n",
        "insurance = pd.read_csv(url)\n",
        "insurance.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DRK_oUvbqRW_",
        "outputId": "a25edd1b-7cf2-4405-ff47-5c5a4c7cff5d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5ad1de4c-36ad-4253-a05f-41cf459f24ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ad1de4c-36ad-4253-a05f-41cf459f24ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ad1de4c-36ad-4253-a05f-41cf459f24ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ad1de4c-36ad-4253-a05f-41cf459f24ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Features**:\n",
        "\n",
        "**age**: age of primary beneficiary\n",
        "\n",
        "**sex**: insurance contractor gender, female, male\n",
        "\n",
        "**bmi**: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,\n",
        "objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n",
        "\n",
        "**children**: Number of children covered by health insurance / Number of dependents\n",
        "\n",
        "**smoker**: Smoking\n",
        "\n",
        "**region**: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
        "\n",
        "**charges**: Individual medical costs billed by health insurance"
      ],
      "metadata": {
        "id": "yQUIFox0rT65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "insurance.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8DKeAQGuGJh",
        "outputId": "a4086529-e95c-4276-f196-2dc433ecad59"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1338 entries, 0 to 1337\n",
            "Data columns (total 7 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       1338 non-null   int64  \n",
            " 1   sex       1338 non-null   object \n",
            " 2   bmi       1338 non-null   float64\n",
            " 3   children  1338 non-null   int64  \n",
            " 4   smoker    1338 non-null   object \n",
            " 5   region    1338 non-null   object \n",
            " 6   charges   1338 non-null   float64\n",
            "dtypes: float64(2), int64(2), object(3)\n",
            "memory usage: 73.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check null values\n",
        "\n",
        "insurance.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8VKqWkPDkMW",
        "outputId": "90953d5f-3b0f-4a8d-d7d3-21025d388a5e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age         0\n",
              "sex         0\n",
              "bmi         0\n",
              "children    0\n",
              "smoker      0\n",
              "region      0\n",
              "charges     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the data type of arributes\n",
        "insurance.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3u67zgaCDlP",
        "outputId": "b01b9746-fc7e-493b-af2c-87f186c66773"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age           int64\n",
              "sex          object\n",
              "bmi         float64\n",
              "children      int64\n",
              "smoker       object\n",
              "region       object\n",
              "charges     float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Q6as8sVQ4LN6"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UTKnQJZI4R-a"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the distribution of numerical features"
      ],
      "metadata": {
        "id": "hA5uEprPetqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(insurance['children'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "nDMShHBHeyc7",
        "outputId": "f00410d4-6f01-490d-dc3d-bab678fcd290"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(insurance['bmi'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "_PWp6EcnfBUQ",
        "outputId": "0474f590-6ade-4a92-9d1d-55ce01e32f63"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(insurance['age'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "cpMVxCmmfGzG",
        "outputId": "db0a7a49-10a4-46bf-858d-9eef7ae5668a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into X and y\n",
        "X = insurance.drop(['charges'], axis =1)\n",
        "y = insurance['charges']\n"
      ],
      "metadata": {
        "id": "ZeaL404fpwGH"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing** (Normalization and standardization)"
      ],
      "metadata": {
        "id": "77UbwT5ZcI_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to try two different methods for scaling. These are MinMax scaler and Standard Scaler"
      ],
      "metadata": {
        "id": "3XJ2Hu9HrB0p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Using Standard Scaler**"
      ],
      "metadata": {
        "id": "oqWNrhv5ratI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the numerical features using Min Max Scaler\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "from sklearn.compose import make_column_transformer\n",
        "\n",
        "ct = make_column_transformer((StandardScaler(),['age', 'bmi','children'] ),\n",
        "                             (OneHotEncoder(), ['smoker', 'region', 'sex'])\n",
        "                             )\n",
        "insurance_standard_scaled = ct.fit_transform(X)\n",
        "\n",
        "insurance_standard_scaled[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC_wOmci4OCy",
        "outputId": "ba681526-7696-4637-d4d8-946db0605f72"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.43876426, -0.45332   , -0.90861367,  0.        ,  1.        ,\n",
              "        0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
              "        0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the date into train, test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(insurance_standard_scaled,y,test_size = .2, random_state = 42)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0sIexaE9gzF",
        "outputId": "73f4076f-bce4-4baa-caf0-fd62ffb58fbf"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1070, 11), (268, 11), (1070,), (268,))"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build Model**"
      ],
      "metadata": {
        "id": "HSjk5jhvf1Om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "insurance_model1 = tf.keras.Sequential([\n",
        "              tf.keras.layers.Dense(100, activation='relu', input_shape = (11,)),\n",
        "              tf.keras.layers.Dense(10, activation='relu'),\n",
        "              tf.keras.layers.Dense(1)\n",
        "\n",
        "              \n",
        "\n",
        "] )\n",
        "\n",
        "# Compile the model\n",
        "insurance_model1.compile(loss=tf.keras.losses.mae,\n",
        "                         optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                         metrics=['mae']\n",
        "                         )\n"
      ],
      "metadata": {
        "id": "u1kbJg2tzgVI"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ealy_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "# train the model\n",
        "history = insurance_model1.fit(X_train,y_train, validation_data=[X_test,y_test],callbacks=[ealy_stopping] ,verbose = 1, epochs = 1000)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zahV5QC_Gzf",
        "outputId": "2654f381-7369-4c5e-fe7a-8e98008fa632"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "34/34 [==============================] - 1s 6ms/step - loss: 13344.8047 - mae: 13344.8047 - val_loss: 12965.3750 - val_mae: 12965.3750\n",
            "Epoch 2/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13340.4424 - mae: 13340.4424 - val_loss: 12958.5791 - val_mae: 12958.5791\n",
            "Epoch 3/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13330.0244 - mae: 13330.0244 - val_loss: 12943.1377 - val_mae: 12943.1377\n",
            "Epoch 4/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13308.0371 - mae: 13308.0371 - val_loss: 12912.7441 - val_mae: 12912.7441\n",
            "Epoch 5/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 13268.1182 - mae: 13268.1182 - val_loss: 12861.2539 - val_mae: 12861.2539\n",
            "Epoch 6/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13204.3223 - mae: 13204.3223 - val_loss: 12782.9854 - val_mae: 12782.9854\n",
            "Epoch 7/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13111.0957 - mae: 13111.0957 - val_loss: 12672.8555 - val_mae: 12672.8555\n",
            "Epoch 8/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12983.2891 - mae: 12983.2891 - val_loss: 12525.4180 - val_mae: 12525.4180\n",
            "Epoch 9/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12816.0684 - mae: 12816.0684 - val_loss: 12336.4912 - val_mae: 12336.4912\n",
            "Epoch 10/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12604.7881 - mae: 12604.7881 - val_loss: 12101.3447 - val_mae: 12101.3447\n",
            "Epoch 11/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12345.4150 - mae: 12345.4150 - val_loss: 11816.8301 - val_mae: 11816.8301\n",
            "Epoch 12/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12039.1104 - mae: 12039.1104 - val_loss: 11491.2549 - val_mae: 11491.2549\n",
            "Epoch 13/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11694.4336 - mae: 11694.4336 - val_loss: 11134.8232 - val_mae: 11134.8232\n",
            "Epoch 14/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11330.7803 - mae: 11330.7803 - val_loss: 10773.5205 - val_mae: 10773.5205\n",
            "Epoch 15/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10945.4053 - mae: 10945.4053 - val_loss: 10394.5020 - val_mae: 10394.5020\n",
            "Epoch 16/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10544.5430 - mae: 10544.5430 - val_loss: 9997.9199 - val_mae: 9997.9199\n",
            "Epoch 17/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10123.9111 - mae: 10123.9111 - val_loss: 9589.2676 - val_mae: 9589.2676\n",
            "Epoch 18/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 9686.2832 - mae: 9686.2832 - val_loss: 9189.9824 - val_mae: 9189.9824\n",
            "Epoch 19/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 9258.7012 - mae: 9258.7012 - val_loss: 8831.5830 - val_mae: 8831.5830\n",
            "Epoch 20/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8863.1621 - mae: 8863.1621 - val_loss: 8518.7188 - val_mae: 8518.7188\n",
            "Epoch 21/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8503.5449 - mae: 8503.5449 - val_loss: 8242.5273 - val_mae: 8242.5273\n",
            "Epoch 22/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8191.0161 - mae: 8191.0161 - val_loss: 8019.7881 - val_mae: 8019.7881\n",
            "Epoch 23/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7935.4404 - mae: 7935.4404 - val_loss: 7845.5020 - val_mae: 7845.5020\n",
            "Epoch 24/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7734.5376 - mae: 7734.5376 - val_loss: 7697.9971 - val_mae: 7697.9971\n",
            "Epoch 25/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7569.3535 - mae: 7569.3535 - val_loss: 7572.7368 - val_mae: 7572.7368\n",
            "Epoch 26/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7441.0928 - mae: 7441.0928 - val_loss: 7468.6416 - val_mae: 7468.6416\n",
            "Epoch 27/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7331.9619 - mae: 7331.9619 - val_loss: 7374.0137 - val_mae: 7374.0137\n",
            "Epoch 28/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7237.0317 - mae: 7237.0317 - val_loss: 7286.5181 - val_mae: 7286.5181\n",
            "Epoch 29/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7149.1689 - mae: 7149.1689 - val_loss: 7197.7070 - val_mae: 7197.7070\n",
            "Epoch 30/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7064.1636 - mae: 7064.1636 - val_loss: 7111.1528 - val_mae: 7111.1528\n",
            "Epoch 31/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6982.2910 - mae: 6982.2910 - val_loss: 7018.8384 - val_mae: 7018.8384\n",
            "Epoch 32/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6899.9141 - mae: 6899.9141 - val_loss: 6927.6553 - val_mae: 6927.6553\n",
            "Epoch 33/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6817.7070 - mae: 6817.7070 - val_loss: 6834.3687 - val_mae: 6834.3687\n",
            "Epoch 34/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6734.4814 - mae: 6734.4814 - val_loss: 6740.9893 - val_mae: 6740.9893\n",
            "Epoch 35/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6650.1333 - mae: 6650.1333 - val_loss: 6644.1055 - val_mae: 6644.1055\n",
            "Epoch 36/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6564.2397 - mae: 6564.2397 - val_loss: 6543.6548 - val_mae: 6543.6548\n",
            "Epoch 37/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6477.2495 - mae: 6477.2495 - val_loss: 6443.3022 - val_mae: 6443.3022\n",
            "Epoch 38/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6387.8843 - mae: 6387.8843 - val_loss: 6339.3716 - val_mae: 6339.3716\n",
            "Epoch 39/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6296.7119 - mae: 6296.7119 - val_loss: 6231.5200 - val_mae: 6231.5200\n",
            "Epoch 40/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6204.0098 - mae: 6204.0098 - val_loss: 6124.3496 - val_mae: 6124.3496\n",
            "Epoch 41/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6109.0547 - mae: 6109.0547 - val_loss: 6020.2354 - val_mae: 6020.2354\n",
            "Epoch 42/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6017.3525 - mae: 6017.3525 - val_loss: 5920.7690 - val_mae: 5920.7690\n",
            "Epoch 43/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5929.1948 - mae: 5929.1948 - val_loss: 5828.3867 - val_mae: 5828.3867\n",
            "Epoch 44/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5851.1450 - mae: 5851.1450 - val_loss: 5741.3657 - val_mae: 5741.3657\n",
            "Epoch 45/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5783.5869 - mae: 5783.5869 - val_loss: 5667.1406 - val_mae: 5667.1406\n",
            "Epoch 46/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5726.0894 - mae: 5726.0894 - val_loss: 5598.4946 - val_mae: 5598.4946\n",
            "Epoch 47/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5672.6689 - mae: 5672.6689 - val_loss: 5544.2788 - val_mae: 5544.2788\n",
            "Epoch 48/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5625.7505 - mae: 5625.7505 - val_loss: 5490.7075 - val_mae: 5490.7075\n",
            "Epoch 49/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5577.2651 - mae: 5577.2651 - val_loss: 5442.6836 - val_mae: 5442.6836\n",
            "Epoch 50/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5531.0249 - mae: 5531.0249 - val_loss: 5393.5625 - val_mae: 5393.5625\n",
            "Epoch 51/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5484.2104 - mae: 5484.2104 - val_loss: 5342.5054 - val_mae: 5342.5054\n",
            "Epoch 52/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5435.7773 - mae: 5435.7773 - val_loss: 5293.4790 - val_mae: 5293.4790\n",
            "Epoch 53/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5385.5830 - mae: 5385.5830 - val_loss: 5241.7295 - val_mae: 5241.7295\n",
            "Epoch 54/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5334.6807 - mae: 5334.6807 - val_loss: 5189.4448 - val_mae: 5189.4448\n",
            "Epoch 55/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5282.1987 - mae: 5282.1987 - val_loss: 5134.6235 - val_mae: 5134.6235\n",
            "Epoch 56/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5228.4688 - mae: 5228.4688 - val_loss: 5078.9771 - val_mae: 5078.9771\n",
            "Epoch 57/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5171.5024 - mae: 5171.5024 - val_loss: 5021.9341 - val_mae: 5021.9341\n",
            "Epoch 58/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5113.2773 - mae: 5113.2773 - val_loss: 4962.8755 - val_mae: 4962.8755\n",
            "Epoch 59/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5051.5820 - mae: 5051.5820 - val_loss: 4906.6128 - val_mae: 4906.6128\n",
            "Epoch 60/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4990.7153 - mae: 4990.7153 - val_loss: 4841.3486 - val_mae: 4841.3486\n",
            "Epoch 61/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4923.6309 - mae: 4923.6309 - val_loss: 4776.4458 - val_mae: 4776.4458\n",
            "Epoch 62/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4855.9819 - mae: 4855.9819 - val_loss: 4706.5400 - val_mae: 4706.5400\n",
            "Epoch 63/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4783.9180 - mae: 4783.9180 - val_loss: 4634.1787 - val_mae: 4634.1787\n",
            "Epoch 64/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4711.7900 - mae: 4711.7900 - val_loss: 4556.3770 - val_mae: 4556.3770\n",
            "Epoch 65/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4634.1538 - mae: 4634.1538 - val_loss: 4479.6045 - val_mae: 4479.6045\n",
            "Epoch 66/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4553.4365 - mae: 4553.4365 - val_loss: 4402.6548 - val_mae: 4402.6548\n",
            "Epoch 67/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4471.8457 - mae: 4471.8457 - val_loss: 4313.0137 - val_mae: 4313.0137\n",
            "Epoch 68/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4383.7070 - mae: 4383.7070 - val_loss: 4231.7183 - val_mae: 4231.7183\n",
            "Epoch 69/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4302.7520 - mae: 4302.7520 - val_loss: 4149.0698 - val_mae: 4149.0698\n",
            "Epoch 70/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4221.8101 - mae: 4221.8101 - val_loss: 4060.0779 - val_mae: 4060.0779\n",
            "Epoch 71/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4136.3984 - mae: 4136.3984 - val_loss: 3973.3879 - val_mae: 3973.3879\n",
            "Epoch 72/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4052.9304 - mae: 4052.9304 - val_loss: 3885.6196 - val_mae: 3885.6196\n",
            "Epoch 73/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3974.2612 - mae: 3974.2612 - val_loss: 3800.9414 - val_mae: 3800.9414\n",
            "Epoch 74/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3903.1082 - mae: 3903.1082 - val_loss: 3719.2390 - val_mae: 3719.2390\n",
            "Epoch 75/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3837.6406 - mae: 3837.6406 - val_loss: 3646.6516 - val_mae: 3646.6516\n",
            "Epoch 76/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3781.6113 - mae: 3781.6113 - val_loss: 3591.5117 - val_mae: 3591.5117\n",
            "Epoch 77/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3737.5574 - mae: 3737.5574 - val_loss: 3548.9841 - val_mae: 3548.9841\n",
            "Epoch 78/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3699.9128 - mae: 3699.9128 - val_loss: 3508.1792 - val_mae: 3508.1792\n",
            "Epoch 79/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3663.2476 - mae: 3663.2476 - val_loss: 3474.7632 - val_mae: 3474.7632\n",
            "Epoch 80/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3636.8508 - mae: 3636.8508 - val_loss: 3445.9307 - val_mae: 3445.9307\n",
            "Epoch 81/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3613.4412 - mae: 3613.4412 - val_loss: 3417.1104 - val_mae: 3417.1104\n",
            "Epoch 82/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3590.4978 - mae: 3590.4978 - val_loss: 3393.4841 - val_mae: 3393.4841\n",
            "Epoch 83/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3571.5842 - mae: 3571.5842 - val_loss: 3379.6865 - val_mae: 3379.6865\n",
            "Epoch 84/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3555.4331 - mae: 3555.4331 - val_loss: 3361.4121 - val_mae: 3361.4121\n",
            "Epoch 85/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3541.7512 - mae: 3541.7512 - val_loss: 3348.0620 - val_mae: 3348.0620\n",
            "Epoch 86/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3529.3179 - mae: 3529.3179 - val_loss: 3335.1873 - val_mae: 3335.1873\n",
            "Epoch 87/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3518.7461 - mae: 3518.7461 - val_loss: 3325.1765 - val_mae: 3325.1765\n",
            "Epoch 88/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3508.6887 - mae: 3508.6887 - val_loss: 3315.6250 - val_mae: 3315.6250\n",
            "Epoch 89/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3498.8235 - mae: 3498.8235 - val_loss: 3306.0286 - val_mae: 3306.0286\n",
            "Epoch 90/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3490.6357 - mae: 3490.6357 - val_loss: 3296.2395 - val_mae: 3296.2395\n",
            "Epoch 91/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3481.5681 - mae: 3481.5681 - val_loss: 3290.4834 - val_mae: 3290.4834\n",
            "Epoch 92/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3475.6052 - mae: 3475.6052 - val_loss: 3281.7612 - val_mae: 3281.7612\n",
            "Epoch 93/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3468.2104 - mae: 3468.2104 - val_loss: 3276.9324 - val_mae: 3276.9324\n",
            "Epoch 94/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3464.3948 - mae: 3464.3948 - val_loss: 3269.1636 - val_mae: 3269.1636\n",
            "Epoch 95/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3456.3525 - mae: 3456.3525 - val_loss: 3261.7754 - val_mae: 3261.7754\n",
            "Epoch 96/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3450.0391 - mae: 3450.0391 - val_loss: 3256.4707 - val_mae: 3256.4707\n",
            "Epoch 97/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3446.9734 - mae: 3446.9734 - val_loss: 3252.4585 - val_mae: 3252.4585\n",
            "Epoch 98/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3441.9348 - mae: 3441.9348 - val_loss: 3248.4395 - val_mae: 3248.4395\n",
            "Epoch 99/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3436.9185 - mae: 3436.9185 - val_loss: 3243.3203 - val_mae: 3243.3203\n",
            "Epoch 100/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3433.3396 - mae: 3433.3396 - val_loss: 3238.1511 - val_mae: 3238.1511\n",
            "Epoch 101/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3429.8909 - mae: 3429.8909 - val_loss: 3233.8616 - val_mae: 3233.8616\n",
            "Epoch 102/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3425.0415 - mae: 3425.0415 - val_loss: 3229.8154 - val_mae: 3229.8154\n",
            "Epoch 103/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3422.5798 - mae: 3422.5798 - val_loss: 3225.5967 - val_mae: 3225.5967\n",
            "Epoch 104/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3417.5994 - mae: 3417.5994 - val_loss: 3219.9575 - val_mae: 3219.9575\n",
            "Epoch 105/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3414.7688 - mae: 3414.7688 - val_loss: 3214.2334 - val_mae: 3214.2334\n",
            "Epoch 106/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3410.0388 - mae: 3410.0388 - val_loss: 3209.9485 - val_mae: 3209.9485\n",
            "Epoch 107/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3406.9148 - mae: 3406.9148 - val_loss: 3204.4043 - val_mae: 3204.4043\n",
            "Epoch 108/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3402.2485 - mae: 3402.2485 - val_loss: 3200.9189 - val_mae: 3200.9189\n",
            "Epoch 109/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3399.0186 - mae: 3399.0186 - val_loss: 3196.7888 - val_mae: 3196.7888\n",
            "Epoch 110/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3396.4939 - mae: 3396.4939 - val_loss: 3192.1875 - val_mae: 3192.1875\n",
            "Epoch 111/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3391.2341 - mae: 3391.2341 - val_loss: 3186.5518 - val_mae: 3186.5518\n",
            "Epoch 112/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3388.9824 - mae: 3388.9824 - val_loss: 3182.7766 - val_mae: 3182.7766\n",
            "Epoch 113/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3385.4172 - mae: 3385.4172 - val_loss: 3177.3022 - val_mae: 3177.3022\n",
            "Epoch 114/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3381.5840 - mae: 3381.5840 - val_loss: 3173.4016 - val_mae: 3173.4016\n",
            "Epoch 115/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3378.4653 - mae: 3378.4653 - val_loss: 3168.0034 - val_mae: 3168.0034\n",
            "Epoch 116/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3374.4358 - mae: 3374.4358 - val_loss: 3164.5972 - val_mae: 3164.5972\n",
            "Epoch 117/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3370.6047 - mae: 3370.6047 - val_loss: 3160.2556 - val_mae: 3160.2556\n",
            "Epoch 118/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3366.3313 - mae: 3366.3313 - val_loss: 3154.6150 - val_mae: 3154.6150\n",
            "Epoch 119/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3362.8813 - mae: 3362.8813 - val_loss: 3147.0857 - val_mae: 3147.0857\n",
            "Epoch 120/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3359.4854 - mae: 3359.4854 - val_loss: 3143.9883 - val_mae: 3143.9883\n",
            "Epoch 121/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3356.4856 - mae: 3356.4856 - val_loss: 3137.4036 - val_mae: 3137.4036\n",
            "Epoch 122/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3351.2915 - mae: 3351.2915 - val_loss: 3132.4595 - val_mae: 3132.4595\n",
            "Epoch 123/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3347.7537 - mae: 3347.7537 - val_loss: 3129.4600 - val_mae: 3129.4600\n",
            "Epoch 124/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3344.8579 - mae: 3344.8579 - val_loss: 3121.3462 - val_mae: 3121.3462\n",
            "Epoch 125/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3339.9866 - mae: 3339.9866 - val_loss: 3118.7263 - val_mae: 3118.7263\n",
            "Epoch 126/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3337.3870 - mae: 3337.3870 - val_loss: 3114.5168 - val_mae: 3114.5168\n",
            "Epoch 127/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3332.5791 - mae: 3332.5791 - val_loss: 3109.5540 - val_mae: 3109.5540\n",
            "Epoch 128/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3330.6260 - mae: 3330.6260 - val_loss: 3105.0352 - val_mae: 3105.0352\n",
            "Epoch 129/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3327.2063 - mae: 3327.2063 - val_loss: 3097.4468 - val_mae: 3097.4468\n",
            "Epoch 130/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3324.1038 - mae: 3324.1038 - val_loss: 3096.9910 - val_mae: 3096.9910\n",
            "Epoch 131/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3320.9880 - mae: 3320.9880 - val_loss: 3094.1238 - val_mae: 3094.1238\n",
            "Epoch 132/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3318.0574 - mae: 3318.0574 - val_loss: 3086.1863 - val_mae: 3086.1863\n",
            "Epoch 133/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3313.2529 - mae: 3313.2529 - val_loss: 3081.4648 - val_mae: 3081.4648\n",
            "Epoch 134/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3311.4490 - mae: 3311.4490 - val_loss: 3080.3008 - val_mae: 3080.3008\n",
            "Epoch 135/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3308.3801 - mae: 3308.3801 - val_loss: 3075.6602 - val_mae: 3075.6602\n",
            "Epoch 136/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3305.3000 - mae: 3305.3000 - val_loss: 3070.0605 - val_mae: 3070.0605\n",
            "Epoch 137/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3302.4958 - mae: 3302.4958 - val_loss: 3067.0808 - val_mae: 3067.0808\n",
            "Epoch 138/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3299.9905 - mae: 3299.9905 - val_loss: 3065.2751 - val_mae: 3065.2751\n",
            "Epoch 139/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3296.0776 - mae: 3296.0776 - val_loss: 3058.9062 - val_mae: 3058.9062\n",
            "Epoch 140/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3293.4646 - mae: 3293.4646 - val_loss: 3057.8494 - val_mae: 3057.8494\n",
            "Epoch 141/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3291.3386 - mae: 3291.3386 - val_loss: 3051.5696 - val_mae: 3051.5696\n",
            "Epoch 142/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3288.2688 - mae: 3288.2688 - val_loss: 3047.8289 - val_mae: 3047.8289\n",
            "Epoch 143/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3284.7551 - mae: 3284.7551 - val_loss: 3041.5884 - val_mae: 3041.5884\n",
            "Epoch 144/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3281.1558 - mae: 3281.1558 - val_loss: 3038.0991 - val_mae: 3038.0991\n",
            "Epoch 145/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3278.8523 - mae: 3278.8523 - val_loss: 3030.8809 - val_mae: 3030.8809\n",
            "Epoch 146/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3275.1335 - mae: 3275.1335 - val_loss: 3029.1565 - val_mae: 3029.1565\n",
            "Epoch 147/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3271.7327 - mae: 3271.7327 - val_loss: 3026.3308 - val_mae: 3026.3308\n",
            "Epoch 148/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3269.6450 - mae: 3269.6450 - val_loss: 3020.0598 - val_mae: 3020.0598\n",
            "Epoch 149/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3264.6731 - mae: 3264.6731 - val_loss: 3014.7715 - val_mae: 3014.7715\n",
            "Epoch 150/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3261.6052 - mae: 3261.6052 - val_loss: 3008.0330 - val_mae: 3008.0330\n",
            "Epoch 151/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3257.8167 - mae: 3257.8167 - val_loss: 3006.3567 - val_mae: 3006.3567\n",
            "Epoch 152/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3256.1602 - mae: 3256.1602 - val_loss: 3001.6565 - val_mae: 3001.6565\n",
            "Epoch 153/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3253.9089 - mae: 3253.9089 - val_loss: 2998.4058 - val_mae: 2998.4058\n",
            "Epoch 154/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3251.1880 - mae: 3251.1880 - val_loss: 2992.0784 - val_mae: 2992.0784\n",
            "Epoch 155/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3246.9434 - mae: 3246.9434 - val_loss: 2986.7871 - val_mae: 2986.7871\n",
            "Epoch 156/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3244.1328 - mae: 3244.1328 - val_loss: 2982.8374 - val_mae: 2982.8374\n",
            "Epoch 157/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3240.9841 - mae: 3240.9841 - val_loss: 2980.1987 - val_mae: 2980.1987\n",
            "Epoch 158/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3238.6167 - mae: 3238.6167 - val_loss: 2974.1167 - val_mae: 2974.1167\n",
            "Epoch 159/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3234.7908 - mae: 3234.7908 - val_loss: 2971.2852 - val_mae: 2971.2852\n",
            "Epoch 160/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3230.9348 - mae: 3230.9348 - val_loss: 2964.2075 - val_mae: 2964.2075\n",
            "Epoch 161/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3228.8562 - mae: 3228.8562 - val_loss: 2966.1738 - val_mae: 2966.1738\n",
            "Epoch 162/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3225.4146 - mae: 3225.4146 - val_loss: 2954.3413 - val_mae: 2954.3413\n",
            "Epoch 163/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3220.3906 - mae: 3220.3906 - val_loss: 2950.0303 - val_mae: 2950.0303\n",
            "Epoch 164/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3217.1404 - mae: 3217.1404 - val_loss: 2947.8242 - val_mae: 2947.8242\n",
            "Epoch 165/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3213.9204 - mae: 3213.9204 - val_loss: 2938.5828 - val_mae: 2938.5828\n",
            "Epoch 166/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3211.3364 - mae: 3211.3364 - val_loss: 2936.5835 - val_mae: 2936.5835\n",
            "Epoch 167/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3208.3752 - mae: 3208.3752 - val_loss: 2930.6946 - val_mae: 2930.6946\n",
            "Epoch 168/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3203.0437 - mae: 3203.0437 - val_loss: 2925.2219 - val_mae: 2925.2219\n",
            "Epoch 169/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3199.2163 - mae: 3199.2163 - val_loss: 2919.3423 - val_mae: 2919.3423\n",
            "Epoch 170/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3194.5820 - mae: 3194.5820 - val_loss: 2912.8750 - val_mae: 2912.8750\n",
            "Epoch 171/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3190.5154 - mae: 3190.5154 - val_loss: 2908.0176 - val_mae: 2908.0176\n",
            "Epoch 172/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3185.4895 - mae: 3185.4895 - val_loss: 2900.7300 - val_mae: 2900.7300\n",
            "Epoch 173/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3181.6567 - mae: 3181.6567 - val_loss: 2894.7100 - val_mae: 2894.7100\n",
            "Epoch 174/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3177.0059 - mae: 3177.0059 - val_loss: 2889.3848 - val_mae: 2889.3848\n",
            "Epoch 175/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3173.7983 - mae: 3173.7983 - val_loss: 2882.7507 - val_mae: 2882.7507\n",
            "Epoch 176/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3170.0132 - mae: 3170.0132 - val_loss: 2878.0811 - val_mae: 2878.0811\n",
            "Epoch 177/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3166.6606 - mae: 3166.6606 - val_loss: 2871.5273 - val_mae: 2871.5273\n",
            "Epoch 178/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3161.6248 - mae: 3161.6248 - val_loss: 2868.2239 - val_mae: 2868.2239\n",
            "Epoch 179/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3159.6841 - mae: 3159.6841 - val_loss: 2861.1006 - val_mae: 2861.1006\n",
            "Epoch 180/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3155.2808 - mae: 3155.2808 - val_loss: 2854.6650 - val_mae: 2854.6650\n",
            "Epoch 181/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3150.8992 - mae: 3150.8992 - val_loss: 2848.9072 - val_mae: 2848.9072\n",
            "Epoch 182/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3146.5471 - mae: 3146.5471 - val_loss: 2848.7188 - val_mae: 2848.7188\n",
            "Epoch 183/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3143.0928 - mae: 3143.0928 - val_loss: 2837.1956 - val_mae: 2837.1956\n",
            "Epoch 184/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3139.3755 - mae: 3139.3755 - val_loss: 2836.2798 - val_mae: 2836.2798\n",
            "Epoch 185/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3135.0439 - mae: 3135.0439 - val_loss: 2826.5161 - val_mae: 2826.5161\n",
            "Epoch 186/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3130.3110 - mae: 3130.3110 - val_loss: 2820.8303 - val_mae: 2820.8303\n",
            "Epoch 187/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3127.1245 - mae: 3127.1245 - val_loss: 2813.8628 - val_mae: 2813.8628\n",
            "Epoch 188/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3121.5024 - mae: 3121.5024 - val_loss: 2809.5229 - val_mae: 2809.5229\n",
            "Epoch 189/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3118.3748 - mae: 3118.3748 - val_loss: 2803.0591 - val_mae: 2803.0591\n",
            "Epoch 190/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3113.5071 - mae: 3113.5071 - val_loss: 2796.7285 - val_mae: 2796.7285\n",
            "Epoch 191/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3110.3342 - mae: 3110.3342 - val_loss: 2794.5979 - val_mae: 2794.5979\n",
            "Epoch 192/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3106.0742 - mae: 3106.0742 - val_loss: 2784.6289 - val_mae: 2784.6289\n",
            "Epoch 193/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3101.3799 - mae: 3101.3799 - val_loss: 2779.5015 - val_mae: 2779.5015\n",
            "Epoch 194/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3096.1104 - mae: 3096.1104 - val_loss: 2774.9114 - val_mae: 2774.9114\n",
            "Epoch 195/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3093.3694 - mae: 3093.3694 - val_loss: 2770.2273 - val_mae: 2770.2273\n",
            "Epoch 196/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3089.3599 - mae: 3089.3599 - val_loss: 2766.3706 - val_mae: 2766.3706\n",
            "Epoch 197/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3086.1946 - mae: 3086.1946 - val_loss: 2761.8218 - val_mae: 2761.8218\n",
            "Epoch 198/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3082.2439 - mae: 3082.2439 - val_loss: 2758.7864 - val_mae: 2758.7864\n",
            "Epoch 199/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3079.1104 - mae: 3079.1104 - val_loss: 2753.9402 - val_mae: 2753.9402\n",
            "Epoch 200/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3076.9451 - mae: 3076.9451 - val_loss: 2753.0601 - val_mae: 2753.0601\n",
            "Epoch 201/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3075.2764 - mae: 3075.2764 - val_loss: 2749.3345 - val_mae: 2749.3345\n",
            "Epoch 202/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3071.0217 - mae: 3071.0217 - val_loss: 2744.5474 - val_mae: 2744.5474\n",
            "Epoch 203/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3069.1045 - mae: 3069.1045 - val_loss: 2743.6021 - val_mae: 2743.6021\n",
            "Epoch 204/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3066.2793 - mae: 3066.2793 - val_loss: 2738.5129 - val_mae: 2738.5129\n",
            "Epoch 205/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3062.5190 - mae: 3062.5190 - val_loss: 2735.5217 - val_mae: 2735.5217\n",
            "Epoch 206/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3059.1787 - mae: 3059.1787 - val_loss: 2732.9402 - val_mae: 2732.9402\n",
            "Epoch 207/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3056.4854 - mae: 3056.4854 - val_loss: 2730.0791 - val_mae: 2730.0791\n",
            "Epoch 208/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3054.4170 - mae: 3054.4170 - val_loss: 2726.2930 - val_mae: 2726.2930\n",
            "Epoch 209/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3049.9585 - mae: 3049.9585 - val_loss: 2723.9697 - val_mae: 2723.9697\n",
            "Epoch 210/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3047.2876 - mae: 3047.2876 - val_loss: 2719.5127 - val_mae: 2719.5127\n",
            "Epoch 211/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3044.3115 - mae: 3044.3115 - val_loss: 2717.2327 - val_mae: 2717.2327\n",
            "Epoch 212/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3041.4438 - mae: 3041.4438 - val_loss: 2715.0991 - val_mae: 2715.0991\n",
            "Epoch 213/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3039.5459 - mae: 3039.5459 - val_loss: 2712.8867 - val_mae: 2712.8867\n",
            "Epoch 214/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3034.8254 - mae: 3034.8254 - val_loss: 2708.2224 - val_mae: 2708.2224\n",
            "Epoch 215/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3031.4751 - mae: 3031.4751 - val_loss: 2705.0984 - val_mae: 2705.0984\n",
            "Epoch 216/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3028.9707 - mae: 3028.9707 - val_loss: 2700.6096 - val_mae: 2700.6096\n",
            "Epoch 217/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3025.3005 - mae: 3025.3005 - val_loss: 2699.2136 - val_mae: 2699.2136\n",
            "Epoch 218/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3022.9346 - mae: 3022.9346 - val_loss: 2695.1299 - val_mae: 2695.1299\n",
            "Epoch 219/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3021.5681 - mae: 3021.5681 - val_loss: 2696.5078 - val_mae: 2696.5078\n",
            "Epoch 220/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3015.2395 - mae: 3015.2395 - val_loss: 2690.1328 - val_mae: 2690.1328\n",
            "Epoch 221/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3011.9949 - mae: 3011.9949 - val_loss: 2684.3203 - val_mae: 2684.3203\n",
            "Epoch 222/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3008.3311 - mae: 3008.3311 - val_loss: 2680.9817 - val_mae: 2680.9817\n",
            "Epoch 223/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3004.9277 - mae: 3004.9277 - val_loss: 2678.5552 - val_mae: 2678.5552\n",
            "Epoch 224/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3002.8718 - mae: 3002.8718 - val_loss: 2677.7952 - val_mae: 2677.7952\n",
            "Epoch 225/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2999.6252 - mae: 2999.6252 - val_loss: 2672.0522 - val_mae: 2672.0522\n",
            "Epoch 226/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2995.4507 - mae: 2995.4507 - val_loss: 2672.0842 - val_mae: 2672.0842\n",
            "Epoch 227/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2991.7146 - mae: 2991.7146 - val_loss: 2669.1370 - val_mae: 2669.1370\n",
            "Epoch 228/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2987.5283 - mae: 2987.5283 - val_loss: 2662.2708 - val_mae: 2662.2708\n",
            "Epoch 229/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2982.8555 - mae: 2982.8555 - val_loss: 2659.4866 - val_mae: 2659.4866\n",
            "Epoch 230/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2981.2803 - mae: 2981.2803 - val_loss: 2653.1978 - val_mae: 2653.1978\n",
            "Epoch 231/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2976.9800 - mae: 2976.9800 - val_loss: 2652.7048 - val_mae: 2652.7048\n",
            "Epoch 232/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2973.2815 - mae: 2973.2815 - val_loss: 2646.2554 - val_mae: 2646.2554\n",
            "Epoch 233/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2972.2644 - mae: 2972.2644 - val_loss: 2645.5754 - val_mae: 2645.5754\n",
            "Epoch 234/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2965.3833 - mae: 2965.3833 - val_loss: 2638.8398 - val_mae: 2638.8398\n",
            "Epoch 235/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2961.6067 - mae: 2961.6067 - val_loss: 2637.2393 - val_mae: 2637.2393\n",
            "Epoch 236/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2957.8354 - mae: 2957.8354 - val_loss: 2630.7378 - val_mae: 2630.7378\n",
            "Epoch 237/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2953.9509 - mae: 2953.9509 - val_loss: 2626.7305 - val_mae: 2626.7305\n",
            "Epoch 238/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2949.6365 - mae: 2949.6365 - val_loss: 2624.2598 - val_mae: 2624.2598\n",
            "Epoch 239/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2947.2883 - mae: 2947.2883 - val_loss: 2621.8909 - val_mae: 2621.8909\n",
            "Epoch 240/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2941.5000 - mae: 2941.5000 - val_loss: 2615.5129 - val_mae: 2615.5129\n",
            "Epoch 241/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2938.8569 - mae: 2938.8569 - val_loss: 2612.6331 - val_mae: 2612.6331\n",
            "Epoch 242/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2936.5310 - mae: 2936.5310 - val_loss: 2611.0471 - val_mae: 2611.0471\n",
            "Epoch 243/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2931.6560 - mae: 2931.6560 - val_loss: 2605.0227 - val_mae: 2605.0227\n",
            "Epoch 244/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2925.9734 - mae: 2925.9734 - val_loss: 2600.5132 - val_mae: 2600.5132\n",
            "Epoch 245/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2921.6953 - mae: 2921.6953 - val_loss: 2594.2773 - val_mae: 2594.2773\n",
            "Epoch 246/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2918.3289 - mae: 2918.3289 - val_loss: 2591.8870 - val_mae: 2591.8870\n",
            "Epoch 247/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2914.7505 - mae: 2914.7505 - val_loss: 2587.4922 - val_mae: 2587.4922\n",
            "Epoch 248/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2911.2163 - mae: 2911.2163 - val_loss: 2583.8525 - val_mae: 2583.8525\n",
            "Epoch 249/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2905.9570 - mae: 2905.9570 - val_loss: 2579.5234 - val_mae: 2579.5234\n",
            "Epoch 250/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2901.9473 - mae: 2901.9473 - val_loss: 2575.6667 - val_mae: 2575.6667\n",
            "Epoch 251/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2897.1814 - mae: 2897.1814 - val_loss: 2572.2422 - val_mae: 2572.2422\n",
            "Epoch 252/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2893.6565 - mae: 2893.6565 - val_loss: 2568.5085 - val_mae: 2568.5085\n",
            "Epoch 253/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2889.8186 - mae: 2889.8186 - val_loss: 2561.7146 - val_mae: 2561.7146\n",
            "Epoch 254/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2884.4775 - mae: 2884.4775 - val_loss: 2557.7986 - val_mae: 2557.7986\n",
            "Epoch 255/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2880.0996 - mae: 2880.0996 - val_loss: 2554.4631 - val_mae: 2554.4631\n",
            "Epoch 256/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2875.2156 - mae: 2875.2156 - val_loss: 2553.2573 - val_mae: 2553.2573\n",
            "Epoch 257/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2872.6279 - mae: 2872.6279 - val_loss: 2544.6992 - val_mae: 2544.6992\n",
            "Epoch 258/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2867.1992 - mae: 2867.1992 - val_loss: 2544.0742 - val_mae: 2544.0742\n",
            "Epoch 259/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2862.3621 - mae: 2862.3621 - val_loss: 2539.3806 - val_mae: 2539.3806\n",
            "Epoch 260/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2858.6907 - mae: 2858.6907 - val_loss: 2536.5474 - val_mae: 2536.5474\n",
            "Epoch 261/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2854.5112 - mae: 2854.5112 - val_loss: 2531.8577 - val_mae: 2531.8577\n",
            "Epoch 262/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2849.1333 - mae: 2849.1333 - val_loss: 2526.6533 - val_mae: 2526.6533\n",
            "Epoch 263/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2844.8987 - mae: 2844.8987 - val_loss: 2522.4736 - val_mae: 2522.4736\n",
            "Epoch 264/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2840.5830 - mae: 2840.5830 - val_loss: 2517.4565 - val_mae: 2517.4565\n",
            "Epoch 265/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2836.1587 - mae: 2836.1587 - val_loss: 2514.6760 - val_mae: 2514.6760\n",
            "Epoch 266/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2830.8967 - mae: 2830.8967 - val_loss: 2509.2214 - val_mae: 2509.2214\n",
            "Epoch 267/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2826.9536 - mae: 2826.9536 - val_loss: 2507.4475 - val_mae: 2507.4475\n",
            "Epoch 268/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2823.1284 - mae: 2823.1284 - val_loss: 2502.5125 - val_mae: 2502.5125\n",
            "Epoch 269/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2818.6545 - mae: 2818.6545 - val_loss: 2497.6040 - val_mae: 2497.6040\n",
            "Epoch 270/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2813.7207 - mae: 2813.7207 - val_loss: 2493.7751 - val_mae: 2493.7751\n",
            "Epoch 271/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2810.6243 - mae: 2810.6243 - val_loss: 2489.1733 - val_mae: 2489.1733\n",
            "Epoch 272/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2805.4197 - mae: 2805.4197 - val_loss: 2485.3418 - val_mae: 2485.3418\n",
            "Epoch 273/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2801.1765 - mae: 2801.1765 - val_loss: 2481.2639 - val_mae: 2481.2639\n",
            "Epoch 274/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2796.5945 - mae: 2796.5945 - val_loss: 2475.8525 - val_mae: 2475.8525\n",
            "Epoch 275/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2792.2830 - mae: 2792.2830 - val_loss: 2472.8154 - val_mae: 2472.8154\n",
            "Epoch 276/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2790.8853 - mae: 2790.8853 - val_loss: 2469.3113 - val_mae: 2469.3113\n",
            "Epoch 277/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2784.6316 - mae: 2784.6316 - val_loss: 2466.3430 - val_mae: 2466.3430\n",
            "Epoch 278/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2779.6760 - mae: 2779.6760 - val_loss: 2461.6440 - val_mae: 2461.6440\n",
            "Epoch 279/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2776.3228 - mae: 2776.3228 - val_loss: 2458.2715 - val_mae: 2458.2715\n",
            "Epoch 280/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2771.5081 - mae: 2771.5081 - val_loss: 2453.4058 - val_mae: 2453.4058\n",
            "Epoch 281/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2766.8887 - mae: 2766.8887 - val_loss: 2449.2473 - val_mae: 2449.2473\n",
            "Epoch 282/1000\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 2763.9397 - mae: 2763.9397 - val_loss: 2446.5674 - val_mae: 2446.5674\n",
            "Epoch 283/1000\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 2761.5034 - mae: 2761.5034 - val_loss: 2441.4558 - val_mae: 2441.4558\n",
            "Epoch 284/1000\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2755.0444 - mae: 2755.0444 - val_loss: 2439.2549 - val_mae: 2439.2549\n",
            "Epoch 285/1000\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 2750.1560 - mae: 2750.1560 - val_loss: 2434.4207 - val_mae: 2434.4207\n",
            "Epoch 286/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2746.6704 - mae: 2746.6704 - val_loss: 2430.3918 - val_mae: 2430.3918\n",
            "Epoch 287/1000\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 2742.1726 - mae: 2742.1726 - val_loss: 2426.4717 - val_mae: 2426.4717\n",
            "Epoch 288/1000\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 2739.8645 - mae: 2739.8645 - val_loss: 2422.4468 - val_mae: 2422.4468\n",
            "Epoch 289/1000\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 2733.7788 - mae: 2733.7788 - val_loss: 2420.7837 - val_mae: 2420.7837\n",
            "Epoch 290/1000\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 2730.8828 - mae: 2730.8828 - val_loss: 2415.5078 - val_mae: 2415.5078\n",
            "Epoch 291/1000\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 2726.9048 - mae: 2726.9048 - val_loss: 2411.3240 - val_mae: 2411.3240\n",
            "Epoch 292/1000\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 2723.0378 - mae: 2723.0378 - val_loss: 2408.0837 - val_mae: 2408.0837\n",
            "Epoch 293/1000\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 2720.3928 - mae: 2720.3928 - val_loss: 2404.2427 - val_mae: 2404.2427\n",
            "Epoch 294/1000\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 2715.1616 - mae: 2715.1616 - val_loss: 2400.6421 - val_mae: 2400.6421\n",
            "Epoch 295/1000\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2711.0281 - mae: 2711.0281 - val_loss: 2397.4724 - val_mae: 2397.4724\n",
            "Epoch 296/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2708.3552 - mae: 2708.3552 - val_loss: 2394.1943 - val_mae: 2394.1943\n",
            "Epoch 297/1000\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 2704.3889 - mae: 2704.3889 - val_loss: 2394.3247 - val_mae: 2394.3247\n",
            "Epoch 298/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2701.5396 - mae: 2701.5396 - val_loss: 2389.0940 - val_mae: 2389.0940\n",
            "Epoch 299/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2698.3679 - mae: 2698.3679 - val_loss: 2384.3484 - val_mae: 2384.3484\n",
            "Epoch 300/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2694.2766 - mae: 2694.2766 - val_loss: 2381.0664 - val_mae: 2381.0664\n",
            "Epoch 301/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2689.4268 - mae: 2689.4268 - val_loss: 2379.8774 - val_mae: 2379.8774\n",
            "Epoch 302/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2686.6663 - mae: 2686.6663 - val_loss: 2374.4089 - val_mae: 2374.4089\n",
            "Epoch 303/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2683.1194 - mae: 2683.1194 - val_loss: 2372.3584 - val_mae: 2372.3584\n",
            "Epoch 304/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2680.8789 - mae: 2680.8789 - val_loss: 2368.9246 - val_mae: 2368.9246\n",
            "Epoch 305/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2676.1992 - mae: 2676.1992 - val_loss: 2366.0808 - val_mae: 2366.0808\n",
            "Epoch 306/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2674.1433 - mae: 2674.1433 - val_loss: 2361.8899 - val_mae: 2361.8899\n",
            "Epoch 307/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2669.5576 - mae: 2669.5576 - val_loss: 2359.7151 - val_mae: 2359.7151\n",
            "Epoch 308/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2667.4434 - mae: 2667.4434 - val_loss: 2356.9814 - val_mae: 2356.9814\n",
            "Epoch 309/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2664.4397 - mae: 2664.4397 - val_loss: 2353.0256 - val_mae: 2353.0256\n",
            "Epoch 310/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2660.4922 - mae: 2660.4922 - val_loss: 2351.4539 - val_mae: 2351.4539\n",
            "Epoch 311/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2658.3308 - mae: 2658.3308 - val_loss: 2350.3232 - val_mae: 2350.3232\n",
            "Epoch 312/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2654.6274 - mae: 2654.6274 - val_loss: 2346.3252 - val_mae: 2346.3252\n",
            "Epoch 313/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2651.5352 - mae: 2651.5352 - val_loss: 2341.8203 - val_mae: 2341.8203\n",
            "Epoch 314/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2647.5520 - mae: 2647.5520 - val_loss: 2339.5349 - val_mae: 2339.5349\n",
            "Epoch 315/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2644.5686 - mae: 2644.5686 - val_loss: 2334.1086 - val_mae: 2334.1086\n",
            "Epoch 316/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2640.3650 - mae: 2640.3650 - val_loss: 2331.6365 - val_mae: 2331.6365\n",
            "Epoch 317/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2637.6672 - mae: 2637.6672 - val_loss: 2328.6956 - val_mae: 2328.6956\n",
            "Epoch 318/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2634.8723 - mae: 2634.8723 - val_loss: 2326.1519 - val_mae: 2326.1519\n",
            "Epoch 319/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2630.5625 - mae: 2630.5625 - val_loss: 2322.2852 - val_mae: 2322.2852\n",
            "Epoch 320/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2626.4885 - mae: 2626.4885 - val_loss: 2320.8572 - val_mae: 2320.8572\n",
            "Epoch 321/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2623.5916 - mae: 2623.5916 - val_loss: 2316.5767 - val_mae: 2316.5767\n",
            "Epoch 322/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2619.7524 - mae: 2619.7524 - val_loss: 2311.2275 - val_mae: 2311.2275\n",
            "Epoch 323/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2616.1223 - mae: 2616.1223 - val_loss: 2309.8694 - val_mae: 2309.8694\n",
            "Epoch 324/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2614.1382 - mae: 2614.1382 - val_loss: 2310.5078 - val_mae: 2310.5078\n",
            "Epoch 325/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2614.0142 - mae: 2614.0142 - val_loss: 2304.4417 - val_mae: 2304.4417\n",
            "Epoch 326/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2607.7412 - mae: 2607.7412 - val_loss: 2300.9724 - val_mae: 2300.9724\n",
            "Epoch 327/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2603.8513 - mae: 2603.8513 - val_loss: 2297.7373 - val_mae: 2297.7373\n",
            "Epoch 328/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2598.9502 - mae: 2598.9502 - val_loss: 2294.8147 - val_mae: 2294.8147\n",
            "Epoch 329/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2596.6504 - mae: 2596.6504 - val_loss: 2295.1318 - val_mae: 2295.1318\n",
            "Epoch 330/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2592.2827 - mae: 2592.2827 - val_loss: 2289.1077 - val_mae: 2289.1077\n",
            "Epoch 331/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2589.9175 - mae: 2589.9175 - val_loss: 2287.4746 - val_mae: 2287.4746\n",
            "Epoch 332/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2585.0239 - mae: 2585.0239 - val_loss: 2285.6272 - val_mae: 2285.6272\n",
            "Epoch 333/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2581.9236 - mae: 2581.9236 - val_loss: 2282.0850 - val_mae: 2282.0850\n",
            "Epoch 334/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2578.5940 - mae: 2578.5940 - val_loss: 2281.8103 - val_mae: 2281.8103\n",
            "Epoch 335/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2576.6523 - mae: 2576.6523 - val_loss: 2277.7815 - val_mae: 2277.7815\n",
            "Epoch 336/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2570.6477 - mae: 2570.6477 - val_loss: 2273.2468 - val_mae: 2273.2468\n",
            "Epoch 337/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2567.4614 - mae: 2567.4614 - val_loss: 2271.3662 - val_mae: 2271.3662\n",
            "Epoch 338/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2563.7598 - mae: 2563.7598 - val_loss: 2270.0276 - val_mae: 2270.0276\n",
            "Epoch 339/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2560.7461 - mae: 2560.7461 - val_loss: 2268.8921 - val_mae: 2268.8921\n",
            "Epoch 340/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2557.8398 - mae: 2557.8398 - val_loss: 2266.0994 - val_mae: 2266.0994\n",
            "Epoch 341/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2554.4170 - mae: 2554.4170 - val_loss: 2262.2888 - val_mae: 2262.2888\n",
            "Epoch 342/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2550.2383 - mae: 2550.2383 - val_loss: 2258.6797 - val_mae: 2258.6797\n",
            "Epoch 343/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2547.2617 - mae: 2547.2617 - val_loss: 2259.2424 - val_mae: 2259.2424\n",
            "Epoch 344/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2543.1316 - mae: 2543.1316 - val_loss: 2253.8538 - val_mae: 2253.8538\n",
            "Epoch 345/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2541.3135 - mae: 2541.3135 - val_loss: 2251.2607 - val_mae: 2251.2607\n",
            "Epoch 346/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2539.1394 - mae: 2539.1394 - val_loss: 2248.7007 - val_mae: 2248.7007\n",
            "Epoch 347/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2535.9165 - mae: 2535.9165 - val_loss: 2243.3574 - val_mae: 2243.3574\n",
            "Epoch 348/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2530.8171 - mae: 2530.8171 - val_loss: 2241.2795 - val_mae: 2241.2795\n",
            "Epoch 349/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2528.1416 - mae: 2528.1416 - val_loss: 2240.3794 - val_mae: 2240.3794\n",
            "Epoch 350/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2525.3347 - mae: 2525.3347 - val_loss: 2239.8464 - val_mae: 2239.8464\n",
            "Epoch 351/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2522.4915 - mae: 2522.4915 - val_loss: 2235.3362 - val_mae: 2235.3362\n",
            "Epoch 352/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2518.6580 - mae: 2518.6580 - val_loss: 2234.3250 - val_mae: 2234.3250\n",
            "Epoch 353/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2516.1252 - mae: 2516.1252 - val_loss: 2230.9790 - val_mae: 2230.9790\n",
            "Epoch 354/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2512.0691 - mae: 2512.0691 - val_loss: 2227.1350 - val_mae: 2227.1350\n",
            "Epoch 355/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2510.9033 - mae: 2510.9033 - val_loss: 2227.5916 - val_mae: 2227.5916\n",
            "Epoch 356/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2507.3748 - mae: 2507.3748 - val_loss: 2222.9199 - val_mae: 2222.9199\n",
            "Epoch 357/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2502.0403 - mae: 2502.0403 - val_loss: 2222.3752 - val_mae: 2222.3752\n",
            "Epoch 358/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2499.4900 - mae: 2499.4900 - val_loss: 2219.8877 - val_mae: 2219.8877\n",
            "Epoch 359/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2495.7390 - mae: 2495.7390 - val_loss: 2217.1602 - val_mae: 2217.1602\n",
            "Epoch 360/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2492.4504 - mae: 2492.4504 - val_loss: 2213.5522 - val_mae: 2213.5522\n",
            "Epoch 361/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2489.7622 - mae: 2489.7622 - val_loss: 2211.4355 - val_mae: 2211.4355\n",
            "Epoch 362/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2486.3940 - mae: 2486.3940 - val_loss: 2209.2783 - val_mae: 2209.2783\n",
            "Epoch 363/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2483.4387 - mae: 2483.4387 - val_loss: 2205.3362 - val_mae: 2205.3362\n",
            "Epoch 364/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2480.4788 - mae: 2480.4788 - val_loss: 2204.6062 - val_mae: 2204.6062\n",
            "Epoch 365/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2479.3394 - mae: 2479.3394 - val_loss: 2202.7649 - val_mae: 2202.7649\n",
            "Epoch 366/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2475.1602 - mae: 2475.1602 - val_loss: 2198.0669 - val_mae: 2198.0669\n",
            "Epoch 367/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2470.6194 - mae: 2470.6194 - val_loss: 2195.5107 - val_mae: 2195.5107\n",
            "Epoch 368/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2468.0254 - mae: 2468.0254 - val_loss: 2192.9990 - val_mae: 2192.9990\n",
            "Epoch 369/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2464.3813 - mae: 2464.3813 - val_loss: 2191.0625 - val_mae: 2191.0625\n",
            "Epoch 370/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2462.1455 - mae: 2462.1455 - val_loss: 2190.3567 - val_mae: 2190.3567\n",
            "Epoch 371/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2459.9592 - mae: 2459.9592 - val_loss: 2185.4521 - val_mae: 2185.4521\n",
            "Epoch 372/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2456.9883 - mae: 2456.9883 - val_loss: 2183.9851 - val_mae: 2183.9851\n",
            "Epoch 373/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2453.9807 - mae: 2453.9807 - val_loss: 2181.7751 - val_mae: 2181.7751\n",
            "Epoch 374/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2448.6016 - mae: 2448.6016 - val_loss: 2178.6589 - val_mae: 2178.6589\n",
            "Epoch 375/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2446.7654 - mae: 2446.7654 - val_loss: 2178.1848 - val_mae: 2178.1848\n",
            "Epoch 376/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2444.1899 - mae: 2444.1899 - val_loss: 2175.9961 - val_mae: 2175.9961\n",
            "Epoch 377/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2440.5913 - mae: 2440.5913 - val_loss: 2171.0706 - val_mae: 2171.0706\n",
            "Epoch 378/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2437.0691 - mae: 2437.0691 - val_loss: 2169.6428 - val_mae: 2169.6428\n",
            "Epoch 379/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2434.3496 - mae: 2434.3496 - val_loss: 2165.9932 - val_mae: 2165.9932\n",
            "Epoch 380/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2432.4487 - mae: 2432.4487 - val_loss: 2161.6111 - val_mae: 2161.6111\n",
            "Epoch 381/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2427.3669 - mae: 2427.3669 - val_loss: 2160.5027 - val_mae: 2160.5027\n",
            "Epoch 382/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2424.2527 - mae: 2424.2527 - val_loss: 2158.3669 - val_mae: 2158.3669\n",
            "Epoch 383/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2421.3203 - mae: 2421.3203 - val_loss: 2158.2102 - val_mae: 2158.2102\n",
            "Epoch 384/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2418.2998 - mae: 2418.2998 - val_loss: 2155.9114 - val_mae: 2155.9114\n",
            "Epoch 385/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2415.8804 - mae: 2415.8804 - val_loss: 2150.9807 - val_mae: 2150.9807\n",
            "Epoch 386/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2411.8018 - mae: 2411.8018 - val_loss: 2148.3723 - val_mae: 2148.3723\n",
            "Epoch 387/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2410.3091 - mae: 2410.3091 - val_loss: 2144.9990 - val_mae: 2144.9990\n",
            "Epoch 388/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2406.8247 - mae: 2406.8247 - val_loss: 2142.1968 - val_mae: 2142.1968\n",
            "Epoch 389/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2402.5842 - mae: 2402.5842 - val_loss: 2138.6335 - val_mae: 2138.6335\n",
            "Epoch 390/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2399.7090 - mae: 2399.7090 - val_loss: 2136.7488 - val_mae: 2136.7488\n",
            "Epoch 391/1000\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 2396.5027 - mae: 2396.5027 - val_loss: 2133.3621 - val_mae: 2133.3621\n",
            "Epoch 392/1000\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 2394.7539 - mae: 2394.7539 - val_loss: 2130.3694 - val_mae: 2130.3694\n",
            "Epoch 393/1000\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2390.7056 - mae: 2390.7056 - val_loss: 2127.2227 - val_mae: 2127.2227\n",
            "Epoch 394/1000\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 2387.5608 - mae: 2387.5608 - val_loss: 2125.2671 - val_mae: 2125.2671\n",
            "Epoch 395/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2385.6648 - mae: 2385.6648 - val_loss: 2122.5757 - val_mae: 2122.5757\n",
            "Epoch 396/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2383.0464 - mae: 2383.0464 - val_loss: 2120.4890 - val_mae: 2120.4890\n",
            "Epoch 397/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2379.7014 - mae: 2379.7014 - val_loss: 2118.6960 - val_mae: 2118.6960\n",
            "Epoch 398/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2376.5974 - mae: 2376.5974 - val_loss: 2114.9983 - val_mae: 2114.9983\n",
            "Epoch 399/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2374.1919 - mae: 2374.1919 - val_loss: 2112.7263 - val_mae: 2112.7263\n",
            "Epoch 400/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2372.4854 - mae: 2372.4854 - val_loss: 2109.9150 - val_mae: 2109.9150\n",
            "Epoch 401/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2369.1301 - mae: 2369.1301 - val_loss: 2108.6887 - val_mae: 2108.6887\n",
            "Epoch 402/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2365.4895 - mae: 2365.4895 - val_loss: 2105.9424 - val_mae: 2105.9424\n",
            "Epoch 403/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2362.7100 - mae: 2362.7100 - val_loss: 2102.4094 - val_mae: 2102.4094\n",
            "Epoch 404/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2359.8015 - mae: 2359.8015 - val_loss: 2099.5342 - val_mae: 2099.5342\n",
            "Epoch 405/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2356.4236 - mae: 2356.4236 - val_loss: 2097.9885 - val_mae: 2097.9885\n",
            "Epoch 406/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2354.0847 - mae: 2354.0847 - val_loss: 2096.0024 - val_mae: 2096.0024\n",
            "Epoch 407/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2351.2761 - mae: 2351.2761 - val_loss: 2093.5596 - val_mae: 2093.5596\n",
            "Epoch 408/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2348.6472 - mae: 2348.6472 - val_loss: 2090.4143 - val_mae: 2090.4143\n",
            "Epoch 409/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2346.6877 - mae: 2346.6877 - val_loss: 2089.9587 - val_mae: 2089.9587\n",
            "Epoch 410/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2343.6431 - mae: 2343.6431 - val_loss: 2086.2573 - val_mae: 2086.2573\n",
            "Epoch 411/1000\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 2340.2246 - mae: 2340.2246 - val_loss: 2083.6067 - val_mae: 2083.6067\n",
            "Epoch 412/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2336.8049 - mae: 2336.8049 - val_loss: 2080.1746 - val_mae: 2080.1746\n",
            "Epoch 413/1000\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 2334.6550 - mae: 2334.6550 - val_loss: 2079.6687 - val_mae: 2079.6687\n",
            "Epoch 414/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2331.3857 - mae: 2331.3857 - val_loss: 2075.4468 - val_mae: 2075.4468\n",
            "Epoch 415/1000\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 2329.3262 - mae: 2329.3262 - val_loss: 2074.4297 - val_mae: 2074.4297\n",
            "Epoch 416/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2326.2246 - mae: 2326.2246 - val_loss: 2070.9402 - val_mae: 2070.9402\n",
            "Epoch 417/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2322.7551 - mae: 2322.7551 - val_loss: 2069.8074 - val_mae: 2069.8074\n",
            "Epoch 418/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2321.4429 - mae: 2321.4429 - val_loss: 2065.0898 - val_mae: 2065.0898\n",
            "Epoch 419/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2316.8706 - mae: 2316.8706 - val_loss: 2063.6440 - val_mae: 2063.6440\n",
            "Epoch 420/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2313.9429 - mae: 2313.9429 - val_loss: 2061.3198 - val_mae: 2061.3198\n",
            "Epoch 421/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2311.3328 - mae: 2311.3328 - val_loss: 2059.3787 - val_mae: 2059.3787\n",
            "Epoch 422/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2308.2332 - mae: 2308.2332 - val_loss: 2057.0686 - val_mae: 2057.0686\n",
            "Epoch 423/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2305.1511 - mae: 2305.1511 - val_loss: 2054.6389 - val_mae: 2054.6389\n",
            "Epoch 424/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2302.5859 - mae: 2302.5859 - val_loss: 2051.7002 - val_mae: 2051.7002\n",
            "Epoch 425/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2299.2107 - mae: 2299.2107 - val_loss: 2048.8740 - val_mae: 2048.8740\n",
            "Epoch 426/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2296.7236 - mae: 2296.7236 - val_loss: 2045.6470 - val_mae: 2045.6470\n",
            "Epoch 427/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2294.1145 - mae: 2294.1145 - val_loss: 2044.1732 - val_mae: 2044.1732\n",
            "Epoch 428/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2291.7925 - mae: 2291.7925 - val_loss: 2043.3169 - val_mae: 2043.3169\n",
            "Epoch 429/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2287.9324 - mae: 2287.9324 - val_loss: 2040.3141 - val_mae: 2040.3141\n",
            "Epoch 430/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2286.0149 - mae: 2286.0149 - val_loss: 2040.9749 - val_mae: 2040.9749\n",
            "Epoch 431/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2283.1062 - mae: 2283.1062 - val_loss: 2034.4641 - val_mae: 2034.4641\n",
            "Epoch 432/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2278.8438 - mae: 2278.8438 - val_loss: 2032.5604 - val_mae: 2032.5604\n",
            "Epoch 433/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2276.3975 - mae: 2276.3975 - val_loss: 2030.4180 - val_mae: 2030.4180\n",
            "Epoch 434/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2274.6226 - mae: 2274.6226 - val_loss: 2028.3010 - val_mae: 2028.3010\n",
            "Epoch 435/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2270.4280 - mae: 2270.4280 - val_loss: 2024.7899 - val_mae: 2024.7899\n",
            "Epoch 436/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2268.1626 - mae: 2268.1626 - val_loss: 2023.7607 - val_mae: 2023.7607\n",
            "Epoch 437/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2266.2803 - mae: 2266.2803 - val_loss: 2021.5717 - val_mae: 2021.5717\n",
            "Epoch 438/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2262.4363 - mae: 2262.4363 - val_loss: 2018.8062 - val_mae: 2018.8062\n",
            "Epoch 439/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2259.6006 - mae: 2259.6006 - val_loss: 2017.6742 - val_mae: 2017.6742\n",
            "Epoch 440/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2256.3013 - mae: 2256.3013 - val_loss: 2014.2546 - val_mae: 2014.2546\n",
            "Epoch 441/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2253.3433 - mae: 2253.3433 - val_loss: 2011.8499 - val_mae: 2011.8499\n",
            "Epoch 442/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2250.7388 - mae: 2250.7388 - val_loss: 2009.5930 - val_mae: 2009.5930\n",
            "Epoch 443/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2247.7854 - mae: 2247.7854 - val_loss: 2006.6427 - val_mae: 2006.6427\n",
            "Epoch 444/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2245.7061 - mae: 2245.7061 - val_loss: 2007.1575 - val_mae: 2007.1575\n",
            "Epoch 445/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2242.5688 - mae: 2242.5688 - val_loss: 2001.5098 - val_mae: 2001.5098\n",
            "Epoch 446/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2241.1609 - mae: 2241.1609 - val_loss: 2000.6427 - val_mae: 2000.6427\n",
            "Epoch 447/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2238.3704 - mae: 2238.3704 - val_loss: 1997.1406 - val_mae: 1997.1406\n",
            "Epoch 448/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2234.3098 - mae: 2234.3098 - val_loss: 1995.7538 - val_mae: 1995.7538\n",
            "Epoch 449/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2231.0254 - mae: 2231.0254 - val_loss: 1993.4498 - val_mae: 1993.4498\n",
            "Epoch 450/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2228.1970 - mae: 2228.1970 - val_loss: 1990.0404 - val_mae: 1990.0404\n",
            "Epoch 451/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2226.0081 - mae: 2226.0081 - val_loss: 1987.7003 - val_mae: 1987.7003\n",
            "Epoch 452/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2222.2944 - mae: 2222.2944 - val_loss: 1985.9575 - val_mae: 1985.9575\n",
            "Epoch 453/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2219.9453 - mae: 2219.9453 - val_loss: 1984.0695 - val_mae: 1984.0695\n",
            "Epoch 454/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2216.9182 - mae: 2216.9182 - val_loss: 1981.1740 - val_mae: 1981.1740\n",
            "Epoch 455/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2213.4851 - mae: 2213.4851 - val_loss: 1978.1455 - val_mae: 1978.1455\n",
            "Epoch 456/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2211.0942 - mae: 2211.0942 - val_loss: 1978.0623 - val_mae: 1978.0623\n",
            "Epoch 457/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2208.2234 - mae: 2208.2234 - val_loss: 1974.5179 - val_mae: 1974.5179\n",
            "Epoch 458/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2204.6372 - mae: 2204.6372 - val_loss: 1971.3353 - val_mae: 1971.3353\n",
            "Epoch 459/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2201.7075 - mae: 2201.7075 - val_loss: 1969.3022 - val_mae: 1969.3022\n",
            "Epoch 460/1000\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2199.2507 - mae: 2199.2507 - val_loss: 1968.4818 - val_mae: 1968.4818\n",
            "Epoch 461/1000\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 2197.5015 - mae: 2197.5015 - val_loss: 1966.6677 - val_mae: 1966.6677\n",
            "Epoch 462/1000\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 2194.2473 - mae: 2194.2473 - val_loss: 1963.9196 - val_mae: 1963.9196\n",
            "Epoch 463/1000\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 2192.0754 - mae: 2192.0754 - val_loss: 1963.6954 - val_mae: 1963.6954\n",
            "Epoch 464/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2189.4321 - mae: 2189.4321 - val_loss: 1958.9675 - val_mae: 1958.9675\n",
            "Epoch 465/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2185.5408 - mae: 2185.5408 - val_loss: 1961.4977 - val_mae: 1961.4977\n",
            "Epoch 466/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2184.2390 - mae: 2184.2390 - val_loss: 1954.0376 - val_mae: 1954.0376\n",
            "Epoch 467/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2179.8242 - mae: 2179.8242 - val_loss: 1952.1760 - val_mae: 1952.1760\n",
            "Epoch 468/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2176.9299 - mae: 2176.9299 - val_loss: 1949.7993 - val_mae: 1949.7993\n",
            "Epoch 469/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2174.5171 - mae: 2174.5171 - val_loss: 1947.9095 - val_mae: 1947.9095\n",
            "Epoch 470/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2171.9375 - mae: 2171.9375 - val_loss: 1943.7428 - val_mae: 1943.7428\n",
            "Epoch 471/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2168.7637 - mae: 2168.7637 - val_loss: 1944.9646 - val_mae: 1944.9646\n",
            "Epoch 472/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2166.0996 - mae: 2166.0996 - val_loss: 1940.8956 - val_mae: 1940.8956\n",
            "Epoch 473/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2162.3892 - mae: 2162.3892 - val_loss: 1937.7245 - val_mae: 1937.7245\n",
            "Epoch 474/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2159.9202 - mae: 2159.9202 - val_loss: 1937.0826 - val_mae: 1937.0826\n",
            "Epoch 475/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2158.4553 - mae: 2158.4553 - val_loss: 1934.9506 - val_mae: 1934.9506\n",
            "Epoch 476/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2154.2266 - mae: 2154.2266 - val_loss: 1930.5677 - val_mae: 1930.5677\n",
            "Epoch 477/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2151.9932 - mae: 2151.9932 - val_loss: 1928.7474 - val_mae: 1928.7474\n",
            "Epoch 478/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2148.5205 - mae: 2148.5205 - val_loss: 1926.2839 - val_mae: 1926.2839\n",
            "Epoch 479/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2145.1414 - mae: 2145.1414 - val_loss: 1923.7058 - val_mae: 1923.7058\n",
            "Epoch 480/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2142.4885 - mae: 2142.4885 - val_loss: 1921.3971 - val_mae: 1921.3971\n",
            "Epoch 481/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2139.6472 - mae: 2139.6472 - val_loss: 1919.0514 - val_mae: 1919.0514\n",
            "Epoch 482/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2137.0940 - mae: 2137.0940 - val_loss: 1917.8342 - val_mae: 1917.8342\n",
            "Epoch 483/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2136.2161 - mae: 2136.2161 - val_loss: 1916.0386 - val_mae: 1916.0386\n",
            "Epoch 484/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2131.8159 - mae: 2131.8159 - val_loss: 1913.1926 - val_mae: 1913.1926\n",
            "Epoch 485/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2129.8108 - mae: 2129.8108 - val_loss: 1910.0494 - val_mae: 1910.0494\n",
            "Epoch 486/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2126.8694 - mae: 2126.8694 - val_loss: 1908.1478 - val_mae: 1908.1478\n",
            "Epoch 487/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2124.3049 - mae: 2124.3049 - val_loss: 1905.7056 - val_mae: 1905.7056\n",
            "Epoch 488/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2122.0044 - mae: 2122.0044 - val_loss: 1903.5181 - val_mae: 1903.5181\n",
            "Epoch 489/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2120.6238 - mae: 2120.6238 - val_loss: 1904.2959 - val_mae: 1904.2959\n",
            "Epoch 490/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2117.7937 - mae: 2117.7937 - val_loss: 1898.8523 - val_mae: 1898.8523\n",
            "Epoch 491/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2115.0178 - mae: 2115.0178 - val_loss: 1897.8186 - val_mae: 1897.8186\n",
            "Epoch 492/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2112.3057 - mae: 2112.3057 - val_loss: 1894.6714 - val_mae: 1894.6714\n",
            "Epoch 493/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2110.6167 - mae: 2110.6167 - val_loss: 1893.8024 - val_mae: 1893.8024\n",
            "Epoch 494/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2108.2322 - mae: 2108.2322 - val_loss: 1892.1808 - val_mae: 1892.1808\n",
            "Epoch 495/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2105.8423 - mae: 2105.8423 - val_loss: 1889.1095 - val_mae: 1889.1095\n",
            "Epoch 496/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2103.8450 - mae: 2103.8450 - val_loss: 1886.8969 - val_mae: 1886.8969\n",
            "Epoch 497/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2101.1790 - mae: 2101.1790 - val_loss: 1885.4408 - val_mae: 1885.4409\n",
            "Epoch 498/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2099.1846 - mae: 2099.1846 - val_loss: 1883.7753 - val_mae: 1883.7753\n",
            "Epoch 499/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2098.2930 - mae: 2098.2930 - val_loss: 1882.1632 - val_mae: 1882.1632\n",
            "Epoch 500/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2095.6108 - mae: 2095.6108 - val_loss: 1879.2169 - val_mae: 1879.2169\n",
            "Epoch 501/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2093.2183 - mae: 2093.2183 - val_loss: 1877.4136 - val_mae: 1877.4136\n",
            "Epoch 502/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2091.7979 - mae: 2091.7979 - val_loss: 1876.6328 - val_mae: 1876.6328\n",
            "Epoch 503/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2090.1902 - mae: 2090.1902 - val_loss: 1873.4095 - val_mae: 1873.4095\n",
            "Epoch 504/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2087.3318 - mae: 2087.3318 - val_loss: 1871.5856 - val_mae: 1871.5856\n",
            "Epoch 505/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2086.3999 - mae: 2086.3999 - val_loss: 1873.3430 - val_mae: 1873.3430\n",
            "Epoch 506/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2085.1572 - mae: 2085.1572 - val_loss: 1869.3040 - val_mae: 1869.3040\n",
            "Epoch 507/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2081.8713 - mae: 2081.8713 - val_loss: 1866.3632 - val_mae: 1866.3632\n",
            "Epoch 508/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2080.9812 - mae: 2080.9812 - val_loss: 1866.1205 - val_mae: 1866.1205\n",
            "Epoch 509/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2079.5315 - mae: 2079.5315 - val_loss: 1862.6288 - val_mae: 1862.6288\n",
            "Epoch 510/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2077.5461 - mae: 2077.5461 - val_loss: 1860.8379 - val_mae: 1860.8379\n",
            "Epoch 511/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2075.9490 - mae: 2075.9490 - val_loss: 1864.4882 - val_mae: 1864.4882\n",
            "Epoch 512/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2073.7817 - mae: 2073.7817 - val_loss: 1857.5621 - val_mae: 1857.5621\n",
            "Epoch 513/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2070.6646 - mae: 2070.6646 - val_loss: 1857.6606 - val_mae: 1857.6606\n",
            "Epoch 514/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 2070.3228 - mae: 2070.3228 - val_loss: 1853.9414 - val_mae: 1853.9414\n",
            "Epoch 515/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2068.2534 - mae: 2068.2534 - val_loss: 1853.6217 - val_mae: 1853.6217\n",
            "Epoch 516/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2066.8650 - mae: 2066.8650 - val_loss: 1851.5504 - val_mae: 1851.5504\n",
            "Epoch 517/1000\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 2064.5540 - mae: 2064.5540 - val_loss: 1850.5404 - val_mae: 1850.5404\n",
            "Epoch 518/1000\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2063.3833 - mae: 2063.3833 - val_loss: 1849.9272 - val_mae: 1849.9272\n",
            "Epoch 519/1000\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2061.1804 - mae: 2061.1804 - val_loss: 1847.5493 - val_mae: 1847.5493\n",
            "Epoch 520/1000\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 2059.0117 - mae: 2059.0117 - val_loss: 1846.7021 - val_mae: 1846.7021\n",
            "Epoch 521/1000\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 2058.8354 - mae: 2058.8354 - val_loss: 1846.1628 - val_mae: 1846.1628\n",
            "Epoch 522/1000\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 2056.5100 - mae: 2056.5100 - val_loss: 1843.5364 - val_mae: 1843.5364\n",
            "Epoch 523/1000\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2055.0957 - mae: 2055.0957 - val_loss: 1841.4025 - val_mae: 1841.4025\n",
            "Epoch 524/1000\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 2053.5415 - mae: 2053.5415 - val_loss: 1841.9209 - val_mae: 1841.9209\n",
            "Epoch 525/1000\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2054.6978 - mae: 2054.6978 - val_loss: 1840.9152 - val_mae: 1840.9152\n",
            "Epoch 526/1000\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 2052.3821 - mae: 2052.3821 - val_loss: 1837.9463 - val_mae: 1837.9463\n",
            "Epoch 527/1000\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 2049.1982 - mae: 2049.1982 - val_loss: 1836.5898 - val_mae: 1836.5898\n",
            "Epoch 528/1000\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 2049.0029 - mae: 2049.0029 - val_loss: 1836.5665 - val_mae: 1836.5665\n",
            "Epoch 529/1000\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 2046.8177 - mae: 2046.8177 - val_loss: 1835.3411 - val_mae: 1835.3411\n",
            "Epoch 530/1000\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2044.3885 - mae: 2044.3885 - val_loss: 1833.8632 - val_mae: 1833.8632\n",
            "Epoch 531/1000\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2044.0787 - mae: 2044.0787 - val_loss: 1831.8835 - val_mae: 1831.8835\n",
            "Epoch 532/1000\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 2043.3612 - mae: 2043.3612 - val_loss: 1832.3501 - val_mae: 1832.3501\n",
            "Epoch 533/1000\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 2042.8926 - mae: 2042.8926 - val_loss: 1829.8295 - val_mae: 1829.8295\n",
            "Epoch 534/1000\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 2039.8605 - mae: 2039.8605 - val_loss: 1829.9717 - val_mae: 1829.9717\n",
            "Epoch 535/1000\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 2039.1449 - mae: 2039.1449 - val_loss: 1827.5000 - val_mae: 1827.5000\n",
            "Epoch 536/1000\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2038.8661 - mae: 2038.8661 - val_loss: 1829.2518 - val_mae: 1829.2518\n",
            "Epoch 537/1000\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 2037.0294 - mae: 2037.0294 - val_loss: 1826.6029 - val_mae: 1826.6029\n",
            "Epoch 538/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2035.3282 - mae: 2035.3282 - val_loss: 1826.3304 - val_mae: 1826.3304\n",
            "Epoch 539/1000\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 2035.4806 - mae: 2035.4806 - val_loss: 1824.0450 - val_mae: 1824.0450\n",
            "Epoch 540/1000\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 2033.6827 - mae: 2033.6827 - val_loss: 1824.0077 - val_mae: 1824.0077\n",
            "Epoch 541/1000\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 2032.6794 - mae: 2032.6794 - val_loss: 1823.2554 - val_mae: 1823.2554\n",
            "Epoch 542/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2033.0647 - mae: 2033.0647 - val_loss: 1820.0013 - val_mae: 1820.0013\n",
            "Epoch 543/1000\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 2030.9388 - mae: 2030.9388 - val_loss: 1819.5001 - val_mae: 1819.5001\n",
            "Epoch 544/1000\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 2029.6895 - mae: 2029.6895 - val_loss: 1819.2111 - val_mae: 1819.2111\n",
            "Epoch 545/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2029.0261 - mae: 2029.0261 - val_loss: 1818.8376 - val_mae: 1818.8376\n",
            "Epoch 546/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2027.8011 - mae: 2027.8011 - val_loss: 1820.8649 - val_mae: 1820.8649\n",
            "Epoch 547/1000\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 2028.0350 - mae: 2028.0350 - val_loss: 1818.1211 - val_mae: 1818.1211\n",
            "Epoch 548/1000\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 2026.5682 - mae: 2026.5682 - val_loss: 1816.0758 - val_mae: 1816.0758\n",
            "Epoch 549/1000\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 2026.3170 - mae: 2026.3170 - val_loss: 1814.6644 - val_mae: 1814.6644\n",
            "Epoch 550/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2023.7628 - mae: 2023.7628 - val_loss: 1812.7283 - val_mae: 1812.7283\n",
            "Epoch 551/1000\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 2022.8655 - mae: 2022.8655 - val_loss: 1812.5465 - val_mae: 1812.5465\n",
            "Epoch 552/1000\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 2022.3057 - mae: 2022.3057 - val_loss: 1809.8654 - val_mae: 1809.8654\n",
            "Epoch 553/1000\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 2020.7042 - mae: 2020.7042 - val_loss: 1810.8982 - val_mae: 1810.8982\n",
            "Epoch 554/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2019.7084 - mae: 2019.7084 - val_loss: 1809.1572 - val_mae: 1809.1572\n",
            "Epoch 555/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2019.7081 - mae: 2019.7081 - val_loss: 1807.6094 - val_mae: 1807.6094\n",
            "Epoch 556/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2018.2362 - mae: 2018.2362 - val_loss: 1807.7430 - val_mae: 1807.7430\n",
            "Epoch 557/1000\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 2017.9169 - mae: 2017.9169 - val_loss: 1807.7356 - val_mae: 1807.7356\n",
            "Epoch 558/1000\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 2017.1559 - mae: 2017.1559 - val_loss: 1806.9857 - val_mae: 1806.9857\n",
            "Epoch 559/1000\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 2014.9872 - mae: 2014.9872 - val_loss: 1803.1377 - val_mae: 1803.1377\n",
            "Epoch 560/1000\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 2014.0568 - mae: 2014.0568 - val_loss: 1801.8335 - val_mae: 1801.8335\n",
            "Epoch 561/1000\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 2013.6285 - mae: 2013.6285 - val_loss: 1800.8601 - val_mae: 1800.8601\n",
            "Epoch 562/1000\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 2012.8334 - mae: 2012.8334 - val_loss: 1802.1460 - val_mae: 1802.1460\n",
            "Epoch 563/1000\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 2012.0792 - mae: 2012.0792 - val_loss: 1800.6882 - val_mae: 1800.6882\n",
            "Epoch 564/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2011.3878 - mae: 2011.3878 - val_loss: 1799.4185 - val_mae: 1799.4185\n",
            "Epoch 565/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2010.6353 - mae: 2010.6353 - val_loss: 1797.3674 - val_mae: 1797.3674\n",
            "Epoch 566/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2009.0283 - mae: 2009.0283 - val_loss: 1797.8217 - val_mae: 1797.8217\n",
            "Epoch 567/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2008.9028 - mae: 2008.9028 - val_loss: 1796.3989 - val_mae: 1796.3989\n",
            "Epoch 568/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2007.8579 - mae: 2007.8579 - val_loss: 1795.9581 - val_mae: 1795.9581\n",
            "Epoch 569/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2007.1215 - mae: 2007.1215 - val_loss: 1794.0859 - val_mae: 1794.0859\n",
            "Epoch 570/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2006.2963 - mae: 2006.2963 - val_loss: 1792.8403 - val_mae: 1792.8403\n",
            "Epoch 571/1000\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 2005.5250 - mae: 2005.5250 - val_loss: 1791.3333 - val_mae: 1791.3333\n",
            "Epoch 572/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2003.5828 - mae: 2003.5828 - val_loss: 1790.8752 - val_mae: 1790.8752\n",
            "Epoch 573/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2002.7729 - mae: 2002.7729 - val_loss: 1789.6038 - val_mae: 1789.6038\n",
            "Epoch 574/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2002.5977 - mae: 2002.5977 - val_loss: 1791.0789 - val_mae: 1791.0789\n",
            "Epoch 575/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 2003.2761 - mae: 2003.2761 - val_loss: 1789.7188 - val_mae: 1789.7188\n",
            "Epoch 576/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 2001.5309 - mae: 2001.5309 - val_loss: 1786.7837 - val_mae: 1786.7837\n",
            "Epoch 577/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 1999.8857 - mae: 1999.8857 - val_loss: 1784.9362 - val_mae: 1784.9362\n",
            "Epoch 578/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 1998.9192 - mae: 1998.9192 - val_loss: 1783.9701 - val_mae: 1783.9701\n",
            "Epoch 579/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 1998.4093 - mae: 1998.4093 - val_loss: 1783.2493 - val_mae: 1783.2493\n",
            "Epoch 580/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 1998.3545 - mae: 1998.3545 - val_loss: 1783.0621 - val_mae: 1783.0621\n",
            "Epoch 581/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 1997.1155 - mae: 1997.1155 - val_loss: 1781.5021 - val_mae: 1781.5021\n",
            "Epoch 582/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1996.2786 - mae: 1996.2786 - val_loss: 1781.6700 - val_mae: 1781.6700\n",
            "Epoch 583/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 1995.4470 - mae: 1995.4470 - val_loss: 1783.0986 - val_mae: 1783.0986\n",
            "Epoch 584/1000\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 1994.8469 - mae: 1994.8469 - val_loss: 1778.7733 - val_mae: 1778.7733\n",
            "Epoch 585/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 1993.9857 - mae: 1993.9857 - val_loss: 1777.6848 - val_mae: 1777.6848\n",
            "Epoch 586/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 1992.7753 - mae: 1992.7753 - val_loss: 1777.8265 - val_mae: 1777.8265\n",
            "Epoch 587/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 1991.8990 - mae: 1991.8990 - val_loss: 1775.2939 - val_mae: 1775.2939\n",
            "Epoch 588/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1990.9745 - mae: 1990.9745 - val_loss: 1775.7885 - val_mae: 1775.7885\n",
            "Epoch 589/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1990.8801 - mae: 1990.8801 - val_loss: 1775.3499 - val_mae: 1775.3499\n",
            "Epoch 590/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1989.5304 - mae: 1989.5304 - val_loss: 1772.7043 - val_mae: 1772.7043\n",
            "Epoch 591/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1988.9934 - mae: 1988.9934 - val_loss: 1773.3176 - val_mae: 1773.3176\n",
            "Epoch 592/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1988.3776 - mae: 1988.3776 - val_loss: 1773.1632 - val_mae: 1773.1632\n",
            "Epoch 593/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1988.2437 - mae: 1988.2437 - val_loss: 1770.6705 - val_mae: 1770.6705\n",
            "Epoch 594/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1986.4208 - mae: 1986.4208 - val_loss: 1770.0205 - val_mae: 1770.0205\n",
            "Epoch 595/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1987.3134 - mae: 1987.3134 - val_loss: 1766.3834 - val_mae: 1766.3834\n",
            "Epoch 596/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1985.5005 - mae: 1985.5005 - val_loss: 1766.7885 - val_mae: 1766.7885\n",
            "Epoch 597/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1984.1943 - mae: 1984.1943 - val_loss: 1766.1772 - val_mae: 1766.1772\n",
            "Epoch 598/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1983.6989 - mae: 1983.6989 - val_loss: 1764.0408 - val_mae: 1764.0408\n",
            "Epoch 599/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1983.6094 - mae: 1983.6094 - val_loss: 1763.9296 - val_mae: 1763.9296\n",
            "Epoch 600/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1981.8740 - mae: 1981.8740 - val_loss: 1762.4697 - val_mae: 1762.4697\n",
            "Epoch 601/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1981.5042 - mae: 1981.5042 - val_loss: 1761.7551 - val_mae: 1761.7551\n",
            "Epoch 602/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1980.4119 - mae: 1980.4119 - val_loss: 1760.8043 - val_mae: 1760.8043\n",
            "Epoch 603/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1979.6503 - mae: 1979.6503 - val_loss: 1761.6158 - val_mae: 1761.6158\n",
            "Epoch 604/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1978.9108 - mae: 1978.9108 - val_loss: 1758.6246 - val_mae: 1758.6246\n",
            "Epoch 605/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1979.3300 - mae: 1979.3300 - val_loss: 1759.7126 - val_mae: 1759.7126\n",
            "Epoch 606/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1979.1194 - mae: 1979.1194 - val_loss: 1760.1357 - val_mae: 1760.1357\n",
            "Epoch 607/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1977.8551 - mae: 1977.8551 - val_loss: 1758.7979 - val_mae: 1758.7979\n",
            "Epoch 608/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1976.9493 - mae: 1976.9493 - val_loss: 1757.2764 - val_mae: 1757.2764\n",
            "Epoch 609/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1976.4093 - mae: 1976.4093 - val_loss: 1757.5624 - val_mae: 1757.5624\n",
            "Epoch 610/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1976.9220 - mae: 1976.9220 - val_loss: 1755.2637 - val_mae: 1755.2637\n",
            "Epoch 611/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1974.9913 - mae: 1974.9913 - val_loss: 1755.3906 - val_mae: 1755.3906\n",
            "Epoch 612/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1975.5951 - mae: 1975.5951 - val_loss: 1754.6188 - val_mae: 1754.6188\n",
            "Epoch 613/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1973.6232 - mae: 1973.6232 - val_loss: 1752.4159 - val_mae: 1752.4159\n",
            "Epoch 614/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1973.2584 - mae: 1973.2584 - val_loss: 1752.7505 - val_mae: 1752.7505\n",
            "Epoch 615/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1972.4556 - mae: 1972.4556 - val_loss: 1753.2214 - val_mae: 1753.2214\n",
            "Epoch 616/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1972.3241 - mae: 1972.3241 - val_loss: 1751.0206 - val_mae: 1751.0206\n",
            "Epoch 617/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1972.1124 - mae: 1972.1124 - val_loss: 1750.5890 - val_mae: 1750.5890\n",
            "Epoch 618/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1971.4872 - mae: 1971.4872 - val_loss: 1752.1708 - val_mae: 1752.1708\n",
            "Epoch 619/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1971.1227 - mae: 1971.1227 - val_loss: 1749.5273 - val_mae: 1749.5273\n",
            "Epoch 620/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1971.0815 - mae: 1971.0815 - val_loss: 1749.3240 - val_mae: 1749.3240\n",
            "Epoch 621/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1970.0056 - mae: 1970.0056 - val_loss: 1748.2307 - val_mae: 1748.2307\n",
            "Epoch 622/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 1969.4816 - mae: 1969.4816 - val_loss: 1748.3101 - val_mae: 1748.3101\n",
            "Epoch 623/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 1969.0264 - mae: 1969.0264 - val_loss: 1748.0596 - val_mae: 1748.0596\n",
            "Epoch 624/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 1968.4792 - mae: 1968.4792 - val_loss: 1747.3911 - val_mae: 1747.3911\n",
            "Epoch 625/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 1968.1219 - mae: 1968.1219 - val_loss: 1747.8527 - val_mae: 1747.8527\n",
            "Epoch 626/1000\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 1968.6600 - mae: 1968.6600 - val_loss: 1745.2357 - val_mae: 1745.2357\n",
            "Epoch 627/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 1967.6180 - mae: 1967.6180 - val_loss: 1746.8508 - val_mae: 1746.8508\n",
            "Epoch 628/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 1968.4841 - mae: 1968.4841 - val_loss: 1746.1250 - val_mae: 1746.1250\n",
            "Epoch 629/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 1967.1771 - mae: 1967.1771 - val_loss: 1743.3324 - val_mae: 1743.3324\n",
            "Epoch 630/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 1965.6600 - mae: 1965.6600 - val_loss: 1744.3779 - val_mae: 1744.3779\n",
            "Epoch 631/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 1965.6099 - mae: 1965.6099 - val_loss: 1742.8585 - val_mae: 1742.8585\n",
            "Epoch 632/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 1966.4016 - mae: 1966.4016 - val_loss: 1743.7710 - val_mae: 1743.7710\n",
            "Epoch 633/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1964.5913 - mae: 1964.5913 - val_loss: 1741.2314 - val_mae: 1741.2314\n",
            "Epoch 634/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 1964.9504 - mae: 1964.9504 - val_loss: 1740.7886 - val_mae: 1740.7886\n",
            "Epoch 635/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 1963.4384 - mae: 1963.4384 - val_loss: 1743.5966 - val_mae: 1743.5966\n",
            "Epoch 636/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 1964.4984 - mae: 1964.4984 - val_loss: 1743.7799 - val_mae: 1743.7799\n",
            "Epoch 637/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 1964.7091 - mae: 1964.7091 - val_loss: 1740.6356 - val_mae: 1740.6356\n",
            "Epoch 638/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 1962.6342 - mae: 1962.6342 - val_loss: 1740.0828 - val_mae: 1740.0828\n",
            "Epoch 639/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 1962.0035 - mae: 1962.0035 - val_loss: 1740.3019 - val_mae: 1740.3019\n",
            "Epoch 640/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 1962.1454 - mae: 1962.1454 - val_loss: 1738.3900 - val_mae: 1738.3900\n",
            "Epoch 641/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 1961.3325 - mae: 1961.3325 - val_loss: 1738.9410 - val_mae: 1738.9410\n",
            "Epoch 642/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 1960.3357 - mae: 1960.3357 - val_loss: 1739.3628 - val_mae: 1739.3628\n",
            "Epoch 643/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 1960.7222 - mae: 1960.7222 - val_loss: 1738.0118 - val_mae: 1738.0118\n",
            "Epoch 644/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 1960.8035 - mae: 1960.8035 - val_loss: 1737.5955 - val_mae: 1737.5955\n",
            "Epoch 645/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 1959.8862 - mae: 1959.8862 - val_loss: 1737.8470 - val_mae: 1737.8470\n",
            "Epoch 646/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 1959.7518 - mae: 1959.7518 - val_loss: 1736.9358 - val_mae: 1736.9358\n",
            "Epoch 647/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 1959.4945 - mae: 1959.4945 - val_loss: 1738.0938 - val_mae: 1738.0938\n",
            "Epoch 648/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1959.5674 - mae: 1959.5674 - val_loss: 1737.1246 - val_mae: 1737.1246\n",
            "Epoch 649/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1958.6547 - mae: 1958.6547 - val_loss: 1736.1355 - val_mae: 1736.1355\n",
            "Epoch 650/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1957.7665 - mae: 1957.7665 - val_loss: 1735.9927 - val_mae: 1735.9927\n",
            "Epoch 651/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1957.8812 - mae: 1957.8812 - val_loss: 1736.8005 - val_mae: 1736.8005\n",
            "Epoch 652/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1956.9552 - mae: 1956.9552 - val_loss: 1738.0206 - val_mae: 1738.0206\n",
            "Epoch 653/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1956.9615 - mae: 1956.9615 - val_loss: 1735.7808 - val_mae: 1735.7808\n",
            "Epoch 654/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1956.4678 - mae: 1956.4678 - val_loss: 1734.3951 - val_mae: 1734.3951\n",
            "Epoch 655/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1955.0358 - mae: 1955.0358 - val_loss: 1733.7557 - val_mae: 1733.7557\n",
            "Epoch 656/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1954.5613 - mae: 1954.5613 - val_loss: 1734.4045 - val_mae: 1734.4045\n",
            "Epoch 657/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1955.4363 - mae: 1955.4363 - val_loss: 1733.0110 - val_mae: 1733.0110\n",
            "Epoch 658/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1954.3190 - mae: 1954.3190 - val_loss: 1732.9244 - val_mae: 1732.9244\n",
            "Epoch 659/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1954.2533 - mae: 1954.2533 - val_loss: 1732.8005 - val_mae: 1732.8005\n",
            "Epoch 660/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1953.6388 - mae: 1953.6388 - val_loss: 1732.5957 - val_mae: 1732.5957\n",
            "Epoch 661/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1954.8176 - mae: 1954.8176 - val_loss: 1731.5522 - val_mae: 1731.5522\n",
            "Epoch 662/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1953.5031 - mae: 1953.5031 - val_loss: 1730.8298 - val_mae: 1730.8298\n",
            "Epoch 663/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1952.6460 - mae: 1952.6460 - val_loss: 1731.9324 - val_mae: 1731.9324\n",
            "Epoch 664/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1952.4596 - mae: 1952.4596 - val_loss: 1731.7535 - val_mae: 1731.7535\n",
            "Epoch 665/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1951.4773 - mae: 1951.4773 - val_loss: 1731.1772 - val_mae: 1731.1772\n",
            "Epoch 666/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1952.3474 - mae: 1952.3474 - val_loss: 1730.3352 - val_mae: 1730.3352\n",
            "Epoch 667/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1950.8752 - mae: 1950.8752 - val_loss: 1730.9944 - val_mae: 1730.9944\n",
            "Epoch 668/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1950.8402 - mae: 1950.8402 - val_loss: 1731.0724 - val_mae: 1731.0724\n",
            "Epoch 669/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1950.3778 - mae: 1950.3778 - val_loss: 1729.9618 - val_mae: 1729.9618\n",
            "Epoch 670/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1949.2643 - mae: 1949.2643 - val_loss: 1730.7708 - val_mae: 1730.7708\n",
            "Epoch 671/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1950.2052 - mae: 1950.2052 - val_loss: 1729.8835 - val_mae: 1729.8835\n",
            "Epoch 672/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1948.8872 - mae: 1948.8872 - val_loss: 1728.8358 - val_mae: 1728.8358\n",
            "Epoch 673/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1948.1740 - mae: 1948.1740 - val_loss: 1728.8553 - val_mae: 1728.8553\n",
            "Epoch 674/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1949.2191 - mae: 1949.2191 - val_loss: 1728.8794 - val_mae: 1728.8794\n",
            "Epoch 675/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1948.3768 - mae: 1948.3768 - val_loss: 1729.0015 - val_mae: 1729.0015\n",
            "Epoch 676/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1947.1984 - mae: 1947.1984 - val_loss: 1728.1609 - val_mae: 1728.1609\n",
            "Epoch 677/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1948.1683 - mae: 1948.1683 - val_loss: 1728.2366 - val_mae: 1728.2366\n",
            "Epoch 678/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1946.5715 - mae: 1946.5715 - val_loss: 1727.5426 - val_mae: 1727.5426\n",
            "Epoch 679/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1946.2532 - mae: 1946.2532 - val_loss: 1728.3905 - val_mae: 1728.3905\n",
            "Epoch 680/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1947.2297 - mae: 1947.2297 - val_loss: 1731.6063 - val_mae: 1731.6063\n",
            "Epoch 681/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1947.3057 - mae: 1947.3057 - val_loss: 1725.8785 - val_mae: 1725.8785\n",
            "Epoch 682/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1944.7639 - mae: 1944.7639 - val_loss: 1726.6130 - val_mae: 1726.6130\n",
            "Epoch 683/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1944.8693 - mae: 1944.8693 - val_loss: 1727.1809 - val_mae: 1727.1809\n",
            "Epoch 684/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1945.1727 - mae: 1945.1727 - val_loss: 1727.6102 - val_mae: 1727.6102\n",
            "Epoch 685/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1943.8112 - mae: 1943.8112 - val_loss: 1725.8625 - val_mae: 1725.8625\n",
            "Epoch 686/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1943.7087 - mae: 1943.7087 - val_loss: 1725.6622 - val_mae: 1725.6622\n",
            "Epoch 687/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 1942.9926 - mae: 1942.9926 - val_loss: 1725.3513 - val_mae: 1725.3513\n",
            "Epoch 688/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1942.7362 - mae: 1942.7362 - val_loss: 1724.9791 - val_mae: 1724.9791\n",
            "Epoch 689/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1942.1848 - mae: 1942.1848 - val_loss: 1725.4205 - val_mae: 1725.4205\n",
            "Epoch 690/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1942.7279 - mae: 1942.7279 - val_loss: 1725.4590 - val_mae: 1725.4590\n",
            "Epoch 691/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1941.4907 - mae: 1941.4907 - val_loss: 1725.3901 - val_mae: 1725.3901\n",
            "Epoch 692/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1941.2175 - mae: 1941.2175 - val_loss: 1725.4618 - val_mae: 1725.4618\n",
            "Epoch 693/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 1942.8167 - mae: 1942.8167 - val_loss: 1727.9564 - val_mae: 1727.9564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "vBI5dXMS_Fba",
        "outputId": "b32f227b-2c94-40c6-ee5e-3ed3462e17d6"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnAAAAG5CAYAAAAOHAlCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXxcd33v/9dnFmk0Wka7rM27k9hxdmenEJImJIGScIGUrUAvbWhLW1p6KeGWlsttuTf99f5KoS1LuEkJhR+QBigBAiQhCUmAhNjGWRw73m1JlrXv+2i+vz/OkSXZsi3J0pwZ6f18POYxM99zzsxnsjjvfL/n+/2acw4RERERyR6hoAsQERERkblRgBMRERHJMgpwIiIiIllGAU5EREQkyyjAiYiIiGQZBTgRERGRLKMAJyJyBmb2FTP7u1mee8jMfvNsP0dE5HQU4ERERESyjAKciIiISJZRgBORJcEfuvyomb1oZgNmdq+ZVZnZj8ysz8weM7OSKee/2cx2mlm3mT1pZhunHLvEzLb7130LiJ3wXW8ysx3+tb8wswvnWfPvm9k+M+s0s4fMrMZvNzP7jJm1mlmvmb1kZpv9Y7ea2St+bU1m9t/m9RdMRLKaApyILCVvBW4EzgF+C/gR8N+BCrw/7/4UwMzOAb4B/Jl/7GHg+2aWY2Y5wH8C/w6UAv/hfy7+tZcA9wEfBMqALwEPmVnuXAo1s+uB/w3cAVQDh4Fv+odvAl7r/46Ef06Hf+xe4IPOuUJgM/D4XL5XRJYGBTgRWUr+2TnX4pxrAp4GnnPO/do5Nwx8F7jEP++3gR865x51zo0B/wfIA64BrgKiwD8558accw8Cz0/5jjuBLznnnnPOjTvn7gdG/Ovm4t3Afc657c65EeDjwNVmthoYAwqB8wBzzu1yzjX7140Bm8ysyDnX5ZzbPsfvFZElQAFORJaSlimvh2Z4X+C/rsHr8QLAOZcCGoBa/1iTc85NufbwlNergL/wh0+7zawbqPevm4sTa+jH62Wrdc49DvwL8K9Aq5ndY2ZF/qlvBW4FDpvZz8zs6jl+r4gsAQpwIrIcHcULYoB3zxleCGsCmoFav23CyimvG4BPO+eKpzzizrlvnGUN+XhDsk0AzrnPOecuAzbhDaV+1G9/3jl3G1CJN9T7wBy/V0SWAAU4EVmOHgDeaGY3mFkU+Au8YdBfAL8EksCfmlnUzP4LcMWUa78M/IGZXelPNsg3szeaWeEca/gG8LtmdrF//9z/whvyPWRml/ufHwUGgGEg5d+j924zS/hDv71A6iz+OohIllKAE5Flxzn3KvAe4J+BdrwJD7/lnBt1zo0C/wV4P9CJd7/cd6ZcuxX4fbwhzi5gn3/uXGt4DPhr4Nt4vX7rgHf4h4vwgmIX3jBrB/AP/rHfAQ6ZWS/wB3j30onIMmPTb/MQERERkUynHjgRERGRLKMAJyIiIpJlFOBEREREsowCnIiIiEiWiQRdQLqVl5e71atXB12GiIiIyBlt27at3TlXcWL7sgtwq1evZuvWrUGXISIiInJGZnZ4pnYNoYqIiIhkGQU4ERERkSyjACciIiKSZZbdPXAiIiKSHcbGxmhsbGR4eDjoUhZdLBajrq6OaDQ6q/MV4ERERCQjNTY2UlhYyOrVqzGzoMtZNM45Ojo6aGxsZM2aNbO6RkOoIiIikpGGh4cpKytb0uENwMwoKyubU0+jApyIiIhkrKUe3ibM9XcqwImIiIhkGQU4ERERkVPo7u7m85///Jyvu/XWW+nu7l6EijwKcCIiIiKncKoAl0wmT3vdww8/THFx8WKVpVmoIiIiIqdy1113sX//fi6++GKi0SixWIySkhJ2797Nnj17uP3222loaGB4eJgPf/jD3HnnncDk1p39/f3ccsstvOY1r+EXv/gFtbW1fO973yMvL++s6lKAExERkYz3qe/v5JWjvQv6mZtqivjkb51/2nPuvvtuXn75ZXbs2MGTTz7JG9/4Rl5++eXjy33cd999lJaWMjQ0xOWXX85b3/pWysrKpn3G3r17+cY3vsGXv/xl7rjjDr797W/znve856xqV4ATERERmaUrrrhi2lptn/vc5/jud78LQENDA3v37j0pwK1Zs4aLL74YgMsuu4xDhw6ddR0KcCIiIpLxztRTli75+fnHXz/55JM89thj/PKXvyQej3PdddfNuJZbbm7u8dfhcJihoaGzrkOTGBbYwfYBmnuGcM4FXYqIiIicpcLCQvr6+mY81tPTQ0lJCfF4nN27d/Pss8+mrS71wC2w//XwLh59pYVN1UX8v3dcxMbqoqBLEhERkXkqKyvj2muvZfPmzeTl5VFVVXX82M0338wXv/hFNm7cyLnnnstVV12VtrpsufUUbdmyxW3dunXRPv/Fxm6eP9TFl586wOBoksc+8joqi2KL9n0iIiJL1a5du9i4cWPQZaTNTL/XzLY557aceK6GUBfYhXXFfOA1a/j/fv9KhpMp7v7x7qBLEhERkSVGAW6RrK0o4F1XrOQHLzTTNTAadDkiIiKyhCjALaJ3XFHP6HiKh144GnQpIiIisoQowC2i81YUsaY8n6f2tAVdioiIiCwhCnCL7Jp1ZTx7oIOx8VTQpYiIiMgSoQC3yK5dX87A6DgvNfUEXYqIiIgsEQpwi+yi+mIAdirAiYiIZJ3u7m4+//nPz+vaf/qnf2JwcHCBK/IowC2ymkSM4niUnQu8Aa+IiIgsvkwNcNqJYaGlUhCazMVmxuaahAKciIhIFrrrrrvYv38/F198MTfeeCOVlZU88MADjIyM8Ja3vIVPfepTDAwMcMcdd9DY2Mj4+Dh//dd/TUtLC0ePHuX1r3895eXlPPHEEwtalwLcQvvBh+HYy3DFnXDRO8CMTTVFfOUXh0ilHKGQBV2hiIhI9vnRXXDspYX9zBUXwC13n/aUu+++m5dffpkdO3bwyCOP8OCDD/KrX/0K5xxvfvObeeqpp2hra6OmpoYf/vCHgLdHaiKR4B//8R954oknKC8vX9i60RDqwqu6AMbH4D//AJ75DABryvMZTaY42jMUcHEiIiIyX4888giPPPIIl1xyCZdeeim7d+9m7969XHDBBTz66KN87GMf4+mnnyaRSCx6LeqBW2hX3gmX/x58+wPw+N/B+bezptz7G3mwfYC6knjABYqIiGShM/SUpYNzjo9//ON88IMfPOnY9u3befjhh/nEJz7BDTfcwN/8zd8sai3qgVsMoRDc/L8hFIGff4415fmAF+BEREQkexQWFtLX1wfAG97wBu677z76+/sBaGpqorW1laNHjxKPx3nPe97DRz/6UbZv337StQtNPXCLpXAFnP8W2PldKm/5f4jnhBXgREREskxZWRnXXnstmzdv5pZbbuFd73oXV199NQAFBQV87WtfY9++fXz0ox8lFAoRjUb5whe+AMCdd97JzTffTE1NzYJPYjDn3IJ+YKbbsmWL27p1a3q+bNcP4Fvvhvd+j1u+H6Y6EeO+91+enu8WERHJcrt27WLjxo1Bl5E2M/1eM9vmnNty4rkaQl1M666HcA7se4za4jyOdmsSg4iIiJw9BbjFlBOH6ouh4Xlqi2M0KcCJiIjIAlCAW2z1V8DRX1NbFKFvOEnf8FjQFYmIiGSN5XKr11x/pwLcYqu7HMZHOM8OA9DcMxxwQSIiItkhFovR0dGx5EOcc46Ojg5isdisr9Es1MVWtRmAlcnDQC1N3UOcU1UYbE0iIiJZoK6ujsbGRtra2oIuZdHFYjHq6upmfb4C3GIrXQPhXMqHDgC1msggIiIyS9FolDVr1gRdRkbSEOpiC4Wh/BziPXsxg7a+kaArEhERkSynAJcOFecSanuV0ngOrQpwIiIicpYU4NKhfAP0NFJTEFIPnIiIiJw1Bbh0KFkNOM7L61aAExERkbOmAJcOxasA2JDTrgAnIiIiZ00BLh1KvAC3MtRGW9/Ikl/PRkRERBaXAlw6FKyAcC41rpXR8RS9Q8mgKxIREZEspgCXDqEQFK+kbKwZgLZ+7cYgIiIi86cAly5FNRSOeitJdw1qP1QRERGZPwW4dCmqITbcCkDXwGjAxYiIiEg2U4BLl8JqooMtGCm6BhXgREREZP4U4NKlsBpLJSmjT0OoIiIiclYU4NKlqBqAuki3euBERETkrCjApUthDQBrY726B05ERETOigJcuvg9cKujPRpCFRERkbOyaAHOzO4zs1Yze3lK2z+Y2W4ze9HMvmtmxVOOfdzM9pnZq2b2hintN/tt+8zsrinta8zsOb/9W2aWs1i/ZUHEywBYERmgW0OoIiIichYWswfuK8DNJ7Q9Cmx2zl0I7AE+DmBmm4B3AOf713zezMJmFgb+FbgF2AS80z8X4O+Bzzjn1gNdwAcW8becvUgu5BZREe6jU0OoIiIichYWLcA5554COk9oe8Q5N7GP1LNAnf/6NuCbzrkR59xBYB9whf/Y55w74JwbBb4J3GZmBlwPPOhffz9w+2L9lgUTL6OEPro1hCoiIiJnIch74P4r8CP/dS3QMOVYo992qvYyoHtKGJxon5GZ3WlmW81sa1tb2wKVPw/xMopdL12Do6RS2tBeRERE5ieQAGdmfwUkga+n4/ucc/c457Y457ZUVFSk4ytnll9O4Xg3KQd9w9rQXkREROYn7QHOzN4PvAl4t3NuohuqCaifclqd33aq9g6g2MwiJ7Rntng5eckeAK0FJyIiIvOW1gBnZjcDfwm82Tk3OOXQQ8A7zCzXzNYAG4BfAc8DG/wZpzl4Ex0e8oPfE8Db/OvfB3wvXb9j3uKl5I52Ao5OBTgRERGZp8VcRuQbwC+Bc82s0cw+APwLUAg8amY7zOyLAM65ncADwCvAj4EPOefG/Xvc/hj4CbALeMA/F+BjwEfMbB/ePXH3LtZvWTD55YRTo+QzrKVEREREZN4iZz5lfpxz75yh+ZQhyzn3aeDTM7Q/DDw8Q/sBvFmq2SNeDkCJ9dE5oJmoIiIiMj/aiSGd/MV8y+hVD5yIiIjMmwJcOuV7PXDloT5NYhAREZF5U4BLJ78Hrj53UEOoIiIiMm8KcOk0sR9qdIDeIQU4ERERmR8FuHTKLYRwDpXhfnoU4ERERGSeFODSyQzi5ZRbnwKciIiIzJsCXLrFyyhRgBMREZGzoACXbvllFKd66B1WgBMREZH5UYBLt3g5BakeeofGSKXcmc8XEREROYECXLrllZCX7CXloH80GXQ1IiIikoUU4NItr5jcZB9Gip5BDaOKiIjI3CnApVusGMNRyJAmMoiIiMi8KMClW14JAEU2oIkMIiIiMi8KcOmWVwxAMf3ajUFERETmRQEu3WJegEvYgIZQRUREZF4U4NLN74FLoAAnIiIi86MAl27+PXAloUEFOBEREZkXBbh084dQq6KD9A5pHTgRERGZOwW4dIvmQTiH8oiWEREREZH5UYBLNzOIFVOmIVQRERGZJwW4IOSV6B44ERERmTcFuCDkFZPQOnAiIiIyTwpwQYgVU6BlRERERGSeFOCCkFdMfqqP3uExnHNBVyMiIiJZRgEuCHkl5I33MTbuGBobD7oaERERyTIKcEGIFZOb7CdESmvBiYiIyJwpwAXB306riAH6hnUfnIiIiMyNAlwQpmxo3zusHjgRERGZGwW4IPj7oSbUAyciIiLzoAAXhLzJHrg+9cCJiIjIHCnABcEfQi2mXwFORERE5kwBLgjTeuA0hCoiIiJzowAXhIkeOBtUD5yIiIjMmQJcEKIxiORRHhlUD5yIiIjMmQJcUPKKKQ+rB05ERETmTgEuKLFiSkKDWgdORERE5kwBLih5JZrEICIiIvOiABeUvGJ/Ky31wImIiMjcKMAFJVZMYaqPvhH1wImIiMjcKMAFJa+YeKpPPXAiIiIyZwpwQckrITc1xNDwMM65oKsRERGRLKIAFxR/Md/81ABDY+MBFyMiIiLZRAEuKLEEAEXa0F5ERETmSAEuKBMBDu3GICIiInOjABcUf0P7ItNiviIiIjI3CnBBOd4DpyFUERERmRsFuKD4AU67MYiIiMhcKcAFZdo9cOqBExERkdlTgAtKNI4LRSiyAXqH1AMnIiIis6cAFxQziCVImHrgREREZG4WLcCZ2X1m1mpmL09pKzWzR81sr/9c4rebmX3OzPaZ2YtmdumUa97nn7/XzN43pf0yM3vJv+ZzZmaL9VsWi8USlIaHdA+ciIiIzMli9sB9Bbj5hLa7gJ865zYAP/XfA9wCbPAfdwJfAC/wAZ8ErgSuAD45Efr8c35/ynUnflfmixVTEhpSD5yIiIjMyaIFOOfcU0DnCc23Aff7r+8Hbp/S/lXneRYoNrNq4A3Ao865TudcF/AocLN/rMg596zzNhL96pTPyh7+EKrWgRMREZG5SPc9cFXOuWb/9TGgyn9dCzRMOa/Rbztde+MM7TMyszvNbKuZbW1razu7X7CQYgl/HTgNoYqIiMjsBTaJwe85c2n6rnucc1ucc1sqKirS8ZWzE0tQoIV8RUREZI7SHeBa/OFP/OdWv70JqJ9yXp3fdrr2uhnas0ssQTzVT9+IeuBERERk9tId4B4CJmaSvg/43pT29/qzUa8Cevyh1p8AN5lZiT954SbgJ/6xXjO7yp99+t4pn5U9Ygly3CgjQ4NBVyIiIiJZJLJYH2xm3wCuA8rNrBFvNundwANm9gHgMHCHf/rDwK3APmAQ+F0A51ynmf0t8Lx/3v90zk1MjPgjvJmuecCP/Ed28XdjYKQX5xxZuBKKiIiIBGDRApxz7p2nOHTDDOc64EOn+Jz7gPtmaN8KbD6bGgMXKwagwA0wNDZOPGfR/naIiIjIEqKdGIKU5wU47YcqIiIic6EAFyR/CDVhWkpEREREZk8BLkh+gCtiQIv5ioiIyKwpwAVpIsBpQ3sRERGZAwW4IB3vgRvUEKqIiIjMmgJckCIxXDiHItNuDCIiIjJ7CnBBMoPcBEUM0jukHjgRERGZHQW4oOUVk9A9cCIiIjIHCnABs1iC0rDugRMREZHZU4ALWixBsXrgREREZA4U4IIWS1Bkg/SqB05ERERmSQEuaLEEBVrIV0REROZAAS5osQT5qQH6NAtVREREZkkBLmixBFHGGB4aCLoSERERyRIKcEHLKwbARnoCLkRERESyhQJc0PzttCKjPaRSLuBiREREJBsowAXND3AFbpCBUU1kEBERkTNTgAtazBtC1X6oIiIiMlsKcEHze+CK0GK+IiIiMjsKcEGbCHBazFdERERmSQEuaMd74Aa0H6qIiIjMigJc0CK5pCIxirQfqoiIiMySAlwGcLkJEtpOS0RERGZJAS4DWF6CIhugV9tpiYiIyCwowGWAUKyYYhvSEKqIiIjMigJcJoglKA4NahKDiIiIzIoCXCaIJUjYoO6BExERkVlRgMsEsQSFWkZEREREZkkBLhPEEhS4fnoGR4OuRERERLKAAlwmiJcSJsXYYE/QlYiIiEgWUIDLBPFyAGywPeBCREREJBsowGWC/AoAckY6GU+5gIsRERGRTKcAlwnyywAopVeL+YqIiMgZKcBlAn8Itcx66VaAExERkTNQgMsE+V6AK6WXLs1EFRERkTNQgMsE0TzGI/mUWR/dCnAiIiJyBgpwGSIVL6fMeuga0BCqiIiInJ4CXIaw/HJK6dMQqoiIiJyRAlyGCBeUU2699GgSg4iIiJyBAlyGsIIKykOaxCAiIiJnpgCXKeLllNBH14ACnIiIiJyeAlymyC8nSpLRga6gKxEREZEMpwCXKfzttFy/9kMVERGR01OAyxT+bgyR4Y6ACxEREZFMpwCXKfz9UKPDnQEXIiIiIplOAS5T+EOo+ePdjCTHAy5GREREMpkCXKbwh1DL6aF7UGvBiYiIyKkpwGWKaIzRnGKqrVNrwYmIiMhpKcBlkLH8GlZYJ539CnAiIiJyagpwmaSohmrrpLVvJOhKREREJIMpwGWQaGk91dZBa99w0KWIiIhIBgskwJnZn5vZTjN72cy+YWYxM1tjZs+Z2T4z+5aZ5fjn5vrv9/nHV0/5nI/77a+a2RuC+C0LKVpSR4n109XdE3QpIiIiksHSHuDMrBb4U2CLc24zEAbeAfw98Bnn3HqgC/iAf8kHgC6//TP+eZjZJv+684Gbgc+bWTidv2WhWVEtAGPdTQFXIiIiIpksqCHUCJBnZhEgDjQD1wMP+sfvB273X9/mv8c/foOZmd/+TefciHPuILAPuCJN9S+O4noAQt1HAi5EREREMlnaA5xzrgn4P8ARvODWA2wDup1zSf+0RqDWf10LNPjXJv3zy6a2z3DNNGZ2p5ltNbOtbW1tC/uDFlLpWgDyBxXgRERE5NSCGEItwes9WwPUAPl4Q6CLxjl3j3Nui3NuS0VFxWJ+1dkpWMGo5VI83Bh0JSIiIpLBghhC/U3goHOuzTk3BnwHuBYo9odUAeqAiRvBmoB6AP94AuiY2j7DNdkpFKIvXk/NeDN9w9qNQURERGYWRIA7AlxlZnH/XrYbgFeAJ4C3+ee8D/ie//oh/z3+8cedc85vf4c/S3UNsAH4VZp+w6IZTaxmlR2jqXso6FJEREQkQwVxD9xzeJMRtgMv+TXcA3wM+IiZ7cO7x+1e/5J7gTK//SPAXf7n7AQewAt/PwY+5JzL+l3gQ2XrWGUtNLX3Bl2KiIiIZKjImU9ZeM65TwKfPKH5ADPMInXODQNvP8XnfBr49IIXGKBY/YXkvpSk/+hu2FwXdDkiIiKSgbQTQ4YpWnkxAKljLwdciYiIiGSqWQU4M/uwmRWZ514z225mNy12ccuRlZ/DGBHyOncHXYqIiIhkqNn2wP1X51wvcBNQAvwOcPeiVbWcRXI4Fl1Jaf+eoCsRERGRDDXbAGf+863Av/sTCOw058tZ6Co8h5VjB0mlXNCliIiISAaabYDbZmaP4AW4n5hZIZBavLKWt7GKTaywTlpajgZdioiIiGSg2Qa4D+At33G5c24QiAK/u2hVLXOxugsB6Ni/PeBKREREJBPNNsBdDbzqnOs2s/cAn8Dbk1QWQeX6ywAYOrwt4EpEREQkE802wH0BGDSzi4C/APYDX120qpa58hX1HKaaePNzQZciIiIiGWi2AS7pb191G/Avzrl/BQoXr6zlzcw4VHAJq/pfgFTWby4hIiIiC2y2Aa7PzD6Ot3zID80shHcfnCySoZqrKWCAwYYXgi5FREREMsxsA9xvAyN468EdA+qAf1i0qoSija8DoPXFxwKuRERERDLNrAKcH9q+DiTM7E3AsHNO98AtovPO2cihVBXu8M+DLkVEREQyzGy30roD+BXepvJ3AM+Z2dsWs7DlrjQ/hxejF1DVuRXGk0GXIyIiIhkkMsvz/gpvDbhWADOrAB4DHlyswgTaKq8h3vwYrmkbtvLKoMsRERGRDDHbe+BCE+HN1zGHa2WeCjbeyLgzul/+SdCliIiISAaZbQj7sZn9xMzeb2bvB34IPLx4ZQnAlZvW8aJbx9geTWQQERGRSbOdxPBR4B7gQv9xj3PuY4tZmMCqsjg7ci6hvPslGOoKuhwRERHJELMeBnXOfds59xH/8d3FLEo8ZsbIqusIkWJ8/8+CLkdEREQyxGkDnJn1mVnvDI8+M+tNV5HL2coLXkuvy6PzxR8FXYqIiIhkiNPOQnXOabusgF1zzgp+mdrMVYd/Bs6BWdAliYiISMA0kzTDFcdzOFR8JYmRZujYF3Q5IiIikgEU4LJA7LwbAeh/RcuJiIiIiAJcVrjs4ks4mKqib+cjQZciIiIiGUABLgtsqi7i+fAllLY+B8mRoMsRERGRgCnAZYFQyOirex25bpjxw88GXY6IiIgETAEuS9RcfCNjLkzbDm2AISIistwpwGWJazauZodbjzv4dNCliIiISMAU4LJEIh7lUOGlVPbvguGeoMsRERGRACnAZZHI+usIk6J795NBlyIiIiIBUoDLIudc+nqGXZTWFx8LuhQREREJkAJcFtm0spKXQucRb/p50KWIiIhIgBTgsoiZ0V5xJXUj+0n2tQVdjoiIiAREAS7LFG28AYBD27Qrg4iIyHKlAJdlNl9+HQMul75djwddioiIiAREAS7LJArivJp7IeVt2pFBRERkuVKAy0JDdddQn2qkvflQ0KWIiIhIABTgstCKi24EYP9zPwq4EhEREQmCAlwWWrv5avqIM3bgmaBLERERkQAowGUhC0doKriAFb07SI6ngi5HRERE0kwBLkvZqmtYTyMv7jkYdCkiIiKSZgpwWaru4usBOPRrbaslIiKy3CjAZan81VcwRpTUYS0nIiIistwowGWraIy2xPmsG3qRlt7hoKsRERGRNFKAy2I5a65lsx3kmVeOBF2KiIiIpJECXBYr2/Q6ojZOw0tPBV2KiIiIpJECXBaz+itJYUQan2NMy4mIiIgsGwpw2SyvmP7EOVyY2sX2w11BVyMiIiJpogCX5WLrXsOlob08vac56FJEREQkTRTgslzO2mspsGGadz0fdCkiIiKSJgpw2W7l1QAUd2yle3A04GJEREQkHQIJcGZWbGYPmtluM9tlZlebWamZPWpme/3nEv9cM7PPmdk+M3vRzC6d8jnv88/fa2bvC+K3BK6ohpGCerbYq/xif0fQ1YiIiEgaBNUD91ngx86584CLgF3AXcBPnXMbgJ/67wFuATb4jzuBLwCYWSnwSeBK4ArgkxOhb7mJrr2WK0Kv8szetqBLERERkTRIe4AzswTwWuBeAOfcqHOuG7gNuN8/7X7gdv/1bcBXnedZoNjMqoE3AI865zqdc13Ao8DNafwpGSO06hrKrJfDe14MuhQRERFJgyB64NYAbcC/mdmvzez/mlk+UOWcm5hKeQyo8l/XAg1Trm/0207VfhIzu9PMtprZ1ra2JdhLteoaAOr6dnCkYzDgYkRERGSxBRHgIsClwBecc5cAA0wOlwLgnHOAW6gvdM7d45zb4pzbUlFRsVAfmznK1pPMK+OK0G6e3rcEA6qIiIhME0SAawQanXPP+e8fxAt0Lf7QKP5zq3+8Caifcn2d33aq9uXHjPDqa7gmvJvHX2kJuhoRERFZZGkPcM65Y0CDmZ3rN90AvAI8BEzMJH0f8NbqYFAAACAASURBVD3/9UPAe/3ZqFcBPf5Q60+Am8ysxJ+8cJPftizZmtdRTRuH971Ez9BY0OWIiIjIIooE9L1/AnzdzHKAA8Dv4oXJB8zsA8Bh4A7/3IeBW4F9wKB/Ls65TjP7W2BiBdv/6ZzrTN9PyDDrrgfgal7k0VdaeNtldQEXJCIiIoslkADnnNsBbJnh0A0znOuAD53ic+4D7lvY6rJU2TpcyWpu6tnJvS8eVYATERFZwrQTwxJi667nCnby3N5jtPWNBF2OiIiILBIFuKVk3fXkpga50O3ha88eDroaERERWSQKcEvJ2usgEuPOipf42rOHGR4bD7oiERERWQQKcEtJbiFsuInfGH2G7oEhvrN9ea6qIiIistQpwC01m99KznA776w8wr8+sY/RZCroikRERGSBKcAtNee8AXIK+FD5Dpq6h/jW1oYzXyMiIiJZRQFuqYnmwabbWdHwQ66rD/Mvj+/VvXAiIiJLjALcUnTNH2Njg/xt9TO09I7w9eeOBF2RiIiILCAFuKWociOc9ybq9/w716/J4wtP7mNgJBl0VSIiIrJAFOCWqtd8BIa7+VTd87T3j3L/Lw8FXZGIiIgsEAW4paruMljzWup33ceN5yT40s8O0DusTe5FRESWAgW4pew3/hv0H+N/1O2gZ2iM+545GHRFIiIisgAU4JayNa+Fuiuo3flFbt1Uyr1PH1QvnIiIyBKgALeUmcFrPwo9Dfz3upfoG0lqj1QREZElQAFuqdtwI1RfRN1Ln+d160u475lDWhdOREQkyynALXUTvXBdB/nEql2094/w4LbGoKsSERGRs6AAtxyc+0ao3MT6V7/EJXVFfOmp/STHtUeqiIhItlKAWw5CIfiNv8DaX+Vv1u+noXOIx3a1Bl2ViIiIzJMC3HJx/lugbD0XH/4KNUW5/Puzh4KuSEREROZJAW65CIXhqj/Emn/NX2zq4ef7OtjX2h90VSIiIjIPCnDLyUXvhFiCNw3+JznhkJYUERERyVIKcMtJTj5c+l5y9/6Qd51nfHtboza5FxERyUIKcMvNFXcCjj/Ie5y+kSQPvXA06IpERERkjhTglpvilXDem6ja9y0uqIjwrecbgq5IRERE5kgBbjm66g+x4W4+VvMCOxq62dPSF3RFIiIiMgcKcMvRyquh+iKuavsPomF4QL1wIiIiWUUBbjkygyv/kEjnHv54ZSP/ueOodmYQERHJIgpwy9X5b4FYgrdHnqK9f4RnD3QGXZGIiIjMkgLcchWNwea3Ut38U1bkjvLQC01BVyQiIiKzpAC3nF30Tiw5xJ/X7OJHLx9jJDkedEUiIiIyCwpwy1nd5VC6jjeMP0HfcJInX20LuiIRERGZBQW45cwMLnonxa2/4oJ4lxb1FRERyRIKcMvdRb8NwIcrd/DTXS0MjmprLRERkUynALfcFa+E+qu4euQZhsdSPL23PeiKRERE5AwU4AQ2vZn8rl2cH2vnsVdagq5GREREzkABTmDjmwH4YMXLPL67lfGUC7ggEREROR0FOIHieqi5lNcmf0nHwCjbj3QFXZGIiIichgKceDa9meKul1gVbudRDaOKiIhkNAU48fjDqHdW7OTRV1pwTsOoIiIimUoBTjxl66DqAm7kOQ62D7C/rT/oikREROQUFOBk0qY3U9H9AhV08cRu7cogIiKSqRTgZNLG38Jw/E7xTh7f3Rp0NSIiInIKCnAyqeI8KFnNLbGXeP5QJ33DY0FXJCIiIjNQgJNJZrD+Rtb2byWcGuEZ7cogIiKSkRTgZLoNNxFODnFdbK+GUUVERDKUApxMt/o1EInxjpJXtSuDiIhIhlKAk+ly4rD6NVw++jwdA6P8WrsyiIiIZBwFODnZhpsoGDjMunCrdmUQERHJQApwcrL1vwnAeyv2KsCJiIhkIAU4OVnZOihdyw2RFznQPsC+Vu3KICIikkkU4GRm62+kpnsruYyqF05ERCTDBBbgzCxsZr82sx/479eY2XNmts/MvmVmOX57rv9+n3989ZTP+Ljf/qqZvSGYX7JEbbiRUHKI3644zKOvHAu6GhEREZkiyB64DwO7prz/e+Azzrn1QBfwAb/9A0CX3/4Z/zzMbBPwDuB84Gbg82YWTlPtS5+/nMhbCnbx64Zu2vpGgq5IREREfIEEODOrA94I/F//vQHXAw/6p9wP3O6/vs1/j3/8Bv/824BvOudGnHMHgX3AFen5BctANA9W/wabBp/DOfjpLg2jioiIZIqgeuD+CfhLIOW/LwO6nXNJ/30jUOu/rgUaAPzjPf75x9tnuGYaM7vTzLaa2da2traF/B1L24Ybye05yBVF3boPTkREJIOkPcCZ2ZuAVufctnR9p3PuHufcFufcloqKinR9bfbbcCMAv1u5h2f2tTM4mjzDBSIiIpIOQfTAXQu82cwOAd/EGzr9LFBsZhH/nDqgyX/dBNQD+McTQMfU9hmukYVQuhbKNnDV+DZGkime2K3eSxERkUyQ9gDnnPu4c67OObcabxLC4865dwNPAG/zT3sf8D3/9UP+e/zjjzvnnN/+Dn+W6hpgA/CrNP2M5WPDTRS3/oq1RfDN548EXY2IiIiQWevAfQz4iJntw7vH7V6//V6gzG//CHAXgHNuJ/AA8ArwY+BDzrnxtFe91G24ERsf4c/XH+Ppve0cah8IuiIREZFlL3LmUxaPc+5J4En/9QFmmEXqnBsG3n6K6z8NfHrxKhRWXQM5BdwQeYFwqJpv/OoIH791Y9BViYiILGuZ1AMnmSiSC2uvI37op9y8qYqvPXuYYz3DQVclIiKyrCnAyZltuBF6G/mryx1jKcenH9515mtERERk0SjAyZlteANg1DT/lD+6bh3ff+EoP9ujGakiIiJBUYCTMyuqhpVXw87v8AevW8f6ygL+8sEXaOgcDLoyERGRZUkBTmbngrdB225ix7bxz++8hKHRcd755WcV4kRERAKgACezc+FvQywBP/8sG6uL+PrvXUXv0Bhv+fzP2X6kK+jqRERElhUFOJmd3AK4+o9h9w/g4NNcUJfgO390LfGcCG//4i/59A9foWdwLOgqRURElgUFOJm9a/4EilfCj/4SxpOsryzgoT++lrdfVseXnz7INXf/lE99fye7j/UGXamIiMiSZt6uVMvHli1b3NatW4MuI3vt+gF8693wmj+H3/wfx5tfOdrLl57az8MvNTM27rigNsGtF1Rz+eoSNtcmiEXDgZUsIiKSrcxsm3Nuy0ntCnAyZ9//M9j2b/D2++H826cd6hwY5Xs7mnhwWyM7j3o9cdGwsbk2wWUrS7hsVQnn1ySoLckjHLIgqhcREckaCnA+BbgFkByBr7wJml+A9zwIa14742nt/SNsP9zFtiNdbD/cxQuNPYwmUwDkhEOsKouzpjyfNRX5rC3PZ21FAWvK8ynLz8FM4U5EREQBzqcAt0AGO+HfboXuI95Q6uW/B6HT31I5mkyx82gPe1r6ONA+wMG2AQ60D3C4Y4Cx8cl/DgtjEdZWFLC2PN8LeOX5rK3wnuM5gW7fKyIiklYKcD4FuAXUdwy++0E48CTUXwnX3QVrXw9z7D1Ljqc42j3MgfZ+DrQNcLB98tHUPTTt3BVFseNhbm1FARsqC1hfWUBVUUxDsiIisuQowPkU4BaYc7D9q/Dk3dB3FFZcCBe9Aza/FQpXnPXHD42Oc6hjMtDtb+vnYPsAB9oG6BmaXLYkEjKqimLUleSxsjROfWmc+tI86kvirCyNU1GYq2FZERHJOgpwPgW4RZIcgR1fh21f8e6NsxDUXwXrr4d1N0D1xWccYp2r9v4R9rb0s7+tn+aeIZq6hmjsGqKha5CW3pFp5+ZGQtPDXcmUkFcapygWXdDaREREFoICnE8BLg3a98JL/wF7fuyFOYB4GdRcClXnQ9Vm77l8A4QXJzgNj40fD3ONnYMc6RykodN7f6RzkL7h5LTzi+NRP9TlTQ94JXnUluSRG9EyKCIikn4KcD4FuDTrb4MDT3j3yTW/CG27IeUPfYaiULkRai72euhqLoHKTRCNLXpZPYNjNHQN0jAR7rr8gNc5SGPXEKPjqePnmnn33k3rtSuJs7IszioNz4qIyCJSgPMpwAVsfMzroWvZCS0veaHu6K9huNs7bmEoPwdWXAArNvvB7mJvH9Y0SaUcrX0jXm9dx/Rw19A1yLHeYab+a5PIi3JOVQEbqgo5p7KAc6oKWV9ZoGAnIiJnTQHOpwCXgZyD7sNwdAe0vAzHXvIevU2T55RtgNpLvWHY2kuh4ty0hrqpRpLjHO0e5kjnIIfaB9jT0seelj5ePdZH75Sh2cLcCGsrC1hXkc/6ygI2VBayobKA+tK4ZsyKiMisKMD5FOCyyEAHNP8amn4NR7dD03boPzZ5fMWF3n10Fed599RVboJEPYSDWSvOOa/nbk9LHwfavBmz+9v62d86wLHe4ePn5UZCrJ/SUzfxvFLBTkRETqAA51OAy3K9R70h12Mvw5FfQOcBbzHhCeFcWHmlN1GieBVUngfFK6FkzZzXp1tIfcNj7G3tZ19Lv9dj19rP3pY+mnsmg11OOMTaivzjM2WrEzFWJGJUJ2LUlcSpKMglpIAnIrKsKMD5FOCWoJE+aN0NrTuh7VU49Ax07IOxwclzonEv0NVt8SZLVJzr3WuXXxFosOsdHmN/az97W/vZ39rPvtb+4/fcDY2NTzs3JxKirtibFVtXEqeuJI+6Em/WbF1JHhUFuudORGSpUYDzKcAtE85Bfyu07YKuw97s1/a90Pj85IQJgPxKWHWNt5NE6VpvVmzxykBDHXjDsb1DSZp7hzjaPbnGnffwZsp2DIxOuyYvGmZVWZzVZfmsKo+zpiyfVWX5rC6PU1UYU++diEgWOlWA08aSsjSZQWGV95jKOehp8MJc+15vOPbQ0/DKf06eE0t499dVnOf10lVfBAWVULomjeUbiXiURDzKeSuKZjxncDQ5bfHiwx2DHO4YYG9rH4/vbp22FEpuJMSqsrgX6Mq8IdrKwhgX1xdTVaSeOxGRbKMeOBHnYKANOg96s2CbX/Ce2/fCSO/keTWXQO1lXqCrvtgLeJGc4Oo+jfGUo7lniMMdgxzqGOBwxyAH2wc47L8eSU6Gu+J4lPUV3p6yUx81iTz12omIBExDqD4FOJk156CvGZq2effW7X/CC3ejfd7xcK63pMnKq/1h2CsCW9pkLlIpR8fAKA1dg7zQ0O1NrvAfnVOGZeM5YdadEOzOW1FIfUlcwU5EJE0U4HwKcHJWUinoOgjNO7xlTY780gt1qaS3/2vV+bDyGlh1tfd84hBuhuscGGVfaz97W/uOh7p9rf3TZsvm54Q5d0Uh51UXcW5VIRuqCti4ooiS/MzsjRQRyWYKcD4FOFlwowPe5IjDv/SWNml4HpJD3rHStd59dKuu8YZfV14DoVCw9c5D/0iSfa397G7uZfexPnY197KruXfawsVVRblsrC7ivBVFbKwuZGN1EWvL84mEs+/3iohkCgU4nwKcLLrxMa9X7vAvvB669j3esibgDbHWboG6y6H+ci/U5ZUEW+88TSxc/OoxbxeKXc297DrWx77WPsbGvT9XcsIh1vlDr+f6j/NWFLKiKKaJEyIis6AA51OAk0B0H4HGrXDwZ95z6yvg/IkE5ed4ga5uixfuys+BaCzYes/CaDLF/rZ+djX38uqxPnb7AW/qbhSFuRHWVxVwTqU3BLuhqpBzqgoU7ERETqAA51OAk4ww0uctYdL4vBfoGp/3ZsJOKFjh7yCxynsunnhe6W0XlqGzX0+ne3CUV495+8bubfV2pNjb0j9tPbuJYLfhhK3GqhMKdiKyPCnA+RTgJCM5B92HvTDXeRC6D3m9dl2HoacR3NRdGQyKak4OdhNhr6gWwtGgfsmcdfSPsNffWuxUwS4vGmZ1eT5ry/NZM/Go8N4Xx7MvzIqIzJYCnE8BTrLOeNJbzqT78GSo6z4y+b63aXI4FsDC3jBs+QYoXOEtQlywAmouhrINWTM8ezzYtfZzsG2Ag+39HGwfoKFriPHU5J9bJfEoq8vzj28vVl8SZ1VZnJX+frKaRCEi2UwBzqcAJ0vO+JjXSzcR6joPevfYdR6E/mMw3DP9/MJqb6eJklXeYsRV53tbiOUWBb6F2GyMJlM0dA36oW6AA+0DHGofoKl7iOaeoeMTKADCIaO2OI/60jxWlno7UKwsjbOmPJ+15QXk5YQD/CUiImemrbRElqpw1Nvm61RbfY0NQe9Rb0HirkPQsR+OvQSHnoGxgcnzovlekJvYE7b+SlhxAcRm3sorKDmREOsqClhXUXDSsfGU41jvMIc7BmjsHOJI5+DxxyM7W07aP7YmEWN1eT7ViTxqS/JYUx5nTXkBa8ryScSzZxhaRJYf9cCJLFfjSehv8ZY86dgLPU3QstPryes5MnlefgWUrfd66yo3QaX/nF8eXO3z1D+S5HCH33PXNsCBtn6OdA7S3DNMS+8wU0ZmKc3PYU15PvUleawsy2fjikJWleVTX5pHYUzhTkTSQ0OoPgU4kVkY6PBmxrbths4D3lp2rbtguHvynNwEVJzr32+3Hqo2e8GuqCYrhmJPNJIcp6FziIPtk/fbHWwfoKHTG5o9MdxNDMfWleRRnYixuiyftRVeb15YW42JyAJRgPMpwInMk3PQdwzadnlhrvOgNyzbe9S7125CrNi7r67iPG84duI+u8IVWRnsAIZGx9nv99ZNPBr856auIZJT0l0kZNT4993Vl3j33dWV5FFfGqe+JE55QY6WRBGRWVOA8ynAiSyCoS5oecWbPNGy03u0vQojUyZQxMv8CROboHSdF+7K1npLoYSydzJBKuVo6x+Z0mM3SEPXEA2dgzR2DdLeP/2+u7xomLoS75676kSMlaX5rCmPU1cSp6ooRll+DiH14ImITwHOpwAnkibOwWCn12PXshNaXvaeW3dPnzwRiXlLnlRu8pY5KVvr3XNXth5y8oOrf4EMjiZp9APd1HDX1D3EsZ7hkyZWRMNGnb8USk1xHrXFedQUx1hVls+6igISebr/TmQ5UYDzKcCJBMw56G+Fzv3ejNj2V70h2dbd0Ns4/dzCGihb5wW8iVBXstrbjSInHkj5C61veIxD7V6ga+kdprlnmCOdA97kiu6TA15hLOKHOi/YTYY871FVmKu170SWEAU4nwKcSAYbHfQmTXTsm/5o3zt9AgV4s2Onbi82bWeK+iXRewfe/XdHe4aOz5o92j1EU/cwR7uHONozRPfg2LTzQwYrimLHA50X8Ka/L4pFdB+eSJZQgPMpwIlkoYnh2I5903ehmHj0NMD49J4q4uVQVA2JlZO9eMWrIFHnbTeWJTtSnMnASJLmnimhrnuIJv/5aPfwSYsbAxTkRo733lUnpge82uI8qopi5ETUiyeSCbSQr4hkLzPIL/MeK688+XgqBQOtU0LdxDZjzd5Q7b5HZw54iVooqvOfa71wNxHwCqshnPl/RObnRlhfWcj6ysIZj6dSjvb+ET/UDU8LeM09w7zU2HPSMK0ZVBbmTgt1NYnpIa84HlUvnkiA1AMnIktfanwy3PU2eYsW9zZ6zz2NXttI7/RrLOTtITs13BVWewsYl6zxngsqIXfm4JRNhkbHae45OeAd9duauocYTaamXZMXDc94D15NcYza4jxWJGLkRrJ3drFIplAPnIgsX6Hw6bcbAxjuPTnc9foBr+Vl2PNjSA6ffF1htbfGXcEKKKzy3hdUeW0T7fkVGd2bl5cTZm1FAWtn2J4MwDlHx8DolCHayeHao91D7Gruo71/5KTrKiZ68RIxKgpzqSqKsarMWwC5pjiPsnytiScyX5n7J4qISDrFirxH5caZjzsHwz0w0OZNtBjq8sJd10Hoa/FeN22FgXbghJENC3lDtsdDnR/0Cqv84Dfxusrb2zbDmBnlBbmUF+RyYV3xjOcMj41zrGdqD97kRIs9LX38Yn8HPUPTJ1zkRELHh2Zri7218Wr8e/CqinKpKoxpqFbkFBTgRERmwwzyir1H+YZTnzc+5i2T0n/M27mi75i352xfsxf0+o95+88OtIFLnXx9vMwPdNXebNqJWbZFtd42ZYXVEMlZvN85T7FomNXl+awuP/Xs34GR5PGdLJr9e/Amhmuf2ttGa98IJ97Vk58Tpq7E37KsOEZ1whumrU7kUZPIoyqRq6FaWZYU4EREFlI46t03l6g9/XnjSRhsnwx2fc1+0PNDX2+T16M31HXytRMzbAtrvHvziusnl1Ip8HvyMnCWbX5uhI3VRWysLprx+GgyxbGeYVr6hmntHfFn1w7R2OU9th3pOmnZFIDyglxqS/KoK54Md1VFMSqLcqkszKWiMJd4jv5zJ0uL/okWEQlCODI5pHo6I33e8GxPE/Qd9WbWTjz3HoWG505eIw8glpi8L2/inryi2un36xWsyKgFkXMiIVaWxVlZduqaBkeTNPcM0+wvkdI8Zdh2V3Mvj+5qOWnCBXhLp1T4Ya6iMJeKglxK83MoK8ihLD/Xf86hrCCXwtyItjOTjJf2AGdm9cBXgSq8G0Xucc591sxKgW8Bq4FDwB3OuS7zbn74LHArMAi83zm33f+s9wGf8D/675xz96fzt4iILLrcQu++vFPdmwdeyOtu8IJevz9MOzFc298KDb/yevXGT55oQG7C680rqvUmW8TLvHCXqJ+8Xy+DZtvGcyKsqyhg3WkmXHQNjtHSO0xb3witfSP+8+T7V4720tE/Qu9wcsbPCBkUxqIU5UUoikUpjkcpjudQnOe/zsshEY/673P8tihFeVFyIyHdsydpkfZlRMysGqh2zm03s0JgG3A78H6g0zl3t5ndBZQ45z5mZrcCf4IX4K4EPuucu9IPfFuBLXhBcBtwmXNuhvGGSVpGRESWJee84djeo9MDXl+LN1zbe9Qb0h3omL5X7YRovhfkJgJdQdVk797UtvyKjJyIMZPRZIquwVHa+0fo6B+lY8B77hkao3dojN7hJD1DY3QPjtI9NEbP4BjdQ2OMp079381IyMjPjVCQG6Ew5j0XTDznRohFw+TlhMmLhonnhMnPjRD33+flhIlFw8QiYWLRkPc6Ovk6qi3SlqWMWUbEOdcMNPuv+8xsF1AL3AZc5592P/Ak8DG//avOS5rPmlmxHwKvAx51znUCmNmjwM3AN9L2Y0REsoUZxEu9B5tPf+5wz5TevFZ/Ikar/74F2l6Fgz/zzjv5i7xevDMFvYIqb5g3wN6qnEjIn/E6+/sFnXP0jyTpHhzzHkOj/utR+kaS9A8nGRhJHn/dP5Kka2CUI52D9A8nGR4bZ3gsxej4DBNYziASMi/45YbJz4mQEwmRGw2TGw6RGw2RGwl5bZHwlNcztYWPH5t2PBoiJxwiFg2REw6f9JlhDStnlEDvgTOz1cAlwHNAlR/uAI7hDbGCF+4aplzW6Ledqn2m77kTuBNg5cqVC1O8iMhSFUt4j6rzT3/e2LC3A8bUcNfXMhn8+lugY7/X03fiThgA4dwTQl2lP2zrv48VQyQGKy7ImJm3ZkZhLEphLEp96fw/JzmeYnBsnMGRcQZGkwyNjh8Pd0Nj3uuhsXFGZmibuGYkmWIkmWI0OU7/SJLOgZTfNs6of2xkzHt/mk7DWYuE7DShcHowPDEUhkNGJGTHnyNT2nIjISLhECEzQgahkJETDhENh4iEjWjYCIdC064Ph4yo/xlTj+dEvOdIKEQ4PHlu2GzJ3dcYWIAzswLg28CfOed6p94z4JxzZrZgY7vOuXuAe8AbQl2ozxURWdaiMW/ma/EZ/sfYOW+ixfGg1zo543biddchb0LGYPvMnxFLeMOz+RXeLhj5FZBf6W9/Vuu9Lqjyev9CmT/UGAmHKAqHKIqlZ7g5Oe71+nmBLuUHvPHjIXBa6JtyfGoQHB0fP+n6Ez+ze3B0yvHJgJlykEylSI47kguRJufBzAuhIfMDoh/2Jo5Fw17YxCA57sjzh6+nhs3QCT3G//quS0nEg7llIJAAZ2ZRvPD2defcd/zmFjOrds41+0OkrX57E1A/5fI6v62JySHXifYnF7NuERH5/9u72xi5qjqO49/fznS32xbaApUgRQtCwJpAKQTBokGIBAghvqgPiEhIE95gAolGqY8RE6NvQEwIYkTFSABBENIYeSiEBI2UAgVaSqVgCSXQQtttabvb3Zn5++Kc6c4u2+5ad+f2dn+f5GbuPefMnTP/7N397zn34QBI0D07LXNO3n/b+kC6R97OTemcvd5tsOWNVNZc3n8N3vwn7N7Kh2+aXEnJXetUbee0wStwm/1otpkyrdBp3HapVlIiMu0gGMiMiCEJ3Z5ag1qjQQTUG0Ejglo96K+nRLDeSElfek3vaZbV6o302mgwUE/vG8hljb3vG7qd3pfaDeSp7AgYyPtoRFDtEL39KcGtN1LbPSNc3VykIq5CFXAHsDYibmqpehi4Cvh5fn2opfybku4hXcSwPSd5jwA/kzQ7t7sQWNqO72BmZhOkMiXdsPjwj47etj6QztX74J08ktcyldtMAjetgf5dsGek8/WASmeaqm1OG3e3rO+3fFZ6ckdJLtg4mEiiIqh0VOiqwvSuontUTkWMwC0CrgRelrQql32PlLj9WdIS4E3gy7nub6QrUNeTbiNyNUBEbJX0U+DZ3O7G5gUNZmY2CVSmjP6M26bebWnErrcHerfmBG9zmtrt7UkXZPT1pHbbNuSyHmiMfKuRvTpn7D/h6zo8TTVXulLCF43BdpVO6JyeRgSndKftSTAaaOOj7bcRKZpvI2JmZmMSAQO7c3K3fWiit8+yHujNdfsa9dsnpYs2pkxN992bOjNN8XZUoaMyOFo47chUP6U7LdWpqd2U/DridktbJ4mlctDcRsTMzKwUpDRC1jl9bFO6wzXqsGcH1Pqh1pfW1TGY/NX7Yc/OlPTV+tJVvbW89O1I5QO9kyNmRQAACFxJREFUaT+1/nTD5i2vw+4t0L9z5GfpjkW1ex/JXneuGykxHFa3v7bVqel7qiMln53TnTROACdwZmZmE6GjkqZHJ0JESgAHetNSy68DfWnUsNY3Ql3rdt/IdX3bB/ezt273gSeLkBK5Slea8u6oDo4odlTTVLM60vfpnJHK+3em9a7DWtrn96CcHDI0Sax0QrUrfU5HTm325ox5RRq2nuta15v9nfWxlHimYEOjkWIQ9ZRQRz1tn3Jp+twCOIEzMzMrGyklDtWulARNpIh0wchYE8FaX052AhoDaeSw1gf1Wtpu1NO5hY1aOuew+Rn9u1LdtKPSaGXPW7ndQHpt7jMiJ5SR9zWQ+7cnrbfTt9fDjDnt/czMCZyZmZntm5RupFztTOflHcyaI2XN28tEDFtn9LpGHba+kZLCpo5Ky4hfJd2uZiJHWMfACZyZmZkdGjo6gHG4kfOxC///fUywg/921WZmZmY2hBM4MzMzs5JxAmdmZmZWMk7gzMzMzErGCZyZmZlZyTiBMzMzMysZJ3BmZmZmJeMEzszMzKxknMCZmZmZlYwTODMzM7OScQJnZmZmVjJO4MzMzMxKxgmcmZmZWck4gTMzMzMrGSdwZmZmZiWjiCi6D20l6T3gzQn+mKOA9yf4M8rOMRobx2l0jtHoHKOxcZxG5xiNbrxj9PGImDO8cNIlcO0gaWVEnFl0Pw5mjtHYOE6jc4xG5xiNjeM0OsdodO2KkadQzczMzErGCZyZmZlZyTiBmxi/KboDJeAYjY3jNDrHaHSO0dg4TqNzjEbXlhj5HDgzMzOzkvEInJmZmVnJOIEzMzMzKxkncONM0kWS1klaL+mGovtTFEm/k7RZ0uqWsiMkPSbptfw6O5dL0q9yzF6StLC4nrePpOMkPSnpFUlrJF2Xyx2nTNJUSSskvZhj9JNcfrykZ3Is7pXUmcu78vb6XD+vyP63k6SKpBckLcvbjtEwkjZIelnSKkkrc5mPtxaSZkm6X9KrktZKOscxGkrSyflnqLnskHR9u+PkBG4cSaoAtwIXA/OByyXNL7ZXhfkDcNGwshuA5RFxErA8b0OK10l5uQa4rU19LFoN+FZEzAfOBq7NPy+O06A9wPkRcRqwALhI0tnAL4CbI+JEYBuwJLdfAmzL5TfndpPFdcDalm3HaGSfj4gFLffp8vE21C3A3yPiFOA00s+UY9QiItbln6EFwBnAbuBB2h2niPAyTgtwDvBIy/ZSYGnR/SowHvOA1S3b64Bj8voxwLq8fjtw+UjtJtMCPAR8wXHaZ3ymAc8Dnybd5byay/ced8AjwDl5vZrbqei+tyE2c0l/MM4HlgFyjEaM0wbgqGFlPt4Gv+NM4D/Dfx4co/3G7ELgH0XEySNw4+tY4K2W7Y25zJKjI+KdvP4ucHRen/Rxy9NYpwPP4DgNkacGVwGbgceA14GeiKjlJq1x2BujXL8dOLK9PS7EL4HvAI28fSSO0UgCeFTSc5KuyWU+3gYdD7wH/D5Px/9W0nQco/35KnB3Xm9rnJzAWSEi/Rvie9gAkmYAfwGuj4gdrXWOE0REPdJUxVzgLOCUgrt0UJF0KbA5Ip4rui8lcG5ELCRNaV0r6XOtlT7eqAILgdsi4nRgF4PTgIBj1CqfV3oZcN/wunbEyQnc+HobOK5le24us2STpGMA8uvmXD5p4yZpCil5uysiHsjFjtMIIqIHeJI0HThLUjVXtcZhb4xy/UxgS5u72m6LgMskbQDuIU2j3oJj9CER8XZ+3Uw6Z+ksfLy12ghsjIhn8vb9pITOMRrZxcDzEbEpb7c1Tk7gxtezwEn56q9O0tDqwwX36WDyMHBVXr+KdM5Xs/wb+Uqds4HtLcPQhyxJAu4A1kbETS1VjlMmaY6kWXm9m3SO4FpSIrc4Nxseo2bsFgNP5P+ED1kRsTQi5kbEPNLvnCci4gocoyEkTZd0WHOddO7Sany87RUR7wJvSTo5F10AvIJjtC+XMzh9Cu2OU9EnAB5qC3AJ8G/SeTrfL7o/BcbhbuAdYID0X90S0nk2y4HXgMeBI3Jbka7efR14GTiz6P63KUbnkobYXwJW5eUSx2lIjE4FXsgxWg38KJefAKwA1pOmL7py+dS8vT7Xn1D0d2hzvM4DljlGI8bmBODFvKxp/n728fahOC0AVuZj7q/AbMdoxDhNJ41cz2wpa2uc/CgtMzMzs5LxFKqZmZlZyTiBMzMzMysZJ3BmZmZmJeMEzszMzKxknMCZmZmZlYwTODOzNpB0nqRlRffDzA4NTuDMzMzMSsYJnJlZC0lfl7RC0ipJt0uqSNop6WZJayQtlzQnt10g6V+SXpL0oKTZufxESY9LelHS85I+kXc/Q9L9kl6VdFd+GoeZ2f/MCZyZWSbpk8BXgEURsQCoA1eQ7rq+MiI+BTwF/Di/5Y/AdyPiVNId1pvldwG3RsRpwGdITyUBOB24HphPejLAogn/UmZ2SKqO3sTMbNK4ADgDeDYPjnWTHkjdAO7Nbf4EPCBpJjArIp7K5XcC9+XnbR4bEQ8CREQfQN7fiojYmLdXAfOApyf+a5nZocYJnJnZIAF3RsTSIYXSD4e1O9BnEO5pWa/j38FmdoA8hWpmNmg5sFjSRwAkHSHp46TflYtzm68BT0fEdmCbpM/m8iuBpyLiA2CjpC/mfXRJmtbWb2Fmhzz/92dmlkXEK5J+ADwqqQMYAK4FdgFn5brNpPPkAK4Cfp0TtDeAq3P5lcDtkm7M+/hSG7+GmU0CijjQmQAzs8lB0s6ImFF0P8zMmjyFamZmZlYyHoEzMzMzKxmPwJmZmZmVjBM4MzMzs5JxAmdmZmZWMk7gzMzMzErGCZyZmZlZyfwXbiZpeUlVwMEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Using MinMax Scaler**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fhJERXPrslAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the numerical features using Min Max Scaler\n",
        "\n",
        "ct = make_column_transformer((MinMaxScaler(),['age', 'bmi','children'] ),\n",
        "                             (OneHotEncoder(), ['smoker', 'region', 'sex'])\n",
        "                             )\n",
        "insurance_minmax_scaled = ct.fit_transform(X)\n",
        "\n",
        "insurance_minmax_scaled[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sntizrZsTmO",
        "outputId": "069862aa-4534-4e10-ed8a-77835cf39d05"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.02173913, 0.3212268 , 0.        , 0.        , 1.        ,\n",
              "       0.        , 0.        , 0.        , 1.        , 1.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the date into train, test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(insurance_minmax_scaled,y,test_size = .2, random_state = 42)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52XC76RIs8ec",
        "outputId": "178c302c-b5ba-432b-d0ce-08ff6553d942"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1070, 11), (268, 11), (1070,), (268,))"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build the Model**"
      ],
      "metadata": {
        "id": "s-d0hFQ2tK71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "insurance_model1 = tf.keras.Sequential([\n",
        "              tf.keras.layers.Dense(100, activation='relu', input_shape = (11,)),\n",
        "              tf.keras.layers.Dense(10, activation='relu'),\n",
        "              tf.keras.layers.Dense(1)\n",
        "\n",
        "              \n",
        "\n",
        "] )\n",
        "\n",
        "# Compile the model\n",
        "insurance_model1.compile(loss=tf.keras.losses.mae,\n",
        "                         optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                         metrics=['mae']\n",
        "                         )\n"
      ],
      "metadata": {
        "id": "6O3ZStVCfHfC"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ealy_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "# train the model\n",
        "history = insurance_model1.fit(X_train,y_train, validation_data=[X_test,y_test],callbacks=[ealy_stopping] ,verbose = 1, epochs = 1000)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-NtCrPZtXLB",
        "outputId": "83ed3166-2450-4871-815c-4ac945bf1e45"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "34/34 [==============================] - 1s 7ms/step - loss: 13345.4658 - mae: 13345.4658 - val_loss: 12966.6357 - val_mae: 12966.6357\n",
            "Epoch 2/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13342.7061 - mae: 13342.7061 - val_loss: 12962.4463 - val_mae: 12962.4463\n",
            "Epoch 3/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 13336.0508 - mae: 13336.0508 - val_loss: 12952.4268 - val_mae: 12952.4268\n",
            "Epoch 4/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13321.6934 - mae: 13321.6934 - val_loss: 12932.6582 - val_mae: 12932.6582\n",
            "Epoch 5/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13295.6250 - mae: 13295.6250 - val_loss: 12899.2734 - val_mae: 12899.2734\n",
            "Epoch 6/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13254.4180 - mae: 13254.4180 - val_loss: 12849.1260 - val_mae: 12849.1260\n",
            "Epoch 7/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13194.6797 - mae: 13194.6797 - val_loss: 12778.8047 - val_mae: 12778.8047\n",
            "Epoch 8/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13112.8623 - mae: 13112.8623 - val_loss: 12684.1719 - val_mae: 12684.1719\n",
            "Epoch 9/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13005.2119 - mae: 13005.2119 - val_loss: 12562.5000 - val_mae: 12562.5000\n",
            "Epoch 10/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12869.2695 - mae: 12869.2695 - val_loss: 12410.8545 - val_mae: 12410.8545\n",
            "Epoch 11/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12701.4014 - mae: 12701.4014 - val_loss: 12225.9688 - val_mae: 12225.9688\n",
            "Epoch 12/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12499.0908 - mae: 12499.0908 - val_loss: 12005.1904 - val_mae: 12005.1904\n",
            "Epoch 13/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12259.6006 - mae: 12259.6006 - val_loss: 11746.8779 - val_mae: 11746.8779\n",
            "Epoch 14/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11983.8564 - mae: 11983.8564 - val_loss: 11454.1094 - val_mae: 11454.1094\n",
            "Epoch 15/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11675.6777 - mae: 11675.6777 - val_loss: 11130.6758 - val_mae: 11130.6758\n",
            "Epoch 16/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11341.4023 - mae: 11341.4023 - val_loss: 10799.4629 - val_mae: 10799.4629\n",
            "Epoch 17/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11002.8809 - mae: 11002.8809 - val_loss: 10473.1270 - val_mae: 10473.1270\n",
            "Epoch 18/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10670.6309 - mae: 10670.6309 - val_loss: 10146.3711 - val_mae: 10146.3711\n",
            "Epoch 19/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10335.7295 - mae: 10335.7295 - val_loss: 9832.1318 - val_mae: 9832.1318\n",
            "Epoch 20/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10003.7441 - mae: 10003.7441 - val_loss: 9530.6963 - val_mae: 9530.6963\n",
            "Epoch 21/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 9683.7939 - mae: 9683.7939 - val_loss: 9245.8232 - val_mae: 9245.8232\n",
            "Epoch 22/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 9382.8975 - mae: 9382.8975 - val_loss: 9008.0615 - val_mae: 9008.0615\n",
            "Epoch 23/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 9110.2061 - mae: 9110.2061 - val_loss: 8808.5703 - val_mae: 8808.5703\n",
            "Epoch 24/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8865.1758 - mae: 8865.1758 - val_loss: 8638.3438 - val_mae: 8638.3438\n",
            "Epoch 25/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8651.7832 - mae: 8651.7832 - val_loss: 8507.7109 - val_mae: 8507.7109\n",
            "Epoch 26/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8465.3389 - mae: 8465.3389 - val_loss: 8397.8887 - val_mae: 8397.8887\n",
            "Epoch 27/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8306.8545 - mae: 8306.8545 - val_loss: 8315.9248 - val_mae: 8315.9248\n",
            "Epoch 28/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8183.9019 - mae: 8183.9019 - val_loss: 8251.5293 - val_mae: 8251.5293\n",
            "Epoch 29/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8085.5635 - mae: 8085.5635 - val_loss: 8199.4775 - val_mae: 8199.4775\n",
            "Epoch 30/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8009.1299 - mae: 8009.1299 - val_loss: 8157.1519 - val_mae: 8157.1519\n",
            "Epoch 31/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7945.5356 - mae: 7945.5356 - val_loss: 8122.5327 - val_mae: 8122.5327\n",
            "Epoch 32/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7892.9497 - mae: 7892.9497 - val_loss: 8090.5757 - val_mae: 8090.5757\n",
            "Epoch 33/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7849.5073 - mae: 7849.5073 - val_loss: 8059.8984 - val_mae: 8059.8984\n",
            "Epoch 34/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7810.4268 - mae: 7810.4268 - val_loss: 8031.6299 - val_mae: 8031.6299\n",
            "Epoch 35/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7775.4951 - mae: 7775.4951 - val_loss: 8004.1157 - val_mae: 8004.1157\n",
            "Epoch 36/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7741.5908 - mae: 7741.5908 - val_loss: 7975.0483 - val_mae: 7975.0483\n",
            "Epoch 37/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7708.6348 - mae: 7708.6348 - val_loss: 7947.0122 - val_mae: 7947.0122\n",
            "Epoch 38/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7675.3721 - mae: 7675.3721 - val_loss: 7917.8042 - val_mae: 7917.8042\n",
            "Epoch 39/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7643.3418 - mae: 7643.3418 - val_loss: 7890.4019 - val_mae: 7890.4019\n",
            "Epoch 40/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7611.4634 - mae: 7611.4634 - val_loss: 7857.9766 - val_mae: 7857.9766\n",
            "Epoch 41/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7579.0137 - mae: 7579.0137 - val_loss: 7826.0781 - val_mae: 7826.0781\n",
            "Epoch 42/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7547.0742 - mae: 7547.0742 - val_loss: 7791.7803 - val_mae: 7791.7803\n",
            "Epoch 43/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7515.4053 - mae: 7515.4053 - val_loss: 7760.3481 - val_mae: 7760.3481\n",
            "Epoch 44/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7482.4326 - mae: 7482.4326 - val_loss: 7726.4019 - val_mae: 7726.4019\n",
            "Epoch 45/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7449.0508 - mae: 7449.0508 - val_loss: 7694.9355 - val_mae: 7694.9355\n",
            "Epoch 46/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7415.2139 - mae: 7415.2139 - val_loss: 7662.8716 - val_mae: 7662.8716\n",
            "Epoch 47/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7381.5317 - mae: 7381.5317 - val_loss: 7625.6562 - val_mae: 7625.6562\n",
            "Epoch 48/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7345.1465 - mae: 7345.1465 - val_loss: 7592.2583 - val_mae: 7592.2583\n",
            "Epoch 49/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7310.1670 - mae: 7310.1670 - val_loss: 7558.2759 - val_mae: 7558.2759\n",
            "Epoch 50/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7273.3428 - mae: 7273.3428 - val_loss: 7518.8154 - val_mae: 7518.8154\n",
            "Epoch 51/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7236.4619 - mae: 7236.4619 - val_loss: 7482.4648 - val_mae: 7482.4648\n",
            "Epoch 52/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7198.1611 - mae: 7198.1611 - val_loss: 7443.5713 - val_mae: 7443.5713\n",
            "Epoch 53/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7159.4946 - mae: 7159.4946 - val_loss: 7403.9653 - val_mae: 7403.9653\n",
            "Epoch 54/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7119.4653 - mae: 7119.4653 - val_loss: 7364.2710 - val_mae: 7364.2710\n",
            "Epoch 55/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7079.2319 - mae: 7079.2319 - val_loss: 7322.7461 - val_mae: 7322.7461\n",
            "Epoch 56/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7038.5039 - mae: 7038.5039 - val_loss: 7283.5308 - val_mae: 7283.5308\n",
            "Epoch 57/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6994.9321 - mae: 6994.9321 - val_loss: 7237.2993 - val_mae: 7237.2993\n",
            "Epoch 58/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6952.2305 - mae: 6952.2305 - val_loss: 7194.4448 - val_mae: 7194.4448\n",
            "Epoch 59/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6906.0181 - mae: 6906.0181 - val_loss: 7144.2666 - val_mae: 7144.2666\n",
            "Epoch 60/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6862.5117 - mae: 6862.5117 - val_loss: 7095.4897 - val_mae: 7095.4897\n",
            "Epoch 61/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6814.4590 - mae: 6814.4590 - val_loss: 7048.5518 - val_mae: 7048.5518\n",
            "Epoch 62/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6766.0732 - mae: 6766.0732 - val_loss: 6998.3037 - val_mae: 6998.3037\n",
            "Epoch 63/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6716.3447 - mae: 6716.3447 - val_loss: 6948.3271 - val_mae: 6948.3271\n",
            "Epoch 64/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 6666.6055 - mae: 6666.6055 - val_loss: 6891.1138 - val_mae: 6891.1138\n",
            "Epoch 65/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 6611.7969 - mae: 6611.7969 - val_loss: 6839.1797 - val_mae: 6839.1797\n",
            "Epoch 66/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 6558.1929 - mae: 6558.1929 - val_loss: 6780.1836 - val_mae: 6780.1836\n",
            "Epoch 67/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 6502.8540 - mae: 6502.8540 - val_loss: 6722.9673 - val_mae: 6722.9673\n",
            "Epoch 68/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6445.3159 - mae: 6445.3159 - val_loss: 6663.0293 - val_mae: 6663.0293\n",
            "Epoch 69/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6386.1699 - mae: 6386.1699 - val_loss: 6602.3760 - val_mae: 6602.3760\n",
            "Epoch 70/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6325.4600 - mae: 6325.4600 - val_loss: 6538.6445 - val_mae: 6538.6445\n",
            "Epoch 71/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 6263.9980 - mae: 6263.9980 - val_loss: 6469.5132 - val_mae: 6469.5132\n",
            "Epoch 72/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 6199.4214 - mae: 6199.4214 - val_loss: 6404.0435 - val_mae: 6404.0435\n",
            "Epoch 73/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6132.5659 - mae: 6132.5659 - val_loss: 6331.7090 - val_mae: 6331.7095\n",
            "Epoch 74/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 6064.7114 - mae: 6064.7114 - val_loss: 6258.8047 - val_mae: 6258.8047\n",
            "Epoch 75/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 5995.2334 - mae: 5995.2334 - val_loss: 6183.4399 - val_mae: 6183.4399\n",
            "Epoch 76/1000\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 5922.2046 - mae: 5922.2046 - val_loss: 6101.2393 - val_mae: 6101.2393\n",
            "Epoch 77/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 5849.5107 - mae: 5849.5107 - val_loss: 6018.2539 - val_mae: 6018.2539\n",
            "Epoch 78/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 5772.7744 - mae: 5772.7744 - val_loss: 5937.0444 - val_mae: 5937.0444\n",
            "Epoch 79/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 5696.3315 - mae: 5696.3315 - val_loss: 5852.0542 - val_mae: 5852.0542\n",
            "Epoch 80/1000\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 5614.7095 - mae: 5614.7095 - val_loss: 5758.9458 - val_mae: 5758.9458\n",
            "Epoch 81/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 5534.4375 - mae: 5534.4375 - val_loss: 5667.4414 - val_mae: 5667.4414\n",
            "Epoch 82/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5455.9683 - mae: 5455.9683 - val_loss: 5572.8149 - val_mae: 5572.8149\n",
            "Epoch 83/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5374.3066 - mae: 5374.3066 - val_loss: 5476.5269 - val_mae: 5476.5269\n",
            "Epoch 84/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5289.9575 - mae: 5289.9575 - val_loss: 5376.3545 - val_mae: 5376.3545\n",
            "Epoch 85/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5204.5864 - mae: 5204.5864 - val_loss: 5272.5923 - val_mae: 5272.5923\n",
            "Epoch 86/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5119.3296 - mae: 5119.3296 - val_loss: 5169.7554 - val_mae: 5169.7554\n",
            "Epoch 87/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5033.1533 - mae: 5033.1533 - val_loss: 5066.3711 - val_mae: 5066.3711\n",
            "Epoch 88/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4944.7578 - mae: 4944.7578 - val_loss: 4962.2778 - val_mae: 4962.2778\n",
            "Epoch 89/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4856.4014 - mae: 4856.4014 - val_loss: 4858.8433 - val_mae: 4858.8433\n",
            "Epoch 90/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4767.9136 - mae: 4767.9136 - val_loss: 4754.6260 - val_mae: 4754.6260\n",
            "Epoch 91/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4680.8384 - mae: 4680.8384 - val_loss: 4646.3760 - val_mae: 4646.3760\n",
            "Epoch 92/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4594.7358 - mae: 4594.7358 - val_loss: 4541.7754 - val_mae: 4541.7754\n",
            "Epoch 93/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4514.0684 - mae: 4514.0684 - val_loss: 4442.8901 - val_mae: 4442.8901\n",
            "Epoch 94/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4437.9761 - mae: 4437.9761 - val_loss: 4352.7388 - val_mae: 4352.7388\n",
            "Epoch 95/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4366.8066 - mae: 4366.8066 - val_loss: 4264.0195 - val_mae: 4264.0195\n",
            "Epoch 96/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4295.2271 - mae: 4295.2271 - val_loss: 4185.4004 - val_mae: 4185.4004\n",
            "Epoch 97/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4227.8682 - mae: 4227.8682 - val_loss: 4103.4116 - val_mae: 4103.4116\n",
            "Epoch 98/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4163.9546 - mae: 4163.9546 - val_loss: 4030.6572 - val_mae: 4030.6572\n",
            "Epoch 99/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4103.5049 - mae: 4103.5049 - val_loss: 3961.7402 - val_mae: 3961.7402\n",
            "Epoch 100/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4045.1252 - mae: 4045.1252 - val_loss: 3899.1763 - val_mae: 3899.1763\n",
            "Epoch 101/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3991.0337 - mae: 3991.0337 - val_loss: 3838.1833 - val_mae: 3838.1833\n",
            "Epoch 102/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3940.5623 - mae: 3940.5623 - val_loss: 3783.2620 - val_mae: 3783.2620\n",
            "Epoch 103/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3895.8582 - mae: 3895.8582 - val_loss: 3731.6897 - val_mae: 3731.6897\n",
            "Epoch 104/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3854.6558 - mae: 3854.6558 - val_loss: 3689.4927 - val_mae: 3689.4927\n",
            "Epoch 105/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3820.3760 - mae: 3820.3760 - val_loss: 3647.3865 - val_mae: 3647.3865\n",
            "Epoch 106/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3789.8142 - mae: 3789.8142 - val_loss: 3614.2063 - val_mae: 3614.2063\n",
            "Epoch 107/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3762.2473 - mae: 3762.2473 - val_loss: 3589.5544 - val_mae: 3589.5544\n",
            "Epoch 108/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3741.3911 - mae: 3741.3911 - val_loss: 3565.7375 - val_mae: 3565.7375\n",
            "Epoch 109/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3722.6777 - mae: 3722.6777 - val_loss: 3547.3572 - val_mae: 3547.3572\n",
            "Epoch 110/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3707.1497 - mae: 3707.1497 - val_loss: 3533.7400 - val_mae: 3533.7400\n",
            "Epoch 111/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3694.2288 - mae: 3694.2288 - val_loss: 3518.7129 - val_mae: 3518.7129\n",
            "Epoch 112/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3681.6741 - mae: 3681.6741 - val_loss: 3506.9797 - val_mae: 3506.9797\n",
            "Epoch 113/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3672.4158 - mae: 3672.4158 - val_loss: 3496.9089 - val_mae: 3496.9089\n",
            "Epoch 114/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3665.7268 - mae: 3665.7268 - val_loss: 3489.1133 - val_mae: 3489.1130\n",
            "Epoch 115/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3656.7441 - mae: 3656.7441 - val_loss: 3482.3345 - val_mae: 3482.3345\n",
            "Epoch 116/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3651.5889 - mae: 3651.5889 - val_loss: 3475.8125 - val_mae: 3475.8125\n",
            "Epoch 117/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3644.6765 - mae: 3644.6765 - val_loss: 3468.1294 - val_mae: 3468.1294\n",
            "Epoch 118/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3639.7698 - mae: 3639.7698 - val_loss: 3460.1433 - val_mae: 3460.1433\n",
            "Epoch 119/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3633.2288 - mae: 3633.2288 - val_loss: 3455.7393 - val_mae: 3455.7393\n",
            "Epoch 120/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3628.1404 - mae: 3628.1404 - val_loss: 3448.7720 - val_mae: 3448.7720\n",
            "Epoch 121/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3626.0090 - mae: 3626.0090 - val_loss: 3446.6384 - val_mae: 3446.6384\n",
            "Epoch 122/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3621.1860 - mae: 3621.1860 - val_loss: 3440.0588 - val_mae: 3440.0588\n",
            "Epoch 123/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3616.5093 - mae: 3616.5093 - val_loss: 3433.7285 - val_mae: 3433.7285\n",
            "Epoch 124/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3613.3582 - mae: 3613.3582 - val_loss: 3428.3762 - val_mae: 3428.3762\n",
            "Epoch 125/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3609.3789 - mae: 3609.3789 - val_loss: 3424.0747 - val_mae: 3424.0750\n",
            "Epoch 126/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3606.8125 - mae: 3606.8125 - val_loss: 3420.9866 - val_mae: 3420.9866\n",
            "Epoch 127/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3602.7354 - mae: 3602.7354 - val_loss: 3414.8989 - val_mae: 3414.8989\n",
            "Epoch 128/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3598.3608 - mae: 3598.3608 - val_loss: 3409.0425 - val_mae: 3409.0425\n",
            "Epoch 129/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3594.8562 - mae: 3594.8562 - val_loss: 3404.8237 - val_mae: 3404.8237\n",
            "Epoch 130/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3593.4756 - mae: 3593.4756 - val_loss: 3401.8003 - val_mae: 3401.8003\n",
            "Epoch 131/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3587.9399 - mae: 3587.9399 - val_loss: 3397.1621 - val_mae: 3397.1621\n",
            "Epoch 132/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3584.3398 - mae: 3584.3398 - val_loss: 3391.1426 - val_mae: 3391.1426\n",
            "Epoch 133/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3582.9871 - mae: 3582.9871 - val_loss: 3385.9043 - val_mae: 3385.9043\n",
            "Epoch 134/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3577.9880 - mae: 3577.9880 - val_loss: 3382.0659 - val_mae: 3382.0659\n",
            "Epoch 135/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3574.5518 - mae: 3574.5518 - val_loss: 3378.0168 - val_mae: 3378.0168\n",
            "Epoch 136/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3570.8799 - mae: 3570.8799 - val_loss: 3374.8904 - val_mae: 3374.8904\n",
            "Epoch 137/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3569.2747 - mae: 3569.2747 - val_loss: 3368.9114 - val_mae: 3368.9114\n",
            "Epoch 138/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3567.1868 - mae: 3567.1868 - val_loss: 3365.0938 - val_mae: 3365.0938\n",
            "Epoch 139/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3561.9294 - mae: 3561.9294 - val_loss: 3360.0947 - val_mae: 3360.0947\n",
            "Epoch 140/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3558.3425 - mae: 3558.3425 - val_loss: 3355.3303 - val_mae: 3355.3303\n",
            "Epoch 141/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3555.4268 - mae: 3555.4268 - val_loss: 3352.9338 - val_mae: 3352.9338\n",
            "Epoch 142/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3551.9785 - mae: 3551.9785 - val_loss: 3347.1277 - val_mae: 3347.1277\n",
            "Epoch 143/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3548.7341 - mae: 3548.7341 - val_loss: 3342.1687 - val_mae: 3342.1687\n",
            "Epoch 144/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3546.9714 - mae: 3546.9714 - val_loss: 3337.5232 - val_mae: 3337.5232\n",
            "Epoch 145/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3542.1553 - mae: 3542.1553 - val_loss: 3334.6504 - val_mae: 3334.6504\n",
            "Epoch 146/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3539.8733 - mae: 3539.8733 - val_loss: 3330.4663 - val_mae: 3330.4663\n",
            "Epoch 147/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3535.9492 - mae: 3535.9492 - val_loss: 3324.8706 - val_mae: 3324.8706\n",
            "Epoch 148/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3533.1191 - mae: 3533.1191 - val_loss: 3320.9062 - val_mae: 3320.9062\n",
            "Epoch 149/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3531.3015 - mae: 3531.3015 - val_loss: 3317.9165 - val_mae: 3317.9165\n",
            "Epoch 150/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3528.6211 - mae: 3528.6211 - val_loss: 3313.3301 - val_mae: 3313.3301\n",
            "Epoch 151/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3524.2771 - mae: 3524.2771 - val_loss: 3309.7642 - val_mae: 3309.7642\n",
            "Epoch 152/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3521.4834 - mae: 3521.4834 - val_loss: 3304.8093 - val_mae: 3304.8093\n",
            "Epoch 153/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3518.2717 - mae: 3518.2717 - val_loss: 3302.2148 - val_mae: 3302.2148\n",
            "Epoch 154/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3516.6941 - mae: 3516.6941 - val_loss: 3298.7527 - val_mae: 3298.7527\n",
            "Epoch 155/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3513.5554 - mae: 3513.5554 - val_loss: 3294.1045 - val_mae: 3294.1045\n",
            "Epoch 156/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3510.4778 - mae: 3510.4778 - val_loss: 3291.5686 - val_mae: 3291.5686\n",
            "Epoch 157/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3508.4917 - mae: 3508.4917 - val_loss: 3286.2109 - val_mae: 3286.2109\n",
            "Epoch 158/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3504.2534 - mae: 3504.2534 - val_loss: 3281.0540 - val_mae: 3281.0540\n",
            "Epoch 159/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3501.0625 - mae: 3501.0625 - val_loss: 3278.9268 - val_mae: 3278.9268\n",
            "Epoch 160/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3499.2361 - mae: 3499.2361 - val_loss: 3275.4033 - val_mae: 3275.4033\n",
            "Epoch 161/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3496.4651 - mae: 3496.4651 - val_loss: 3269.9907 - val_mae: 3269.9907\n",
            "Epoch 162/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3491.4587 - mae: 3491.4587 - val_loss: 3264.1899 - val_mae: 3264.1899\n",
            "Epoch 163/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3486.9475 - mae: 3486.9475 - val_loss: 3259.8811 - val_mae: 3259.8811\n",
            "Epoch 164/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3483.8330 - mae: 3483.8330 - val_loss: 3254.4697 - val_mae: 3254.4697\n",
            "Epoch 165/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3480.4724 - mae: 3480.4724 - val_loss: 3248.4971 - val_mae: 3248.4971\n",
            "Epoch 166/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3476.1045 - mae: 3476.1045 - val_loss: 3244.8979 - val_mae: 3244.8982\n",
            "Epoch 167/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.9219 - mae: 3472.9219 - val_loss: 3239.3967 - val_mae: 3239.3967\n",
            "Epoch 168/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3468.3127 - mae: 3468.3127 - val_loss: 3236.1506 - val_mae: 3236.1506\n",
            "Epoch 169/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3466.2358 - mae: 3466.2358 - val_loss: 3230.7290 - val_mae: 3230.7290\n",
            "Epoch 170/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3460.9375 - mae: 3460.9375 - val_loss: 3225.2788 - val_mae: 3225.2788\n",
            "Epoch 171/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3458.3530 - mae: 3458.3530 - val_loss: 3221.2993 - val_mae: 3221.2993\n",
            "Epoch 172/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3455.4277 - mae: 3455.4277 - val_loss: 3214.1387 - val_mae: 3214.1387\n",
            "Epoch 173/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3451.2097 - mae: 3451.2097 - val_loss: 3210.8818 - val_mae: 3210.8818\n",
            "Epoch 174/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3447.9771 - mae: 3447.9771 - val_loss: 3208.9028 - val_mae: 3208.9028\n",
            "Epoch 175/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3444.7932 - mae: 3444.7932 - val_loss: 3204.8699 - val_mae: 3204.8699\n",
            "Epoch 176/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3442.3350 - mae: 3442.3350 - val_loss: 3198.7468 - val_mae: 3198.7468\n",
            "Epoch 177/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3439.2290 - mae: 3439.2290 - val_loss: 3194.5315 - val_mae: 3194.5315\n",
            "Epoch 178/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3436.8291 - mae: 3436.8291 - val_loss: 3190.8215 - val_mae: 3190.8215\n",
            "Epoch 179/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3434.1333 - mae: 3434.1333 - val_loss: 3186.6682 - val_mae: 3186.6682\n",
            "Epoch 180/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3430.4204 - mae: 3430.4204 - val_loss: 3182.9968 - val_mae: 3182.9968\n",
            "Epoch 181/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3429.3792 - mae: 3429.3792 - val_loss: 3178.7996 - val_mae: 3178.7996\n",
            "Epoch 182/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3425.5676 - mae: 3425.5676 - val_loss: 3173.3667 - val_mae: 3173.3667\n",
            "Epoch 183/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3422.3362 - mae: 3422.3362 - val_loss: 3169.5962 - val_mae: 3169.5962\n",
            "Epoch 184/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3419.7661 - mae: 3419.7661 - val_loss: 3164.8955 - val_mae: 3164.8955\n",
            "Epoch 185/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3416.7319 - mae: 3416.7319 - val_loss: 3162.5977 - val_mae: 3162.5977\n",
            "Epoch 186/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3413.7642 - mae: 3413.7642 - val_loss: 3156.8057 - val_mae: 3156.8057\n",
            "Epoch 187/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3411.5754 - mae: 3411.5754 - val_loss: 3151.6035 - val_mae: 3151.6035\n",
            "Epoch 188/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3407.8552 - mae: 3407.8552 - val_loss: 3148.1953 - val_mae: 3148.1953\n",
            "Epoch 189/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3405.6060 - mae: 3405.6060 - val_loss: 3142.6060 - val_mae: 3142.6060\n",
            "Epoch 190/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3401.1145 - mae: 3401.1145 - val_loss: 3139.3088 - val_mae: 3139.3088\n",
            "Epoch 191/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3398.0344 - mae: 3398.0344 - val_loss: 3135.5286 - val_mae: 3135.5286\n",
            "Epoch 192/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3394.9985 - mae: 3394.9985 - val_loss: 3129.1497 - val_mae: 3129.1497\n",
            "Epoch 193/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3392.0859 - mae: 3392.0859 - val_loss: 3125.4814 - val_mae: 3125.4814\n",
            "Epoch 194/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3393.8340 - mae: 3393.8340 - val_loss: 3121.4800 - val_mae: 3121.4800\n",
            "Epoch 195/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3386.8149 - mae: 3386.8149 - val_loss: 3115.9646 - val_mae: 3115.9646\n",
            "Epoch 196/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3384.3579 - mae: 3384.3579 - val_loss: 3111.3596 - val_mae: 3111.3596\n",
            "Epoch 197/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3379.9863 - mae: 3379.9863 - val_loss: 3105.8096 - val_mae: 3105.8096\n",
            "Epoch 198/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3376.8787 - mae: 3376.8787 - val_loss: 3102.2842 - val_mae: 3102.2842\n",
            "Epoch 199/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3373.9404 - mae: 3373.9404 - val_loss: 3096.5623 - val_mae: 3096.5623\n",
            "Epoch 200/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3372.1697 - mae: 3372.1697 - val_loss: 3092.5842 - val_mae: 3092.5842\n",
            "Epoch 201/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3368.1926 - mae: 3368.1926 - val_loss: 3086.9648 - val_mae: 3086.9648\n",
            "Epoch 202/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3365.0959 - mae: 3365.0959 - val_loss: 3083.4661 - val_mae: 3083.4661\n",
            "Epoch 203/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3361.9270 - mae: 3361.9270 - val_loss: 3076.0876 - val_mae: 3076.0876\n",
            "Epoch 204/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3359.4692 - mae: 3359.4692 - val_loss: 3075.7031 - val_mae: 3075.7031\n",
            "Epoch 205/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3353.8638 - mae: 3353.8638 - val_loss: 3067.8865 - val_mae: 3067.8865\n",
            "Epoch 206/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3354.6072 - mae: 3354.6072 - val_loss: 3063.4182 - val_mae: 3063.4182\n",
            "Epoch 207/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3350.3086 - mae: 3350.3086 - val_loss: 3058.7471 - val_mae: 3058.7471\n",
            "Epoch 208/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3347.2629 - mae: 3347.2629 - val_loss: 3053.9932 - val_mae: 3053.9932\n",
            "Epoch 209/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3344.3879 - mae: 3344.3879 - val_loss: 3048.9045 - val_mae: 3048.9045\n",
            "Epoch 210/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3341.3804 - mae: 3341.3804 - val_loss: 3045.3660 - val_mae: 3045.3660\n",
            "Epoch 211/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3340.8057 - mae: 3340.8057 - val_loss: 3040.9248 - val_mae: 3040.9248\n",
            "Epoch 212/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3338.2737 - mae: 3338.2737 - val_loss: 3038.4224 - val_mae: 3038.4224\n",
            "Epoch 213/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3334.6060 - mae: 3334.6060 - val_loss: 3033.5183 - val_mae: 3033.5183\n",
            "Epoch 214/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3332.0002 - mae: 3332.0002 - val_loss: 3029.9358 - val_mae: 3029.9358\n",
            "Epoch 215/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3329.0930 - mae: 3329.0930 - val_loss: 3026.9219 - val_mae: 3026.9219\n",
            "Epoch 216/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3327.2634 - mae: 3327.2634 - val_loss: 3024.4839 - val_mae: 3024.4839\n",
            "Epoch 217/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3324.8413 - mae: 3324.8413 - val_loss: 3020.2307 - val_mae: 3020.2307\n",
            "Epoch 218/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3322.8127 - mae: 3322.8127 - val_loss: 3016.7661 - val_mae: 3016.7661\n",
            "Epoch 219/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3320.9392 - mae: 3320.9392 - val_loss: 3015.2312 - val_mae: 3015.2312\n",
            "Epoch 220/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3318.7043 - mae: 3318.7043 - val_loss: 3009.0505 - val_mae: 3009.0505\n",
            "Epoch 221/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3315.4468 - mae: 3315.4468 - val_loss: 3006.3440 - val_mae: 3006.3440\n",
            "Epoch 222/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3313.3411 - mae: 3313.3411 - val_loss: 3004.8105 - val_mae: 3004.8105\n",
            "Epoch 223/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3310.9519 - mae: 3310.9519 - val_loss: 2999.4124 - val_mae: 2999.4124\n",
            "Epoch 224/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3307.7734 - mae: 3307.7734 - val_loss: 2995.8906 - val_mae: 2995.8906\n",
            "Epoch 225/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3306.1045 - mae: 3306.1045 - val_loss: 2992.4563 - val_mae: 2992.4563\n",
            "Epoch 226/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3303.3511 - mae: 3303.3511 - val_loss: 2989.3386 - val_mae: 2989.3386\n",
            "Epoch 227/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3301.8159 - mae: 3301.8159 - val_loss: 2987.8008 - val_mae: 2987.8008\n",
            "Epoch 228/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3299.3467 - mae: 3299.3467 - val_loss: 2985.1321 - val_mae: 2985.1321\n",
            "Epoch 229/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3296.8176 - mae: 3296.8176 - val_loss: 2980.3757 - val_mae: 2980.3757\n",
            "Epoch 230/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3294.9661 - mae: 3294.9661 - val_loss: 2979.1465 - val_mae: 2979.1465\n",
            "Epoch 231/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3293.1558 - mae: 3293.1558 - val_loss: 2973.0225 - val_mae: 2973.0225\n",
            "Epoch 232/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3289.8303 - mae: 3289.8303 - val_loss: 2971.8723 - val_mae: 2971.8723\n",
            "Epoch 233/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3288.0742 - mae: 3288.0742 - val_loss: 2967.5547 - val_mae: 2967.5547\n",
            "Epoch 234/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3286.9473 - mae: 3286.9473 - val_loss: 2963.6917 - val_mae: 2963.6917\n",
            "Epoch 235/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3284.3293 - mae: 3284.3293 - val_loss: 2963.8755 - val_mae: 2963.8755\n",
            "Epoch 236/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3280.8557 - mae: 3280.8557 - val_loss: 2959.0332 - val_mae: 2959.0332\n",
            "Epoch 237/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3280.0034 - mae: 3280.0034 - val_loss: 2953.3335 - val_mae: 2953.3335\n",
            "Epoch 238/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3277.0613 - mae: 3277.0613 - val_loss: 2950.4233 - val_mae: 2950.4233\n",
            "Epoch 239/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3274.4543 - mae: 3274.4543 - val_loss: 2947.0186 - val_mae: 2947.0186\n",
            "Epoch 240/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3272.5222 - mae: 3272.5222 - val_loss: 2943.5469 - val_mae: 2943.5469\n",
            "Epoch 241/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3270.3179 - mae: 3270.3179 - val_loss: 2941.3320 - val_mae: 2941.3320\n",
            "Epoch 242/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3267.2192 - mae: 3267.2192 - val_loss: 2940.0068 - val_mae: 2940.0068\n",
            "Epoch 243/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3265.3303 - mae: 3265.3303 - val_loss: 2936.6472 - val_mae: 2936.6472\n",
            "Epoch 244/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3264.2061 - mae: 3264.2061 - val_loss: 2937.7520 - val_mae: 2937.7520\n",
            "Epoch 245/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3264.0510 - mae: 3264.0510 - val_loss: 2932.4937 - val_mae: 2932.4937\n",
            "Epoch 246/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3262.3511 - mae: 3262.3511 - val_loss: 2928.5234 - val_mae: 2928.5234\n",
            "Epoch 247/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3260.0386 - mae: 3260.0386 - val_loss: 2927.6536 - val_mae: 2927.6536\n",
            "Epoch 248/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3258.9727 - mae: 3258.9727 - val_loss: 2926.8340 - val_mae: 2926.8340\n",
            "Epoch 249/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3257.8096 - mae: 3257.8096 - val_loss: 2924.0454 - val_mae: 2924.0454\n",
            "Epoch 250/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3256.3247 - mae: 3256.3247 - val_loss: 2923.0952 - val_mae: 2923.0952\n",
            "Epoch 251/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3255.2827 - mae: 3255.2827 - val_loss: 2920.6641 - val_mae: 2920.6641\n",
            "Epoch 252/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3254.1582 - mae: 3254.1582 - val_loss: 2918.0327 - val_mae: 2918.0327\n",
            "Epoch 253/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3254.7830 - mae: 3254.7830 - val_loss: 2915.6016 - val_mae: 2915.6016\n",
            "Epoch 254/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3251.4651 - mae: 3251.4651 - val_loss: 2914.8337 - val_mae: 2914.8337\n",
            "Epoch 255/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3251.1265 - mae: 3251.1265 - val_loss: 2914.0645 - val_mae: 2914.0645\n",
            "Epoch 256/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3249.6626 - mae: 3249.6626 - val_loss: 2913.6345 - val_mae: 2913.6345\n",
            "Epoch 257/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3249.9883 - mae: 3249.9883 - val_loss: 2908.8577 - val_mae: 2908.8577\n",
            "Epoch 258/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3247.6924 - mae: 3247.6924 - val_loss: 2907.7920 - val_mae: 2907.7920\n",
            "Epoch 259/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3247.2271 - mae: 3247.2271 - val_loss: 2908.4958 - val_mae: 2908.4958\n",
            "Epoch 260/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3245.6394 - mae: 3245.6394 - val_loss: 2907.3596 - val_mae: 2907.3596\n",
            "Epoch 261/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3244.9568 - mae: 3244.9568 - val_loss: 2904.7175 - val_mae: 2904.7175\n",
            "Epoch 262/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3244.1882 - mae: 3244.1882 - val_loss: 2906.3845 - val_mae: 2906.3845\n",
            "Epoch 263/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3245.2056 - mae: 3245.2056 - val_loss: 2901.9634 - val_mae: 2901.9634\n",
            "Epoch 264/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3241.5129 - mae: 3241.5129 - val_loss: 2901.0903 - val_mae: 2901.0903\n",
            "Epoch 265/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3242.0410 - mae: 3242.0410 - val_loss: 2899.6875 - val_mae: 2899.6875\n",
            "Epoch 266/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3239.5681 - mae: 3239.5681 - val_loss: 2897.4670 - val_mae: 2897.4670\n",
            "Epoch 267/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3238.7952 - mae: 3238.7952 - val_loss: 2898.9377 - val_mae: 2898.9377\n",
            "Epoch 268/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3237.9048 - mae: 3237.9048 - val_loss: 2897.7317 - val_mae: 2897.7317\n",
            "Epoch 269/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3236.9514 - mae: 3236.9514 - val_loss: 2895.9995 - val_mae: 2895.9995\n",
            "Epoch 270/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3236.2034 - mae: 3236.2034 - val_loss: 2893.6870 - val_mae: 2893.6870\n",
            "Epoch 271/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3235.2844 - mae: 3235.2844 - val_loss: 2896.1851 - val_mae: 2896.1851\n",
            "Epoch 272/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3234.5371 - mae: 3234.5371 - val_loss: 2893.5894 - val_mae: 2893.5894\n",
            "Epoch 273/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3234.1511 - mae: 3234.1511 - val_loss: 2892.3411 - val_mae: 2892.3411\n",
            "Epoch 274/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3233.0771 - mae: 3233.0771 - val_loss: 2890.8254 - val_mae: 2890.8254\n",
            "Epoch 275/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3232.3979 - mae: 3232.3979 - val_loss: 2889.8853 - val_mae: 2889.8853\n",
            "Epoch 276/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3231.4458 - mae: 3231.4458 - val_loss: 2892.8623 - val_mae: 2892.8623\n",
            "Epoch 277/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3231.2607 - mae: 3231.2607 - val_loss: 2887.5464 - val_mae: 2887.5464\n",
            "Epoch 278/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3230.2300 - mae: 3230.2300 - val_loss: 2887.3542 - val_mae: 2887.3542\n",
            "Epoch 279/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3229.6191 - mae: 3229.6191 - val_loss: 2886.7544 - val_mae: 2886.7544\n",
            "Epoch 280/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3228.2783 - mae: 3228.2783 - val_loss: 2885.4714 - val_mae: 2885.4714\n",
            "Epoch 281/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3227.2305 - mae: 3227.2305 - val_loss: 2885.9495 - val_mae: 2885.9495\n",
            "Epoch 282/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3226.8086 - mae: 3226.8086 - val_loss: 2884.7966 - val_mae: 2884.7966\n",
            "Epoch 283/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3227.2026 - mae: 3227.2026 - val_loss: 2883.9106 - val_mae: 2883.9106\n",
            "Epoch 284/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3226.0090 - mae: 3226.0090 - val_loss: 2882.8521 - val_mae: 2882.8521\n",
            "Epoch 285/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3225.6865 - mae: 3225.6865 - val_loss: 2885.0640 - val_mae: 2885.0640\n",
            "Epoch 286/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3225.5461 - mae: 3225.5461 - val_loss: 2881.2341 - val_mae: 2881.2341\n",
            "Epoch 287/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3223.7012 - mae: 3223.7012 - val_loss: 2880.8005 - val_mae: 2880.8005\n",
            "Epoch 288/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3223.2747 - mae: 3223.2747 - val_loss: 2881.7910 - val_mae: 2881.7910\n",
            "Epoch 289/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3223.9473 - mae: 3223.9473 - val_loss: 2878.8311 - val_mae: 2878.8311\n",
            "Epoch 290/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3221.9958 - mae: 3221.9958 - val_loss: 2879.5437 - val_mae: 2879.5437\n",
            "Epoch 291/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3221.6404 - mae: 3221.6404 - val_loss: 2879.3035 - val_mae: 2879.3035\n",
            "Epoch 292/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3220.3130 - mae: 3220.3130 - val_loss: 2877.7053 - val_mae: 2877.7053\n",
            "Epoch 293/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3222.0676 - mae: 3222.0676 - val_loss: 2876.6455 - val_mae: 2876.6455\n",
            "Epoch 294/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3220.0876 - mae: 3220.0876 - val_loss: 2880.4434 - val_mae: 2880.4434\n",
            "Epoch 295/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3220.2026 - mae: 3220.2026 - val_loss: 2875.4407 - val_mae: 2875.4407\n",
            "Epoch 296/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3219.0171 - mae: 3219.0171 - val_loss: 2875.7134 - val_mae: 2875.7134\n",
            "Epoch 297/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3217.7791 - mae: 3217.7791 - val_loss: 2875.1538 - val_mae: 2875.1538\n",
            "Epoch 298/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3217.0186 - mae: 3217.0186 - val_loss: 2873.9739 - val_mae: 2873.9739\n",
            "Epoch 299/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3217.2361 - mae: 3217.2361 - val_loss: 2872.5652 - val_mae: 2872.5652\n",
            "Epoch 300/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3218.2520 - mae: 3218.2520 - val_loss: 2874.9341 - val_mae: 2874.9341\n",
            "Epoch 301/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3215.1138 - mae: 3215.1138 - val_loss: 2872.8152 - val_mae: 2872.8152\n",
            "Epoch 302/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3215.2039 - mae: 3215.2039 - val_loss: 2871.4580 - val_mae: 2871.4580\n",
            "Epoch 303/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3214.2739 - mae: 3214.2739 - val_loss: 2871.2275 - val_mae: 2871.2275\n",
            "Epoch 304/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3213.8442 - mae: 3213.8442 - val_loss: 2871.1572 - val_mae: 2871.1572\n",
            "Epoch 305/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3214.2202 - mae: 3214.2202 - val_loss: 2870.5564 - val_mae: 2870.5564\n",
            "Epoch 306/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3212.8879 - mae: 3212.8879 - val_loss: 2869.6243 - val_mae: 2869.6243\n",
            "Epoch 307/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3213.4346 - mae: 3213.4346 - val_loss: 2871.2502 - val_mae: 2871.2502\n",
            "Epoch 308/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3211.9763 - mae: 3211.9763 - val_loss: 2869.5801 - val_mae: 2869.5801\n",
            "Epoch 309/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3211.8225 - mae: 3211.8225 - val_loss: 2869.4580 - val_mae: 2869.4580\n",
            "Epoch 310/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3210.9478 - mae: 3210.9478 - val_loss: 2868.4783 - val_mae: 2868.4783\n",
            "Epoch 311/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3210.8926 - mae: 3210.8926 - val_loss: 2871.2351 - val_mae: 2871.2351\n",
            "Epoch 312/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3211.5120 - mae: 3211.5120 - val_loss: 2867.0681 - val_mae: 2867.0681\n",
            "Epoch 313/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3209.5171 - mae: 3209.5171 - val_loss: 2868.1235 - val_mae: 2868.1235\n",
            "Epoch 314/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3209.2764 - mae: 3209.2764 - val_loss: 2866.2014 - val_mae: 2866.2014\n",
            "Epoch 315/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3210.0149 - mae: 3210.0149 - val_loss: 2869.1846 - val_mae: 2869.1846\n",
            "Epoch 316/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3210.0200 - mae: 3210.0200 - val_loss: 2864.9766 - val_mae: 2864.9766\n",
            "Epoch 317/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3207.6011 - mae: 3207.6011 - val_loss: 2865.0898 - val_mae: 2865.0898\n",
            "Epoch 318/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3208.5774 - mae: 3208.5774 - val_loss: 2866.1042 - val_mae: 2866.1042\n",
            "Epoch 319/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3207.9468 - mae: 3207.9468 - val_loss: 2863.9661 - val_mae: 2863.9661\n",
            "Epoch 320/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3206.7227 - mae: 3206.7227 - val_loss: 2863.8794 - val_mae: 2863.8794\n",
            "Epoch 321/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3205.8401 - mae: 3205.8401 - val_loss: 2863.2820 - val_mae: 2863.2820\n",
            "Epoch 322/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3205.4580 - mae: 3205.4580 - val_loss: 2864.3137 - val_mae: 2864.3137\n",
            "Epoch 323/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3205.3032 - mae: 3205.3032 - val_loss: 2862.6116 - val_mae: 2862.6116\n",
            "Epoch 324/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3206.1125 - mae: 3206.1125 - val_loss: 2862.7922 - val_mae: 2862.7922\n",
            "Epoch 325/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3204.8196 - mae: 3204.8196 - val_loss: 2861.9958 - val_mae: 2861.9958\n",
            "Epoch 326/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3204.3269 - mae: 3204.3269 - val_loss: 2862.2341 - val_mae: 2862.2341\n",
            "Epoch 327/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3203.5542 - mae: 3203.5542 - val_loss: 2860.8315 - val_mae: 2860.8315\n",
            "Epoch 328/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3203.2214 - mae: 3203.2214 - val_loss: 2860.8357 - val_mae: 2860.8357\n",
            "Epoch 329/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3202.6060 - mae: 3202.6060 - val_loss: 2860.2578 - val_mae: 2860.2578\n",
            "Epoch 330/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3201.9529 - mae: 3201.9529 - val_loss: 2861.2490 - val_mae: 2861.2490\n",
            "Epoch 331/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3202.0876 - mae: 3202.0876 - val_loss: 2859.7930 - val_mae: 2859.7930\n",
            "Epoch 332/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3203.5029 - mae: 3203.5029 - val_loss: 2859.9973 - val_mae: 2859.9973\n",
            "Epoch 333/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3202.2644 - mae: 3202.2644 - val_loss: 2859.2615 - val_mae: 2859.2615\n",
            "Epoch 334/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3201.2302 - mae: 3201.2302 - val_loss: 2858.5066 - val_mae: 2858.5066\n",
            "Epoch 335/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3201.7866 - mae: 3201.7866 - val_loss: 2863.0186 - val_mae: 2863.0186\n",
            "Epoch 336/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3202.1387 - mae: 3202.1387 - val_loss: 2858.2551 - val_mae: 2858.2551\n",
            "Epoch 337/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3201.4880 - mae: 3201.4880 - val_loss: 2858.1794 - val_mae: 2858.1794\n",
            "Epoch 338/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3201.4014 - mae: 3201.4014 - val_loss: 2857.9634 - val_mae: 2857.9634\n",
            "Epoch 339/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3199.9797 - mae: 3199.9797 - val_loss: 2858.1799 - val_mae: 2858.1799\n",
            "Epoch 340/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3199.1245 - mae: 3199.1245 - val_loss: 2858.1584 - val_mae: 2858.1584\n",
            "Epoch 341/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3200.5486 - mae: 3200.5486 - val_loss: 2857.7639 - val_mae: 2857.7639\n",
            "Epoch 342/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3198.7217 - mae: 3198.7217 - val_loss: 2857.7461 - val_mae: 2857.7461\n",
            "Epoch 343/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3197.9912 - mae: 3197.9912 - val_loss: 2856.1887 - val_mae: 2856.1887\n",
            "Epoch 344/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3197.9448 - mae: 3197.9448 - val_loss: 2856.2874 - val_mae: 2856.2874\n",
            "Epoch 345/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3198.5764 - mae: 3198.5764 - val_loss: 2856.4277 - val_mae: 2856.4277\n",
            "Epoch 346/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3197.1980 - mae: 3197.1980 - val_loss: 2855.5898 - val_mae: 2855.5898\n",
            "Epoch 347/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3198.6973 - mae: 3198.6973 - val_loss: 2855.6003 - val_mae: 2855.6003\n",
            "Epoch 348/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3197.1567 - mae: 3197.1567 - val_loss: 2856.4417 - val_mae: 2856.4417\n",
            "Epoch 349/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3199.8240 - mae: 3199.8240 - val_loss: 2856.6172 - val_mae: 2856.6172\n",
            "Epoch 350/1000\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3197.5051 - mae: 3197.5051 - val_loss: 2856.7668 - val_mae: 2856.7668\n",
            "Epoch 351/1000\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3197.2031 - mae: 3197.2031 - val_loss: 2857.5051 - val_mae: 2857.5051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "KPc768-ltcI1",
        "outputId": "e73567a0-60c6-4a08-abfa-6d64c28996f3"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The experiment has shown that the performance of neural network models work better with data normalised by MinMax Scaler than data using standard scaler"
      ],
      "metadata": {
        "id": "GuyUXwVGuZFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BijIiakduZ73"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}